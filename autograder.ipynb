{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa10c44c-2a38-417e-a40b-80d77ee593ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0cc1b27acd7bd9927ea608c21bc048be",
     "grade": true,
     "grade_id": "cell-bac711362e26a814",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'holdout_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m pipeline_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpipeline.cloudpickle\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Run prediction on each group\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m results\u001b[38;5;241m=\u001b[39m\u001b[43mholdout_data\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent.id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean_categories.name\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mapply(evaluate, pipeline_file)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Display the results, uncomment this for your own display\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m#results.reset_index()['score'].plot.bar();\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# This is the student final grade\u001b[39;00m\n\u001b[1;32m     82\u001b[0m np\u001b[38;5;241m.\u001b[39maverage(results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'holdout_data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "\n",
    "# This code simulates the autograder. It is not the full autograder implementation\n",
    "# but shares an API with the autograder. It expects that your fitted pipeline is\n",
    "# submitted with the name pipeline.cloudpickle as demonstrated above. This object\n",
    "# must implement the predict() function. This is done automatically by the sklearn\n",
    "# Pipeline object if the last element of your pipeline is a classifier which has\n",
    "# a predict() function. If you are not submitting a Pipeline, and want to do something\n",
    "# different, you *must* have a predict() function of the same method signature, e.g.:\n",
    "#\n",
    "#   predict(self, X, **predict_params)->np.ndarray\n",
    "\n",
    "# Load holdout data, in this case I'll simulate it by loading the training data\n",
    "#df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "\n",
    "# And evaluate on all 5k races that we didn't consider for training\n",
    "#holdout_data=df.query(\"`event.id`!='583f013a-1e54-4906-87f7-2b625206f5f9' and `clean_categories.name`=='5k'\")\n",
    "\n",
    "\n",
    "# This is the scoring function to determine model fitness\n",
    "def score(left: pd.DataFrame, right: pd.DataFrame):\n",
    "    '''\n",
    "    Calculates the difference between the left and the right when considering rank of items. \n",
    "    This scoring function requires that the two DataFrames have identical indicies, and that\n",
    "    they each contain only one column of values and no missing values. Props to Blake Atkinson\n",
    "    for providing MWE indicating issues with autograder version #1.\n",
    "    '''\n",
    "    assert(type(left)==pd.DataFrame)\n",
    "    assert(type(right)==pd.DataFrame)\n",
    "    assert(len(left)==len(right))\n",
    "    assert(not np.any(np.isnan(left)))\n",
    "    assert(not np.any(np.isnan(right)))\n",
    "    assert(left.index.equals(right.index))\n",
    "    # convert to ndarrays\n",
    "    left=left.squeeze()\n",
    "    right=right.squeeze()\n",
    "    return np.sum(np.abs(left-right))/(len(left)*(len(left)-1))\n",
    "\n",
    "# This function runs the prediction model agains a given event/category pair. It\n",
    "# intentionally loads the student model each time to avoid accidental leakage of data\n",
    "# between events.\n",
    "def evaluate(data, pipeline_file='pipeline.cloudpickle'):\n",
    "    # Load student pipeline\n",
    "    fitted_pipe = cloudpickle.load(open(pipeline_file,'rb'))\n",
    "    \n",
    "    # Separate out the X and y\n",
    "    X=list(set(data.columns)-{'overall_ranking'})\n",
    "    y=['overall_ranking']\n",
    "    \n",
    "    # Drop any missing results (DNFs)\n",
    "    data=data.dropna(subset=['overall_ranking'])\n",
    "    \n",
    "    # Ensure there is data to actually predict on\n",
    "    if len(data)==0:\n",
    "        return np.nan\n",
    "\n",
    "    # Predict on unseen data\n",
    "    from IPython.utils import io\n",
    "    with io.capture_output() as captured:\n",
    "        predictions=pd.DataFrame(fitted_pipe.predict(data[X]),data.index)\n",
    "    observed=data[y]\n",
    "    \n",
    "    # Generate rankings within this bracket\n",
    "    observed=pd.DataFrame(data[y].rank(),data.index)\n",
    "    \n",
    "    # Return the ratio of the student score\n",
    "    return pd.Series({\"score\":score(observed,predictions)})\n",
    "\n",
    "# Student solution\n",
    "pipeline_file='pipeline.cloudpickle'\n",
    "\n",
    "# Run prediction on each group\n",
    "results=holdout_data.groupby([\"event.id\",\"clean_categories.name\"]).apply(evaluate, pipeline_file)\n",
    "\n",
    "# Display the results, uncomment this for your own display\n",
    "#results.reset_index()['score'].plot.bar();\n",
    "\n",
    "# This is the student final grade\n",
    "np.average(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c9e48-f958-4b10-9486-b4dd43b055f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_sports_analytics_v1_autograder"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
