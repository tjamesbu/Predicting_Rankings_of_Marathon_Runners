{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd26b480-fac1-4df8-9ede-bc4f1c03b213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/home/brooksch/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3397: DtypeWarning: Columns (13,16,17,20,21,27,38,45,46,47,57,66,67,72,73,74,79,104,105,119,121,124) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/tmp/ipykernel_5941/4148480044.py:18: FutureWarning: casting timedelta64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  df['x_result.duration.chip']=pd.to_timedelta(df['result.duration.chip']).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sequence_id                           event.id                            \n",
       "57bdcd1f-a474-43e0-8e54-5f3a5206f5f9  57bdcd1f-a474-43e0-8e54-5f3a5206f5f9    3259\n",
       "                                      59a99331-e614-4004-8634-16bc5206f5f9    3772\n",
       "5e862221-758c-48b1-a7cf-11bcc0a80a41  5e862221-758c-48b1-a7cf-11bcc0a80a41     194\n",
       "                                      5e8622bc-0ef4-472a-a19b-6f4bc0a80a41     268\n",
       "                                      5e862439-c108-40be-b3ec-36b6c0a80a41     404\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using external data in sklearn pipelines\n",
    "\n",
    "# Sometimes when I am building a pipeline I want to include in it data which will\n",
    "# not be available in the holdout dataset but which is still useful for the modeling\n",
    "# task. For instance, from historical data I might want to build new features that\n",
    "# describe trends that augment the holdout system data. In this assignment, you can\n",
    "# imagine that historical trends for individual events, sequences of events, or\n",
    "# runners might be useful.\n",
    "\n",
    "# Here's an example, starting with our usual test/holdout data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "\n",
    "# We are going to regress on time\n",
    "df['x_result.duration.chip']=pd.to_timedelta(df['result.duration.chip']).astype(int)\n",
    "\n",
    "# For this demo we are going to use the sequence identifiers, let's look at a\n",
    "# couple I hand picked\n",
    "data=df.query('sequence_id in [\"5e862221-758c-48b1-a7cf-11bcc0a80a41\",\"57bdcd1f-a474-43e0-8e54-5f3a5206f5f9\"]')\n",
    "data.groupby(['sequence_id','event.id']).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c15e1036-c8c3-4ef0-be71-a6950220af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that these two sequences have historical event data, and different numbers of runners\n",
    "# so lets separate this into a training and validation set\n",
    "train=data.query(\"`event.id` in ['57bdcd1f-a474-43e0-8e54-5f3a5206f5f9', '5e862221-758c-48b1-a7cf-11bcc0a80a41']\")\n",
    "test=data.query(\"`event.id` not in ['57bdcd1f-a474-43e0-8e54-5f3a5206f5f9', '5e862221-758c-48b1-a7cf-11bcc0a80a41']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d896827-11b5-406c-97f7-9cc6224278f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequence_id\n",
       "57bdcd1f-a474-43e0-8e54-5f3a5206f5f9    0.320344\n",
       "5e862221-758c-48b1-a7cf-11bcc0a80a41    0.376289\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's say that I want to include in my pipeline the ratio of men to non-men\n",
    "# in the race. I can create that with the following:\n",
    "sequence_stats=train.groupby(['sequence_id','event.id']).apply(lambda x: sum(x['sex']=='Male')/len(x)).groupby(['sequence_id']).apply(np.mean)\n",
    "sequence_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6dcc6-8446-4a8a-b06e-fb28ebc08e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To embed this data in my pipeline, I need to add it to one of the steps - either\n",
    "# a transformer or an estimator - as an object. Then when this gets serialized as\n",
    "# part of the pickle process it will be there for estimation. Let's create a new\n",
    "# transformer which does this, our strategy will be that the __init__ function\n",
    "# will calculate our sequence stats data and store it in the object, while our\n",
    "# transform function will add that to unseen data as a column\n",
    "import numpy as np\n",
    "\n",
    "class SequenceSexRatio(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator):\n",
    "    \n",
    "    # this will be called when we first make our pipeline, so we can store things\n",
    "    def __init__(self, train):\n",
    "        # as we want to visualize this later we have to have something in the train\n",
    "        # attribute, which is the parameter to this function. I'll just make this the \n",
    "        # first row of the data coming in.\n",
    "        self.train=train.iloc[0]\n",
    "        \n",
    "        self.sequence_stats=train.groupby(['sequence_id','event.id']).apply(\n",
    "            lambda x: sum(x['sex']=='Male')/len(x)).groupby(['sequence_id']).apply(np.mean)\n",
    "        # you need to name a series in order to merge it later\n",
    "        self.sequence_stats.name='sex_sequence_ratio'\n",
    "    \n",
    "    # this does nothing interesting\n",
    "    def fit(self, data=None, y=None):\n",
    "        return self\n",
    "    \n",
    "    # this will be called when we want to predict our data, since it will transform\n",
    "    def transform(self, data):\n",
    "        # we can print out some diagnostics here, let's check how many sequences in the\n",
    "        # data we are trying to transform existing in our historical dataset\n",
    "        print(f'The number of sequences which are also in our historical data are {len(set(data[\"sequence_id\"].unique()).intersection(self.sequence_stats.index))}')\n",
    "        # align on index via a left join\n",
    "        newdata=pd.merge(data,self.sequence_stats,left_on='sequence_id',right_index=True,how='left')\n",
    "        # set our new sex_sequence_ratio column \n",
    "        data['SequenceSexRatio']=newdata['sex_sequence_ratio']\n",
    "        # return all of the data to the next stage of the pipeline\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305306c2-e31a-46c2-bd13-d9fe2d6f66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can build a little pipeline and use this column as a predictor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"SequenceSexRatio\", SequenceSexRatio(train)),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"sex\", OneHotEncoder(categories=[['Male','Female']], handle_unknown='ignore'), ['sex']),\n",
    "            ('cols_to_keep', 'passthrough', ['age','SequenceSexRatio']),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "        # this is our final estimator\n",
    "        (\"regressor\", LinearRegression())\n",
    "    ])\n",
    "\n",
    "# now let's visually inspect our pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "display(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765cb318-9d3a-4964-95cb-9cf3528eee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have a pipeline that will first add in our new column of data then\n",
    "# pass this on to the rest of the pipeline. Importantly, the new data is\n",
    "# added when we create the object, through the constructor, and is merged\n",
    "# with the data we are fitting to or predicting on when the transform()\n",
    "# function is called. Since the object is *not* created when we predict, and\n",
    "# instead is loaded through the pickle process, it means we can embed historical\n",
    "# data in the pipeline for use in the future.\n",
    "\n",
    "# We now have to fit out pipeline, this will just call the transform() and fit()\n",
    "# functions of the objects in the pipeline, but will not create new objects.\n",
    "fitted_pipe=pipe.fit(train, train['x_result.duration.chip'])\n",
    "\n",
    "# And we can take that final regression object and observe the coefficients\n",
    "# to verify that we have four, two for sex, one for sexsequenceratio, and\n",
    "# one age\n",
    "fitted_pipe.steps[-1][1].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2695e76d-885b-4319-9869-6a26ab68825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we can now try this on unseen data\n",
    "fitted_pipe.score(test, test['x_result.duration.chip'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
