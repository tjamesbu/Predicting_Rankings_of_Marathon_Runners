{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f3e326-86df-4288-9c12-1635ef31726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "preprocessor = StandardScaler()\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "#df = df['overall_ranking'].dropna()\n",
    "events=df['event.id'].unique()\n",
    "\n",
    "df.loc[df.query(\"`sex` not in ['Male','Female']\").index, 'sex']=0\n",
    "\n",
    "df.loc[df.query(\"`sex` == 'Male'\").index, 'sex']=2\n",
    "df.loc[df.query(\"`sex` == 'Female'\").index, 'sex']=1\n",
    "\n",
    "   \n",
    "df['clean_categories_run_count']=df['clean_categories.name'].replace({'15k':15, '5k':5, 'marathon':42.195, 'half marathon':21.0975, '10k':10, '5 mile':8.04672,\n",
    "'8k':8,'5k run':5, '3k walk':0, '10k run':10, 'youth mile':1.60934, '5k run/walk':5,\n",
    "       '5k walk':0, '5 mile run':8.04672, '1 mile run':1.60934, '15k run':15, '10k walk':0,\n",
    "       '6k run':6, '6k walk':0, '1 mile walk':0, '8k run':8, '8k walk':0,\n",
    "       '10 mile run':16.0934, '10 mile walk':0, '5 mile walk':0, '30k run':30,\n",
    "       '30k bike':0, '8 mile run':12.8748, '8 mile walk':0, 'bridge run':10,\n",
    "       'international half marathon':21.0975, 'u.s. only half marathon':21.0975, '1 mile':1.60934,\n",
    "       '5.7 mile run':9.17326, '5.7 mile walk':0, '5k competitive walk':0,\n",
    "       'half marathon run':21.0975, '5k fun walk':0, '5k wheelchair':0,\n",
    "       '1 mile fun run':1.60934, '2 mile run':3.21869, '2 mile walk':0, '4 mile run/walk':6.43738,\n",
    "       'life time commitment day 5k':5, 'midnight streak':5,\n",
    "       'commitment day 5k - master':5, 'quarter marathon':10.54875, '5k walk/run':5,\n",
    "       '1 mile fun run/walk':1.60934, 'one mile fun run':1.60934, '5 km run':5,\n",
    "       'fire fighter':42.195, 'olympic triathlon':10, 'sprint triathlon':10,\n",
    "       'olympic duathlon':10, 'sprint duathlon':10, '10k scenic challenge':10,\n",
    "       'run swim run':50, 'half marathon walk':0, 'mini-marathon':21.0975})\n",
    "\n",
    "df['clean_categories_walk_count']=df['clean_categories.name'].replace({'15k':0, '5k':0, 'marathon':0, 'half marathon':0, '10k':0, '5 mile':0,\n",
    "'8k':0,'5k run':0, '3k walk':3, '10k run':0, 'youth mile':0, '5k run/walk':0,\n",
    "       '5k walk':5, '5 mile run':0, '1 mile run':0, '15k run':0, '10k walk':10,\n",
    "       '6k run':0, '6k walk':6, '1 mile walk':1.60934, '8k run':0, '8k walk':8,\n",
    "       '10 mile run':0, '10 mile walk':16.0934, '5 mile walk':8.04672, '30k run':0,\n",
    "       '30k bike':0, '8 mile run':0, '8 mile walk':12.9748, 'bridge run':0,\n",
    "       'international half marathon':0, 'u.s. only half marathon':0, '1 mile':0,\n",
    "       '5.7 mile run':0, '5.7 mile walk':9.17326, '5k competitive walk':5,\n",
    "       'half marathon run':0, '5k fun walk':5, '5k wheelchair':0,\n",
    "       '1 mile fun run':0, '2 mile run':0, '2 mile walk':3.21869, '4 mile run/walk':0,\n",
    "       'life time commitment day 5k':0, 'midnight streak':0,\n",
    "       'commitment day 5k - master':0, 'quarter marathon':0, '5k walk/run':0,\n",
    "       '1 mile fun run/walk':0, 'one mile fun run':0, '5 km run':0,\n",
    "       'fire fighter':0, 'olympic triathlon':0, 'sprint triathlon':0,\n",
    "       'olympic duathlon':0, 'sprint duathlon':0, '10k scenic challenge':0,\n",
    "       'run swim run':0, 'half marathon walk':21.0975, 'mini-marathon':0})\n",
    "\n",
    "#walk_count = df['clean_categories_walk_count'].unique()\n",
    "#run_count = df['clean_categories_run_count'].unique()\n",
    "\n",
    "df.loc[df.query(\"`age` >= 119\").index, 'age']=np.nan\n",
    "df.loc[df.query(\"`age` <= 18\").index, 'age']=np.nan\n",
    "df.loc[df['age'] == 'nan', 'age'] = 38\n",
    "df['age']=df['age'].replace(np.nan,0)\n",
    "\n",
    "df['date'] = pd.to_datetime(df['event.date.start'])\n",
    "df['year'], df['month'] = df['date'].dt.year, df['date'].dt.month\n",
    "\n",
    "df['result.primary_bracket']=df['result.primary_bracket'].replace(['WHEELCHAIR','nan','Male 25-29','Male 40-44','Female 25-29','Female 20-24','wheelchair'],['Wheelchair','Overall','Male','Male','Female','Female','Wheelchair']) \n",
    "#df['result.primary_bracket1']=df['result.primary_bracket'].replace(['Wheelchair', 'Overall', 'nan', 'Male', 'Female'],[1,2,3,4,5])\n",
    "#df = df.dropna(subset = ['result.duration.chip'])\n",
    "\n",
    "#groups=pd.DataFrame(df.groupby([\"event.id\",\"clean_categories.name\"]).groups.keys(), columns=[\"event.id\",\"clean_categories.name\"])\n",
    "\n",
    "#train_set=events[100:]\n",
    "#holdout_set=events[0:100]\n",
    "\n",
    "#train_set=events[100:]\n",
    "#holdout_set=events[0:100]\n",
    "\n",
    "train_set = df[(df['year']==2018) | (df['year']==2017)] \n",
    "holdout_set = df[(df[\"year\"]==2016) | (df[\"year\"]==2015) | (df[\"year\"]==2014) | (df[\"year\"]==2013) | (df[\"year\"]==2012)]\n",
    "\n",
    "#test_set=events[200:300]\n",
    "\n",
    "train=df.query(\"`event.id` in @train_set\")\n",
    "#test=df.query(\"`event.id` in @test_set\")\n",
    "holdout=df.query(\"`event.id` in @holdout_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c5476a4-1db0-45e6-a654-202df4fce3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 126)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18766750-8d01-4cf3-9ca2-d372815b28f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout=holdout.drop(\n",
    "    columns=['time.end',\n",
    "             'body.results_certificate',\n",
    "             'event.results_posted',\n",
    "            'event.results_posted',\n",
    "             'event.results_certificate',\n",
    "             'event.photos_available',\n",
    "             'event.photos_faces',\n",
    "             'event.photos_social_sharing',\n",
    "             'event.results_searchable',\n",
    "             'corral.id',\n",
    "             'corral.name',\n",
    "             'corral.wave',\n",
    "             'corral.time.close',\n",
    "             'corral.time.start',\n",
    "             'result.duration.chip',\n",
    "             'result.duration.pace',\n",
    "             'result.rankings',\n",
    "             'result.splits',\n",
    "             'result.videos',\n",
    "             'result.finished',\n",
    "             'result.disqualified',\n",
    "             'result.duration'])\n",
    "\n",
    "# Also, I will garuntee in the holdout set there is data. At least 6 rows per race\n",
    "holdout=df.groupby([\"event.id\",\"clean_categories.name\"]).filter(lambda z: len(z)>5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0cf3e-92ed-4b4a-8ade-a8dae8c24ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28642e8f-918e-45c7-a885-6bf69d3fd3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['X_result.duration.pace'] = pd.to_timedelta(df['result.duration.pace']).astype(int)\n",
    "#df['X_result.duration.chip'] = pd.to_timedelta(df['result.duration.chip']).astype(int)\n",
    "#df['X_result.duration.chip']=df['X_result.duration.chip'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7009cc3-26ad-4c29-9091-0ef7fc6dea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_nan = df['result.duration.pace'].isnull().sum()\n",
    "check_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b4e21a6-0231-41b0-8822-fbdede5b2434",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.to_timedelta(train['result.duration.chip']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31899d78-968d-4e5d-ad65-d92cd35cd725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Use the autograder!\n",
    "\n",
    "# I gave you the autograder code, so a next great step is just to copy and paste\n",
    "# that in your notebook and get used to how it works.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "\n",
    "# This code simulates the autograder. It is not the full autograder implementation\n",
    "# but shares an API with the autograder. It expects that your fitted pipeline is\n",
    "# submitted with the name pipeline.cloudpickle as demonstrated above. This object\n",
    "# must implement the predict() function. This is done automatically by the sklearn\n",
    "# Pipeline object if the last element of your pipeline is a classifier which has\n",
    "# a predict() function. If you are not submitting a Pipeline, and want to do something\n",
    "# different, you *must* have a predict() function of the same method signature, e.g.:\n",
    "#\n",
    "#   predict(self, X, **predict_params)->np.ndarray\n",
    "\n",
    "# Load holdout data, in this case I'll simulate it by loading the training data\n",
    "#df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "\n",
    "# And evaluate on all 5k races that we didn't consider for training\n",
    "#holdout_data=df.query(\"`event.id`!='583f013a-1e54-4906-87f7-2b625206f5f9' and `clean_categories.name`=='5k'\")\n",
    "holdout_data=holdout\n",
    "\n",
    "# This is the scoring function to determine model fitness\n",
    "def score(left: pd.DataFrame, right: pd.DataFrame):\n",
    "    '''\n",
    "    Calculates the difference between the left and the right when considering rank of items. \n",
    "    This scoring function requires that the two DataFrames have identical indicies, and that\n",
    "    they each contain only one column of values and no missing values.\n",
    "    '''\n",
    "    assert(type(left)==pd.DataFrame)\n",
    "    assert(type(right)==pd.DataFrame)\n",
    "    assert(len(left)==len(right))\n",
    "    assert(not np.any(np.isnan(left)))\n",
    "    assert(not np.any(np.isnan(right)))\n",
    "    assert(left.index.equals(right.index))\n",
    "    # convert to ndarrays\n",
    "    left=left.squeeze()\n",
    "    right=right.squeeze()\n",
    "    return np.sum(np.abs(left-right))/(len(left)*(len(left)-1))\n",
    "\n",
    "# This function runs the prediction model agains a given event/category pair. It\n",
    "# intentionally loads the student model each time to avoid accidental leakage of data\n",
    "# between events.\n",
    "def evaluate(data, pipeline_file='pipeline.cloudpickle'):\n",
    "    # Load student pipeline\n",
    "    fitted_pipe = cloudpickle.load(open(pipeline_file,'rb'))\n",
    "    \n",
    "    # Separate out the X and y\n",
    "    X=list(set(data.columns)-{'overall_ranking'})\n",
    "    y=['overall_ranking']\n",
    "    \n",
    "    # Drop any missing results (DNFs)\n",
    "    data=data.dropna(subset=['overall_ranking'])\n",
    "    \n",
    "    # Ensure there is data to actually predict on\n",
    "    if len(data)==0:\n",
    "        return np.nan\n",
    "    \n",
    "    # Predict on unseen data\n",
    "    from IPython.utils import io\n",
    "    with io.capture_output() as captured:\n",
    "        predictions=pd.DataFrame(fitted_pipe.predict(data[X]),data.index)\n",
    "    observed=data[y]\n",
    "    \n",
    "    # Generate rankings within this bracket\n",
    "    observed=pd.DataFrame(data[y].rank(),data.index)\n",
    "\n",
    "    # Return the ratio of the student score\n",
    "    return pd.Series({\"score\":score(observed,predictions)})\n",
    "\n",
    "# Student solution\n",
    "pipeline_file='pipeline.cloudpickle'\n",
    "\n",
    "def autograde(holdout_data):\n",
    "    # Run prediction on each group\n",
    "    results=holdout_data.groupby([\"event.id\",\"clean_categories.name\"]).apply(evaluate, pipeline_file)\n",
    "\n",
    "    # Display the results, uncomment this for your own display\n",
    "    results.reset_index()['score'].plot.bar();\n",
    "\n",
    "    # This is the student final grade\n",
    "    print(np.average(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5f8487e-e31d-4827-a048-677703e33514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2017-12-03', '2018-12-02', '2018-01-07', '2018-03-18',\n",
       "       '2018-05-06', '2017-10-01', '2018-10-07', '2017-12-17',\n",
       "       '2018-12-16', '2018-02-04', '2017-06-04', '2017-09-09',\n",
       "       '2017-10-29', '2018-04-29', '2018-05-05', '2018-06-03',\n",
       "       '2018-06-07', '2018-06-21', '2018-06-23', '2018-09-08',\n",
       "       '2018-09-30', '2018-10-14', '2018-10-20', '2018-10-21',\n",
       "       '2018-11-04', '2018-11-22', '2018-12-31', '2018-03-24',\n",
       "       '2018-05-12', '2018-05-31', '2018-06-02', '2018-06-16',\n",
       "       '2018-06-17', '2018-06-30', '2018-07-14', '2018-07-15',\n",
       "       '2018-07-19', '2018-07-21', '2018-07-28', '2018-08-04',\n",
       "       '2018-08-11', '2018-08-16', '2018-08-19', '2018-08-25',\n",
       "       '2018-09-01', '2018-09-29', '2018-10-13', '2018-10-27',\n",
       "       '2018-11-23', '2018-04-14', '2017-12-10', '2018-12-09',\n",
       "       '2017-09-17', '2018-09-16', '2018-02-10', '2017-11-05',\n",
       "       '2018-06-01', '2018-07-27', '2018-09-03', '2018-10-06',\n",
       "       '2018-11-18', '2018-12-22', '2012-08-11', '2013-01-01',\n",
       "       '2013-08-10', '2014-09-27', '2015-01-01', '2015-08-15',\n",
       "       '2015-09-26', '2015-12-12', '2016-03-12', '2016-08-20',\n",
       "       '2016-08-27', '2016-10-02', '2016-10-22', '2016-12-10',\n",
       "       '2017-03-11', '2017-08-26', '2017-09-16', '2017-09-23',\n",
       "       '2017-09-30', '2017-10-28', '2018-03-31', '2018-09-15',\n",
       "       '2018-11-03', '2018-11-17', '2018-12-01', '2018-09-23',\n",
       "       '2018-04-07', '2018-02-17', '2018-01-28', '2018-02-03',\n",
       "       '2016-03-26', '2016-07-16', '2017-03-25', '2017-06-10',\n",
       "       '2017-07-15', '2018-06-09', '2018-06-10', '2018-03-04',\n",
       "       '2018-08-18', '2018-09-22'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['event.date.start'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba5620e6-f704-4d17-b95f-e2891af8746d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['event.date.start'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4e05f08-e121-4c65-88ed-e65fed1e1fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lineage.event_series.id</th>\n",
       "      <th>lineage.event_series.name</th>\n",
       "      <th>lineage.previous_event.id</th>\n",
       "      <th>lineage.previous_event.name</th>\n",
       "      <th>lineage.previous_event.slug</th>\n",
       "      <th>location.name</th>\n",
       "      <th>location.city</th>\n",
       "      <th>location.state</th>\n",
       "      <th>location.zip</th>\n",
       "      <th>location.country_name</th>\n",
       "      <th>location.country_code</th>\n",
       "      <th>location.coordinates.latitude</th>\n",
       "      <th>location.coordinates.longitude</th>\n",
       "      <th>counts.participants.expected</th>\n",
       "      <th>counts.participants.registered</th>\n",
       "      <th>counts.participants.limit</th>\n",
       "      <th>fundraising.description</th>\n",
       "      <th>fundraising.goal</th>\n",
       "      <th>fundraising.status</th>\n",
       "      <th>fundraising.organizations</th>\n",
       "      <th>fundraising.default_organization.id</th>\n",
       "      <th>fundraising.default_organization.name</th>\n",
       "      <th>time.start</th>\n",
       "      <th>time.end</th>\n",
       "      <th>categories.name</th>\n",
       "      <th>body.id</th>\n",
       "      <th>body.name</th>\n",
       "      <th>body.results_certificate</th>\n",
       "      <th>body.timezone</th>\n",
       "      <th>body.type</th>\n",
       "      <th>body.slug</th>\n",
       "      <th>brackets.id</th>\n",
       "      <th>brackets.name</th>\n",
       "      <th>brackets.type</th>\n",
       "      <th>clean_categories.name</th>\n",
       "      <th>id</th>\n",
       "      <th>registrant_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>confirmation_number</th>\n",
       "      <th>registration_status</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bib</th>\n",
       "      <th>checkin_time</th>\n",
       "      <th>coupon</th>\n",
       "      <th>coupon_type</th>\n",
       "      <th>price</th>\n",
       "      <th>created</th>\n",
       "      <th>modified</th>\n",
       "      <th>completed</th>\n",
       "      <th>shipments</th>\n",
       "      <th>hometown</th>\n",
       "      <th>event.id</th>\n",
       "      <th>event.name</th>\n",
       "      <th>event.date.start</th>\n",
       "      <th>event.date.end</th>\n",
       "      <th>event.tenant.id</th>\n",
       "      <th>event.tenant.name</th>\n",
       "      <th>event.timezone</th>\n",
       "      <th>event.location.name</th>\n",
       "      <th>event.location.zip</th>\n",
       "      <th>event.location.coordinates.latitude</th>\n",
       "      <th>event.location.coordinates.longitude</th>\n",
       "      <th>event.images.hub.header</th>\n",
       "      <th>event.images.email.header</th>\n",
       "      <th>event.images.email.footer</th>\n",
       "      <th>event.images.logo</th>\n",
       "      <th>event.description</th>\n",
       "      <th>event.sections</th>\n",
       "      <th>event.results_posted</th>\n",
       "      <th>event.results_certificate</th>\n",
       "      <th>event.photos_available</th>\n",
       "      <th>event.photos_faces</th>\n",
       "      <th>event.photos_social_sharing</th>\n",
       "      <th>event.results_searchable</th>\n",
       "      <th>event.no_bib</th>\n",
       "      <th>event.color</th>\n",
       "      <th>event.sidebar</th>\n",
       "      <th>event.sidebar_elements</th>\n",
       "      <th>event.sharing.twitter.default_text</th>\n",
       "      <th>event.sharing.facebook.default_text</th>\n",
       "      <th>event.sharing.email.default_subject</th>\n",
       "      <th>event.sharing.email.default_body</th>\n",
       "      <th>category.registered.id</th>\n",
       "      <th>category.registered.name</th>\n",
       "      <th>category.registered.date</th>\n",
       "      <th>category.registered.distance.quantity</th>\n",
       "      <th>category.registered.distance.unit</th>\n",
       "      <th>category.registered.distance.name</th>\n",
       "      <th>category.registered.results_log_allow</th>\n",
       "      <th>category.registered.user_photo_upload_allow</th>\n",
       "      <th>category.completed.id</th>\n",
       "      <th>category.completed.name</th>\n",
       "      <th>category.completed.date</th>\n",
       "      <th>category.completed.distance.quantity</th>\n",
       "      <th>category.completed.distance.unit</th>\n",
       "      <th>category.completed.distance.name</th>\n",
       "      <th>corral.id</th>\n",
       "      <th>corral.name</th>\n",
       "      <th>corral.wave</th>\n",
       "      <th>corral.time.close</th>\n",
       "      <th>corral.time.start</th>\n",
       "      <th>team.id</th>\n",
       "      <th>team.name</th>\n",
       "      <th>team.bib</th>\n",
       "      <th>result.provider</th>\n",
       "      <th>result.hometown</th>\n",
       "      <th>result.race_name</th>\n",
       "      <th>result.primary_bracket</th>\n",
       "      <th>result.category_id</th>\n",
       "      <th>result.duration.chip</th>\n",
       "      <th>result.duration.pace</th>\n",
       "      <th>result.rankings</th>\n",
       "      <th>result.splits</th>\n",
       "      <th>result.videos</th>\n",
       "      <th>result.finished</th>\n",
       "      <th>result.disqualified</th>\n",
       "      <th>result.duration</th>\n",
       "      <th>photo</th>\n",
       "      <th>event.race.id</th>\n",
       "      <th>clean_category.completed.name</th>\n",
       "      <th>clean_category.registered.name</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>overall_ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4d7f441a-4fbc-4a3e-b0d1-4e1b7f000001</td>\n",
       "      <td>Hot Chocolate 15K/5K</td>\n",
       "      <td>56156dc5-e744-40c5-b2ae-5fc0c0a86526</td>\n",
       "      <td>2016 Hot Chocolate 15K/5K - Scottsdale</td>\n",
       "      <td>2016-hot-chocolate-15k-5k-scottsdale</td>\n",
       "      <td>Scottsdale, AZ</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9200</td>\n",
       "      <td>9716</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;Our mission at RAM Racing is not only to ra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>[{'id': '5939a2d0-c3b0-43ad-965e-5d915206f5f9'...</td>\n",
       "      <td>5939a2d0-c3b0-43ad-965e-5d915206f5f9</td>\n",
       "      <td>Make-A-WishÂ®</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15k</td>\n",
       "      <td>583f013a-1e54-4906-87f7-2b625206f5f9</td>\n",
       "      <td>2017 Hot Chocolate 15k/5k - Scottsdale</td>\n",
       "      <td>False</td>\n",
       "      <td>America/Boise</td>\n",
       "      <td>Run</td>\n",
       "      <td>2017-hot-chocolate-15k-5k-scottsdale</td>\n",
       "      <td>5bc540b0-7370-41c9-98e5-1aa55206f5f9</td>\n",
       "      <td>Overall</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>15k</td>\n",
       "      <td>57225834-0724-455d-9f96-54365206f5f9</td>\n",
       "      <td>51016889-9ac4-44b6-af81-3dfcc0a86524</td>\n",
       "      <td>51016889-4b64-42d5-9f8f-3dfcc0a86524</td>\n",
       "      <td>awrhqcsz</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Rakhi</td>\n",
       "      <td>Batra</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>52038.0</td>\n",
       "      <td>2017-12-02 11:48:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2016-04-28 13:36:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-04-28 13:39:36</td>\n",
       "      <td>[]</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>583f013a-1e54-4906-87f7-2b625206f5f9</td>\n",
       "      <td>2017 Hot Chocolate 15k/5k - Scottsdale</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7f47b47a-262d-4ae6-b14d-9b15ffc1020c</td>\n",
       "      <td>Ventures Endurance</td>\n",
       "      <td>America/Boise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>Join the movement that's taken over the racing...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#f8a138</td>\n",
       "      <td>&lt;ul class=\"sponsors\"&gt;&lt;li&gt;&lt;a href=\"https://nuun...</td>\n",
       "      <td>[{'id': 'sidebar_5b75040fa1951', 'section_type...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>583f013a-16bc-4212-9659-2b625206f5f9</td>\n",
       "      <td>15k</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>15.0</td>\n",
       "      <td>km</td>\n",
       "      <td>15K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5bc540af-23fc-497f-98e3-1aa55206f5f9</td>\n",
       "      <td>15k</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>15.0</td>\n",
       "      <td>km</td>\n",
       "      <td>15K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>15k</td>\n",
       "      <td>Overall</td>\n",
       "      <td>5bc540af-23fc-497f-98e3-1aa55206f5f9</td>\n",
       "      <td>01:51:13</td>\n",
       "      <td>00:11:56</td>\n",
       "      <td>[{'order': '1', 'name': 'Overall', 'rank': '2,...</td>\n",
       "      <td>[{'name': '5K', 'time': '00:33:21', 'pace': '1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15k</td>\n",
       "      <td>15k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4d7f441a-4fbc-4a3e-b0d1-4e1b7f000001</td>\n",
       "      <td>Hot Chocolate 15K/5K</td>\n",
       "      <td>56156dc5-e744-40c5-b2ae-5fc0c0a86526</td>\n",
       "      <td>2016 Hot Chocolate 15K/5K - Scottsdale</td>\n",
       "      <td>2016-hot-chocolate-15k-5k-scottsdale</td>\n",
       "      <td>Scottsdale, AZ</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9200</td>\n",
       "      <td>9716</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;Our mission at RAM Racing is not only to ra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>[{'id': '5939a2d0-c3b0-43ad-965e-5d915206f5f9'...</td>\n",
       "      <td>5939a2d0-c3b0-43ad-965e-5d915206f5f9</td>\n",
       "      <td>Make-A-WishÂ®</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15k</td>\n",
       "      <td>583f013a-1e54-4906-87f7-2b625206f5f9</td>\n",
       "      <td>2017 Hot Chocolate 15k/5k - Scottsdale</td>\n",
       "      <td>False</td>\n",
       "      <td>America/Boise</td>\n",
       "      <td>Run</td>\n",
       "      <td>2017-hot-chocolate-15k-5k-scottsdale</td>\n",
       "      <td>5bc540b0-7370-41c9-98e5-1aa55206f5f9</td>\n",
       "      <td>Overall</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>15k</td>\n",
       "      <td>572258a1-2858-48cb-a631-54365206f5f9</td>\n",
       "      <td>543efa86-c11c-49bd-b3c3-7756c0a86526</td>\n",
       "      <td>51016889-4b64-42d5-9f8f-3dfcc0a86524</td>\n",
       "      <td>qcludofk</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Harsha</td>\n",
       "      <td>Vardhan</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>52039.0</td>\n",
       "      <td>2017-12-02 11:49:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2016-04-28 13:38:25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-04-28 13:39:37</td>\n",
       "      <td>[]</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>583f013a-1e54-4906-87f7-2b625206f5f9</td>\n",
       "      <td>2017 Hot Chocolate 15k/5k - Scottsdale</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7f47b47a-262d-4ae6-b14d-9b15ffc1020c</td>\n",
       "      <td>Ventures Endurance</td>\n",
       "      <td>America/Boise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>Join the movement that's taken over the racing...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#f8a138</td>\n",
       "      <td>&lt;ul class=\"sponsors\"&gt;&lt;li&gt;&lt;a href=\"https://nuun...</td>\n",
       "      <td>[{'id': 'sidebar_5b75040fa1951', 'section_type...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>583f013a-16bc-4212-9659-2b625206f5f9</td>\n",
       "      <td>15k</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>15.0</td>\n",
       "      <td>km</td>\n",
       "      <td>15K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5bc540af-23fc-497f-98e3-1aa55206f5f9</td>\n",
       "      <td>15k</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>15.0</td>\n",
       "      <td>km</td>\n",
       "      <td>15K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>15k</td>\n",
       "      <td>Overall</td>\n",
       "      <td>5bc540af-23fc-497f-98e3-1aa55206f5f9</td>\n",
       "      <td>01:37:40</td>\n",
       "      <td>00:10:29</td>\n",
       "      <td>[{'order': '1', 'name': 'Overall', 'rank': '1,...</td>\n",
       "      <td>[{'name': '5K', 'time': '00:29:19', 'pace': '0...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15k</td>\n",
       "      <td>15k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4d7f441a-4fbc-4a3e-b0d1-4e1b7f000001</td>\n",
       "      <td>Hot Chocolate 15K/5K</td>\n",
       "      <td>56156dc5-e744-40c5-b2ae-5fc0c0a86526</td>\n",
       "      <td>2016 Hot Chocolate 15K/5K - Scottsdale</td>\n",
       "      <td>2016-hot-chocolate-15k-5k-scottsdale</td>\n",
       "      <td>Scottsdale, AZ</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9200</td>\n",
       "      <td>9716</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;Our mission at RAM Racing is not only to ra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>[{'id': '5939a2d0-c3b0-43ad-965e-5d915206f5f9'...</td>\n",
       "      <td>5939a2d0-c3b0-43ad-965e-5d915206f5f9</td>\n",
       "      <td>Make-A-WishÂ®</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15k</td>\n",
       "      <td>583f013a-1e54-4906-87f7-2b625206f5f9</td>\n",
       "      <td>2017 Hot Chocolate 15k/5k - Scottsdale</td>\n",
       "      <td>False</td>\n",
       "      <td>America/Boise</td>\n",
       "      <td>Run</td>\n",
       "      <td>2017-hot-chocolate-15k-5k-scottsdale</td>\n",
       "      <td>5bc540b0-7370-41c9-98e5-1aa55206f5f9</td>\n",
       "      <td>Overall</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>15k</td>\n",
       "      <td>575312c2-b73c-484a-9cf7-5af15206f5f9</td>\n",
       "      <td>54bd1e41-0d84-47ba-beb1-7fafc0a86526</td>\n",
       "      <td>54bd1e41-a028-444d-a6bd-7fafc0a86526</td>\n",
       "      <td>phcncuav</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Christie</td>\n",
       "      <td>Casuga-Nguyen</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>52770.0</td>\n",
       "      <td>2017-12-02 17:10:53</td>\n",
       "      <td>RNRSDLEIA</td>\n",
       "      <td>buff</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2016-06-04 12:41:22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-04 12:44:14</td>\n",
       "      <td>[]</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>583f013a-1e54-4906-87f7-2b625206f5f9</td>\n",
       "      <td>2017 Hot Chocolate 15k/5k - Scottsdale</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7f47b47a-262d-4ae6-b14d-9b15ffc1020c</td>\n",
       "      <td>Ventures Endurance</td>\n",
       "      <td>America/Boise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>Join the movement that's taken over the racing...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#f8a138</td>\n",
       "      <td>&lt;ul class=\"sponsors\"&gt;&lt;li&gt;&lt;a href=\"https://nuun...</td>\n",
       "      <td>[{'id': 'sidebar_5b75040fa1951', 'section_type...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>583f013a-16bc-4212-9659-2b625206f5f9</td>\n",
       "      <td>15k</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>15.0</td>\n",
       "      <td>km</td>\n",
       "      <td>15K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5bc540af-23fc-497f-98e3-1aa55206f5f9</td>\n",
       "      <td>15k</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>15.0</td>\n",
       "      <td>km</td>\n",
       "      <td>15K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>15k</td>\n",
       "      <td>Overall</td>\n",
       "      <td>5bc540af-23fc-497f-98e3-1aa55206f5f9</td>\n",
       "      <td>02:18:00</td>\n",
       "      <td>00:14:49</td>\n",
       "      <td>[{'order': '1', 'name': 'Overall', 'rank': '3,...</td>\n",
       "      <td>[{'name': '5K', 'time': '00:43:45', 'pace': '1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15k</td>\n",
       "      <td>15k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3084.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4d7f441a-4fbc-4a3e-b0d1-4e1b7f000001</td>\n",
       "      <td>Hot Chocolate 15K/5K</td>\n",
       "      <td>56156dc5-e744-40c5-b2ae-5fc0c0a86526</td>\n",
       "      <td>2016 Hot Chocolate 15K/5K - Scottsdale</td>\n",
       "      <td>2016-hot-chocolate-15k-5k-scottsdale</td>\n",
       "      <td>Scottsdale, AZ</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9200</td>\n",
       "      <td>9716</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;Our mission at RAM Racing is not only to ra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>[{'id': '5939a2d0-c3b0-43ad-965e-5d915206f5f9'...</td>\n",
       "      <td>5939a2d0-c3b0-43ad-965e-5d915206f5f9</td>\n",
       "      <td>Make-A-WishÂ®</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15k</td>\n",
       "      <td>583f013a-1e54-4906-87f7-2b625206f5f9</td>\n",
       "      <td>2017 Hot Chocolate 15k/5k - Scottsdale</td>\n",
       "      <td>False</td>\n",
       "      <td>America/Boise</td>\n",
       "      <td>Run</td>\n",
       "      <td>2017-hot-chocolate-15k-5k-scottsdale</td>\n",
       "      <td>5bc540b0-7370-41c9-98e5-1aa55206f5f9</td>\n",
       "      <td>Overall</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>15k</td>\n",
       "      <td>575312c9-8f24-4b1c-93f1-5a8b5206f5f9</td>\n",
       "      <td>54bf4092-3bcc-4155-bbcb-444cc0a86526</td>\n",
       "      <td>54bf4092-5690-4bfb-a8c7-444cc0a86526</td>\n",
       "      <td>tlcbsjsi</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Maldonado</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>53594.0</td>\n",
       "      <td>2017-12-02 17:10:40</td>\n",
       "      <td>RNRSDLEIA</td>\n",
       "      <td>buff</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2016-06-04 12:41:29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-04 12:44:09</td>\n",
       "      <td>[]</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>583f013a-1e54-4906-87f7-2b625206f5f9</td>\n",
       "      <td>2017 Hot Chocolate 15k/5k - Scottsdale</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7f47b47a-262d-4ae6-b14d-9b15ffc1020c</td>\n",
       "      <td>Ventures Endurance</td>\n",
       "      <td>America/Boise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>Join the movement that's taken over the racing...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#f8a138</td>\n",
       "      <td>&lt;ul class=\"sponsors\"&gt;&lt;li&gt;&lt;a href=\"https://nuun...</td>\n",
       "      <td>[{'id': 'sidebar_5b75040fa1951', 'section_type...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>583f013a-16bc-4212-9659-2b625206f5f9</td>\n",
       "      <td>15k</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>15.0</td>\n",
       "      <td>km</td>\n",
       "      <td>15K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5bc540af-23fc-497f-98e3-1aa55206f5f9</td>\n",
       "      <td>15k</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>15.0</td>\n",
       "      <td>km</td>\n",
       "      <td>15K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>15k</td>\n",
       "      <td>Overall</td>\n",
       "      <td>5bc540af-23fc-497f-98e3-1aa55206f5f9</td>\n",
       "      <td>02:18:01</td>\n",
       "      <td>00:14:49</td>\n",
       "      <td>[{'order': '1', 'name': 'Overall', 'rank': '3,...</td>\n",
       "      <td>[{'name': '5K', 'time': '00:43:46', 'pace': '1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15k</td>\n",
       "      <td>15k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3085.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4d7f441a-4fbc-4a3e-b0d1-4e1b7f000001</td>\n",
       "      <td>Hot Chocolate 15K/5K</td>\n",
       "      <td>56156dc5-e744-40c5-b2ae-5fc0c0a86526</td>\n",
       "      <td>2016 Hot Chocolate 15K/5K - Scottsdale</td>\n",
       "      <td>2016-hot-chocolate-15k-5k-scottsdale</td>\n",
       "      <td>Scottsdale, AZ</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9200</td>\n",
       "      <td>9716</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;Our mission at RAM Racing is not only to ra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>[{'id': '5939a2d0-c3b0-43ad-965e-5d915206f5f9'...</td>\n",
       "      <td>5939a2d0-c3b0-43ad-965e-5d915206f5f9</td>\n",
       "      <td>Make-A-WishÂ®</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15k</td>\n",
       "      <td>583f013a-1e54-4906-87f7-2b625206f5f9</td>\n",
       "      <td>2017 Hot Chocolate 15k/5k - Scottsdale</td>\n",
       "      <td>False</td>\n",
       "      <td>America/Boise</td>\n",
       "      <td>Run</td>\n",
       "      <td>2017-hot-chocolate-15k-5k-scottsdale</td>\n",
       "      <td>5bc540b0-7370-41c9-98e5-1aa55206f5f9</td>\n",
       "      <td>Overall</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>15k</td>\n",
       "      <td>58082a0c-9ea8-4dbb-bb52-53b15206f5f9</td>\n",
       "      <td>58082a43-2594-4fa6-bbd8-53655206f5f9</td>\n",
       "      <td>58082a43-4f0c-4c87-9f48-53655206f5f9</td>\n",
       "      <td>yisfpkrj</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Cristina</td>\n",
       "      <td>Verdugo</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>51166.0</td>\n",
       "      <td>2017-11-14 13:50:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2016-10-19 21:21:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-19 21:31:21</td>\n",
       "      <td>[{'carrier': 'stampscom_usps', 'tracking_numbe...</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>583f013a-1e54-4906-87f7-2b625206f5f9</td>\n",
       "      <td>2017 Hot Chocolate 15k/5k - Scottsdale</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7f47b47a-262d-4ae6-b14d-9b15ffc1020c</td>\n",
       "      <td>Ventures Endurance</td>\n",
       "      <td>America/Boise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>Join the movement that's taken over the racing...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#f8a138</td>\n",
       "      <td>&lt;ul class=\"sponsors\"&gt;&lt;li&gt;&lt;a href=\"https://nuun...</td>\n",
       "      <td>[{'id': 'sidebar_5b75040fa1951', 'section_type...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...</td>\n",
       "      <td>583f013a-16bc-4212-9659-2b625206f5f9</td>\n",
       "      <td>15k</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>15.0</td>\n",
       "      <td>km</td>\n",
       "      <td>15K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5bc540af-23fc-497f-98e3-1aa55206f5f9</td>\n",
       "      <td>15k</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>15.0</td>\n",
       "      <td>km</td>\n",
       "      <td>15K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>15k</td>\n",
       "      <td>Overall</td>\n",
       "      <td>5bc540af-23fc-497f-98e3-1aa55206f5f9</td>\n",
       "      <td>01:35:45</td>\n",
       "      <td>00:10:17</td>\n",
       "      <td>[{'order': '1', 'name': 'Overall', 'rank': '1,...</td>\n",
       "      <td>[{'name': '5K', 'time': '00:30:06', 'pace': '0...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15k</td>\n",
       "      <td>15k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1241.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293528</th>\n",
       "      <td>599c4cc7-e910-45d2-9706-4cbe5206f5f9</td>\n",
       "      <td>Brewers Mini-Marathon</td>\n",
       "      <td>599c4cc7-b584-4507-bc54-4cbe5206f5f9</td>\n",
       "      <td>2017 Brewers Mini-Marathon</td>\n",
       "      <td>2017-brewers-mini-marathon</td>\n",
       "      <td>Milwaukee, WI</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>WI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4500</td>\n",
       "      <td>4747</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5K</td>\n",
       "      <td>5b7ae951-7e04-4262-a599-2f745206f5f9</td>\n",
       "      <td>2018 Brewers Mini-Marathon</td>\n",
       "      <td>1</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>Run</td>\n",
       "      <td>2018-brewers-mini-marathon</td>\n",
       "      <td>5ba47ae9-73d4-4dcf-a041-21495206f5f9</td>\n",
       "      <td>Overall</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>5k</td>\n",
       "      <td>5ba5a4c0-82d8-433e-bb08-3ae25206f5f9</td>\n",
       "      <td>5ba5a4c0-0728-4036-8abe-3ae25206f5f9</td>\n",
       "      <td>5ba5a4c0-c3ac-42d1-a9d6-3ae25206f5f9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Matt</td>\n",
       "      <td>Kinnard</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>5349.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-09-21 21:11:12</td>\n",
       "      <td>2018-09-21 21:11:12</td>\n",
       "      <td>2018-09-21 18:11:19</td>\n",
       "      <td>[]</td>\n",
       "      <td>New Franken, WI</td>\n",
       "      <td>5b7ae951-7e04-4262-a599-2f745206f5f9</td>\n",
       "      <td>2018 Brewers Mini-Marathon</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5b75b173-717c-4344-a5f6-7d325206f5f9</td>\n",
       "      <td>Milwaukee Brewers Baseball Club</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>The 7th annual Brewers Mini-Marathon returns o...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#f8a138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>I ran the 2018 Brewers Mini-Marathon today!!  ...</td>\n",
       "      <td>I ran the 2018 Brewers Mini-Marathon today!!  ...</td>\n",
       "      <td>Check out my results from the 2018 Brewers Min...</td>\n",
       "      <td>I ran the 2018 Brewers Mini-Marathon today!!  ...</td>\n",
       "      <td>5b7ae951-8164-4e97-b024-2f745206f5f9</td>\n",
       "      <td>5K</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>km</td>\n",
       "      <td>5K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5ba47ae8-5ed4-4539-9bd0-21495206f5f9</td>\n",
       "      <td>5K</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>km</td>\n",
       "      <td>5K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>New Franken, WI</td>\n",
       "      <td>5K</td>\n",
       "      <td>Overall</td>\n",
       "      <td>5ba47ae8-5ed4-4539-9bd0-21495206f5f9</td>\n",
       "      <td>00:28:53</td>\n",
       "      <td>00:09:18</td>\n",
       "      <td>[{'order': '1', 'name': 'Overall', 'rank': '21...</td>\n",
       "      <td>[{'name': 'Full Course', 'time': '00:28:53', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5k</td>\n",
       "      <td>5k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293529</th>\n",
       "      <td>599c4cc7-e910-45d2-9706-4cbe5206f5f9</td>\n",
       "      <td>Brewers Mini-Marathon</td>\n",
       "      <td>599c4cc7-b584-4507-bc54-4cbe5206f5f9</td>\n",
       "      <td>2017 Brewers Mini-Marathon</td>\n",
       "      <td>2017-brewers-mini-marathon</td>\n",
       "      <td>Milwaukee, WI</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>WI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4500</td>\n",
       "      <td>4747</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5K</td>\n",
       "      <td>5b7ae951-7e04-4262-a599-2f745206f5f9</td>\n",
       "      <td>2018 Brewers Mini-Marathon</td>\n",
       "      <td>1</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>Run</td>\n",
       "      <td>2018-brewers-mini-marathon</td>\n",
       "      <td>5ba47ae9-73d4-4dcf-a041-21495206f5f9</td>\n",
       "      <td>Overall</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>5k</td>\n",
       "      <td>5ba5a4c0-8764-4016-8267-3ae25206f5f9</td>\n",
       "      <td>581104a6-1900-49f3-97a1-715c5206f5f9</td>\n",
       "      <td>581104a6-ceb4-4f5e-9b27-715c5206f5f9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Audrey</td>\n",
       "      <td>Harwood</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>5362.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-09-21 21:11:12</td>\n",
       "      <td>2018-09-21 21:11:12</td>\n",
       "      <td>2018-09-21 21:11:12</td>\n",
       "      <td>[]</td>\n",
       "      <td>Palatine, IL</td>\n",
       "      <td>5b7ae951-7e04-4262-a599-2f745206f5f9</td>\n",
       "      <td>2018 Brewers Mini-Marathon</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5b75b173-717c-4344-a5f6-7d325206f5f9</td>\n",
       "      <td>Milwaukee Brewers Baseball Club</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>The 7th annual Brewers Mini-Marathon returns o...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#f8a138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>I ran the 2018 Brewers Mini-Marathon today!!  ...</td>\n",
       "      <td>I ran the 2018 Brewers Mini-Marathon today!!  ...</td>\n",
       "      <td>Check out my results from the 2018 Brewers Min...</td>\n",
       "      <td>I ran the 2018 Brewers Mini-Marathon today!!  ...</td>\n",
       "      <td>5b7ae951-8164-4e97-b024-2f745206f5f9</td>\n",
       "      <td>5K</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>km</td>\n",
       "      <td>5K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5ba47ae8-5ed4-4539-9bd0-21495206f5f9</td>\n",
       "      <td>5K</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>km</td>\n",
       "      <td>5K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Palatine, IL</td>\n",
       "      <td>5K</td>\n",
       "      <td>Overall</td>\n",
       "      <td>5ba47ae8-5ed4-4539-9bd0-21495206f5f9</td>\n",
       "      <td>00:30:46</td>\n",
       "      <td>00:09:54</td>\n",
       "      <td>[{'order': '1', 'name': 'Overall', 'rank': '33...</td>\n",
       "      <td>[{'name': 'Full Course', 'time': '00:30:46', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5k</td>\n",
       "      <td>5k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293530</th>\n",
       "      <td>599c4cc7-e910-45d2-9706-4cbe5206f5f9</td>\n",
       "      <td>Brewers Mini-Marathon</td>\n",
       "      <td>599c4cc7-b584-4507-bc54-4cbe5206f5f9</td>\n",
       "      <td>2017 Brewers Mini-Marathon</td>\n",
       "      <td>2017-brewers-mini-marathon</td>\n",
       "      <td>Milwaukee, WI</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>WI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4500</td>\n",
       "      <td>4747</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5K</td>\n",
       "      <td>5b7ae951-7e04-4262-a599-2f745206f5f9</td>\n",
       "      <td>2018 Brewers Mini-Marathon</td>\n",
       "      <td>1</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>Run</td>\n",
       "      <td>2018-brewers-mini-marathon</td>\n",
       "      <td>5ba47ae9-73d4-4dcf-a041-21495206f5f9</td>\n",
       "      <td>Overall</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>5k</td>\n",
       "      <td>5ba5a4c0-a08c-4134-a0cf-3ae25206f5f9</td>\n",
       "      <td>5ba5a4bf-f048-40bb-bd4d-3ae25206f5f9</td>\n",
       "      <td>5ba5a4bf-1cd4-4ca8-bbdd-3ae25206f5f9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Richard</td>\n",
       "      <td>Hombsch</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>5346.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-09-21 21:11:12</td>\n",
       "      <td>2018-09-21 21:11:12</td>\n",
       "      <td>2018-09-21 17:51:08</td>\n",
       "      <td>[]</td>\n",
       "      <td>Milwaukee, WI</td>\n",
       "      <td>5b7ae951-7e04-4262-a599-2f745206f5f9</td>\n",
       "      <td>2018 Brewers Mini-Marathon</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5b75b173-717c-4344-a5f6-7d325206f5f9</td>\n",
       "      <td>Milwaukee Brewers Baseball Club</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>The 7th annual Brewers Mini-Marathon returns o...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#f8a138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>I ran the 2018 Brewers Mini-Marathon today!!  ...</td>\n",
       "      <td>I ran the 2018 Brewers Mini-Marathon today!!  ...</td>\n",
       "      <td>Check out my results from the 2018 Brewers Min...</td>\n",
       "      <td>I ran the 2018 Brewers Mini-Marathon today!!  ...</td>\n",
       "      <td>5b7ae951-8164-4e97-b024-2f745206f5f9</td>\n",
       "      <td>5K</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>km</td>\n",
       "      <td>5K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5ba47ae8-5ed4-4539-9bd0-21495206f5f9</td>\n",
       "      <td>5K</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>km</td>\n",
       "      <td>5K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Milwaukee, WI</td>\n",
       "      <td>5K</td>\n",
       "      <td>Overall</td>\n",
       "      <td>5ba47ae8-5ed4-4539-9bd0-21495206f5f9</td>\n",
       "      <td>00:31:14</td>\n",
       "      <td>00:10:03</td>\n",
       "      <td>[{'order': '1', 'name': 'Overall', 'rank': '35...</td>\n",
       "      <td>[{'name': 'Full Course', 'time': '00:31:14', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5k</td>\n",
       "      <td>5k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293531</th>\n",
       "      <td>599c4cc7-e910-45d2-9706-4cbe5206f5f9</td>\n",
       "      <td>Brewers Mini-Marathon</td>\n",
       "      <td>599c4cc7-b584-4507-bc54-4cbe5206f5f9</td>\n",
       "      <td>2017 Brewers Mini-Marathon</td>\n",
       "      <td>2017-brewers-mini-marathon</td>\n",
       "      <td>Milwaukee, WI</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>WI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4500</td>\n",
       "      <td>4747</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5K</td>\n",
       "      <td>5b7ae951-7e04-4262-a599-2f745206f5f9</td>\n",
       "      <td>2018 Brewers Mini-Marathon</td>\n",
       "      <td>1</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>Run</td>\n",
       "      <td>2018-brewers-mini-marathon</td>\n",
       "      <td>5ba47ae9-73d4-4dcf-a041-21495206f5f9</td>\n",
       "      <td>Overall</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>5k</td>\n",
       "      <td>5ba5a4c0-de84-4e49-a0aa-3ae25206f5f9</td>\n",
       "      <td>5ba5a4c0-2f0c-4b68-9073-3ae25206f5f9</td>\n",
       "      <td>523000ba-ba24-431b-a94b-70bdc0a86524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Trista</td>\n",
       "      <td>Tolkacz</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>5352.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-09-21 21:11:12</td>\n",
       "      <td>2018-09-21 21:11:12</td>\n",
       "      <td>2018-09-21 18:30:30</td>\n",
       "      <td>[]</td>\n",
       "      <td>South Milwaukee, WI</td>\n",
       "      <td>5b7ae951-7e04-4262-a599-2f745206f5f9</td>\n",
       "      <td>2018 Brewers Mini-Marathon</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5b75b173-717c-4344-a5f6-7d325206f5f9</td>\n",
       "      <td>Milwaukee Brewers Baseball Club</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>The 7th annual Brewers Mini-Marathon returns o...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#f8a138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>I ran the 2018 Brewers Mini-Marathon today!!  ...</td>\n",
       "      <td>I ran the 2018 Brewers Mini-Marathon today!!  ...</td>\n",
       "      <td>Check out my results from the 2018 Brewers Min...</td>\n",
       "      <td>I ran the 2018 Brewers Mini-Marathon today!!  ...</td>\n",
       "      <td>5b7ae951-8164-4e97-b024-2f745206f5f9</td>\n",
       "      <td>5K</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>km</td>\n",
       "      <td>5K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5ba47ae8-5ed4-4539-9bd0-21495206f5f9</td>\n",
       "      <td>5K</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>km</td>\n",
       "      <td>5K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>South Milwaukee, WI</td>\n",
       "      <td>5K</td>\n",
       "      <td>Overall</td>\n",
       "      <td>5ba47ae8-5ed4-4539-9bd0-21495206f5f9</td>\n",
       "      <td>00:30:20</td>\n",
       "      <td>00:09:46</td>\n",
       "      <td>[{'order': '1', 'name': 'Overall', 'rank': '31...</td>\n",
       "      <td>[{'name': 'Full Course', 'time': '00:30:20', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5k</td>\n",
       "      <td>5k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293532</th>\n",
       "      <td>599c4cc7-e910-45d2-9706-4cbe5206f5f9</td>\n",
       "      <td>Brewers Mini-Marathon</td>\n",
       "      <td>599c4cc7-b584-4507-bc54-4cbe5206f5f9</td>\n",
       "      <td>2017 Brewers Mini-Marathon</td>\n",
       "      <td>2017-brewers-mini-marathon</td>\n",
       "      <td>Milwaukee, WI</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>WI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4500</td>\n",
       "      <td>4747</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5K</td>\n",
       "      <td>5b7ae951-7e04-4262-a599-2f745206f5f9</td>\n",
       "      <td>2018 Brewers Mini-Marathon</td>\n",
       "      <td>1</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>Run</td>\n",
       "      <td>2018-brewers-mini-marathon</td>\n",
       "      <td>5ba47ae9-73d4-4dcf-a041-21495206f5f9</td>\n",
       "      <td>Overall</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>5k</td>\n",
       "      <td>5ba5b322-17ac-4ec9-b4fd-48ae5206f5f9</td>\n",
       "      <td>5ba5b322-f8b0-4825-a762-48ae5206f5f9</td>\n",
       "      <td>5ba5b321-e954-4e7b-8a98-48ae5206f5f9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Lomnes</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>5355.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-09-21 22:12:34</td>\n",
       "      <td>2018-09-21 22:12:34</td>\n",
       "      <td>2018-09-17 12:07:48</td>\n",
       "      <td>[]</td>\n",
       "      <td>Campbellsport, WI</td>\n",
       "      <td>5b7ae951-7e04-4262-a599-2f745206f5f9</td>\n",
       "      <td>2018 Brewers Mini-Marathon</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5b75b173-717c-4344-a5f6-7d325206f5f9</td>\n",
       "      <td>Milwaukee Brewers Baseball Club</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s3.amazonaws.com/media.racebx.com/tran...</td>\n",
       "      <td>The 7th annual Brewers Mini-Marathon returns o...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#f8a138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>I ran the 2018 Brewers Mini-Marathon today!!  ...</td>\n",
       "      <td>I ran the 2018 Brewers Mini-Marathon today!!  ...</td>\n",
       "      <td>Check out my results from the 2018 Brewers Min...</td>\n",
       "      <td>I ran the 2018 Brewers Mini-Marathon today!!  ...</td>\n",
       "      <td>5b7ae951-8164-4e97-b024-2f745206f5f9</td>\n",
       "      <td>5K</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>km</td>\n",
       "      <td>5K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5ba47ae8-5ed4-4539-9bd0-21495206f5f9</td>\n",
       "      <td>5K</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>km</td>\n",
       "      <td>5K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Campbellsport, WI</td>\n",
       "      <td>5K</td>\n",
       "      <td>Overall</td>\n",
       "      <td>5ba47ae8-5ed4-4539-9bd0-21495206f5f9</td>\n",
       "      <td>00:33:19</td>\n",
       "      <td>00:10:44</td>\n",
       "      <td>[{'order': '1', 'name': 'Overall', 'rank': '47...</td>\n",
       "      <td>[{'name': 'Full Course', 'time': '00:33:19', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5k</td>\n",
       "      <td>5k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>471.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293533 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lineage.event_series.id lineage.event_series.name  \\\n",
       "0       4d7f441a-4fbc-4a3e-b0d1-4e1b7f000001      Hot Chocolate 15K/5K   \n",
       "1       4d7f441a-4fbc-4a3e-b0d1-4e1b7f000001      Hot Chocolate 15K/5K   \n",
       "2       4d7f441a-4fbc-4a3e-b0d1-4e1b7f000001      Hot Chocolate 15K/5K   \n",
       "3       4d7f441a-4fbc-4a3e-b0d1-4e1b7f000001      Hot Chocolate 15K/5K   \n",
       "4       4d7f441a-4fbc-4a3e-b0d1-4e1b7f000001      Hot Chocolate 15K/5K   \n",
       "...                                      ...                       ...   \n",
       "293528  599c4cc7-e910-45d2-9706-4cbe5206f5f9     Brewers Mini-Marathon   \n",
       "293529  599c4cc7-e910-45d2-9706-4cbe5206f5f9     Brewers Mini-Marathon   \n",
       "293530  599c4cc7-e910-45d2-9706-4cbe5206f5f9     Brewers Mini-Marathon   \n",
       "293531  599c4cc7-e910-45d2-9706-4cbe5206f5f9     Brewers Mini-Marathon   \n",
       "293532  599c4cc7-e910-45d2-9706-4cbe5206f5f9     Brewers Mini-Marathon   \n",
       "\n",
       "                   lineage.previous_event.id  \\\n",
       "0       56156dc5-e744-40c5-b2ae-5fc0c0a86526   \n",
       "1       56156dc5-e744-40c5-b2ae-5fc0c0a86526   \n",
       "2       56156dc5-e744-40c5-b2ae-5fc0c0a86526   \n",
       "3       56156dc5-e744-40c5-b2ae-5fc0c0a86526   \n",
       "4       56156dc5-e744-40c5-b2ae-5fc0c0a86526   \n",
       "...                                      ...   \n",
       "293528  599c4cc7-b584-4507-bc54-4cbe5206f5f9   \n",
       "293529  599c4cc7-b584-4507-bc54-4cbe5206f5f9   \n",
       "293530  599c4cc7-b584-4507-bc54-4cbe5206f5f9   \n",
       "293531  599c4cc7-b584-4507-bc54-4cbe5206f5f9   \n",
       "293532  599c4cc7-b584-4507-bc54-4cbe5206f5f9   \n",
       "\n",
       "                   lineage.previous_event.name  \\\n",
       "0       2016 Hot Chocolate 15K/5K - Scottsdale   \n",
       "1       2016 Hot Chocolate 15K/5K - Scottsdale   \n",
       "2       2016 Hot Chocolate 15K/5K - Scottsdale   \n",
       "3       2016 Hot Chocolate 15K/5K - Scottsdale   \n",
       "4       2016 Hot Chocolate 15K/5K - Scottsdale   \n",
       "...                                        ...   \n",
       "293528              2017 Brewers Mini-Marathon   \n",
       "293529              2017 Brewers Mini-Marathon   \n",
       "293530              2017 Brewers Mini-Marathon   \n",
       "293531              2017 Brewers Mini-Marathon   \n",
       "293532              2017 Brewers Mini-Marathon   \n",
       "\n",
       "                 lineage.previous_event.slug   location.name location.city  \\\n",
       "0       2016-hot-chocolate-15k-5k-scottsdale  Scottsdale, AZ    Scottsdale   \n",
       "1       2016-hot-chocolate-15k-5k-scottsdale  Scottsdale, AZ    Scottsdale   \n",
       "2       2016-hot-chocolate-15k-5k-scottsdale  Scottsdale, AZ    Scottsdale   \n",
       "3       2016-hot-chocolate-15k-5k-scottsdale  Scottsdale, AZ    Scottsdale   \n",
       "4       2016-hot-chocolate-15k-5k-scottsdale  Scottsdale, AZ    Scottsdale   \n",
       "...                                      ...             ...           ...   \n",
       "293528            2017-brewers-mini-marathon   Milwaukee, WI     Milwaukee   \n",
       "293529            2017-brewers-mini-marathon   Milwaukee, WI     Milwaukee   \n",
       "293530            2017-brewers-mini-marathon   Milwaukee, WI     Milwaukee   \n",
       "293531            2017-brewers-mini-marathon   Milwaukee, WI     Milwaukee   \n",
       "293532            2017-brewers-mini-marathon   Milwaukee, WI     Milwaukee   \n",
       "\n",
       "       location.state  location.zip location.country_name  \\\n",
       "0                  AZ           NaN                    US   \n",
       "1                  AZ           NaN                    US   \n",
       "2                  AZ           NaN                    US   \n",
       "3                  AZ           NaN                    US   \n",
       "4                  AZ           NaN                    US   \n",
       "...               ...           ...                   ...   \n",
       "293528             WI           NaN                    US   \n",
       "293529             WI           NaN                    US   \n",
       "293530             WI           NaN                    US   \n",
       "293531             WI           NaN                    US   \n",
       "293532             WI           NaN                    US   \n",
       "\n",
       "        location.country_code  location.coordinates.latitude  \\\n",
       "0                         NaN                            NaN   \n",
       "1                         NaN                            NaN   \n",
       "2                         NaN                            NaN   \n",
       "3                         NaN                            NaN   \n",
       "4                         NaN                            NaN   \n",
       "...                       ...                            ...   \n",
       "293528                    NaN                            NaN   \n",
       "293529                    NaN                            NaN   \n",
       "293530                    NaN                            NaN   \n",
       "293531                    NaN                            NaN   \n",
       "293532                    NaN                            NaN   \n",
       "\n",
       "        location.coordinates.longitude counts.participants.expected  \\\n",
       "0                                  NaN                         9200   \n",
       "1                                  NaN                         9200   \n",
       "2                                  NaN                         9200   \n",
       "3                                  NaN                         9200   \n",
       "4                                  NaN                         9200   \n",
       "...                                ...                          ...   \n",
       "293528                             NaN                         4500   \n",
       "293529                             NaN                         4500   \n",
       "293530                             NaN                         4500   \n",
       "293531                             NaN                         4500   \n",
       "293532                             NaN                         4500   \n",
       "\n",
       "        counts.participants.registered  counts.participants.limit  \\\n",
       "0                                 9716                          0   \n",
       "1                                 9716                          0   \n",
       "2                                 9716                          0   \n",
       "3                                 9716                          0   \n",
       "4                                 9716                          0   \n",
       "...                                ...                        ...   \n",
       "293528                            4747                          0   \n",
       "293529                            4747                          0   \n",
       "293530                            4747                          0   \n",
       "293531                            4747                          0   \n",
       "293532                            4747                          0   \n",
       "\n",
       "                                  fundraising.description fundraising.goal  \\\n",
       "0       <p>Our mission at RAM Racing is not only to ra...              NaN   \n",
       "1       <p>Our mission at RAM Racing is not only to ra...              NaN   \n",
       "2       <p>Our mission at RAM Racing is not only to ra...              NaN   \n",
       "3       <p>Our mission at RAM Racing is not only to ra...              NaN   \n",
       "4       <p>Our mission at RAM Racing is not only to ra...              NaN   \n",
       "...                                                   ...              ...   \n",
       "293528                                                NaN              NaN   \n",
       "293529                                                NaN              NaN   \n",
       "293530                                                NaN              NaN   \n",
       "293531                                                NaN              NaN   \n",
       "293532                                                NaN              NaN   \n",
       "\n",
       "       fundraising.status                          fundraising.organizations  \\\n",
       "0                    open  [{'id': '5939a2d0-c3b0-43ad-965e-5d915206f5f9'...   \n",
       "1                    open  [{'id': '5939a2d0-c3b0-43ad-965e-5d915206f5f9'...   \n",
       "2                    open  [{'id': '5939a2d0-c3b0-43ad-965e-5d915206f5f9'...   \n",
       "3                    open  [{'id': '5939a2d0-c3b0-43ad-965e-5d915206f5f9'...   \n",
       "4                    open  [{'id': '5939a2d0-c3b0-43ad-965e-5d915206f5f9'...   \n",
       "...                   ...                                                ...   \n",
       "293528               open                                                 []   \n",
       "293529               open                                                 []   \n",
       "293530               open                                                 []   \n",
       "293531               open                                                 []   \n",
       "293532               open                                                 []   \n",
       "\n",
       "         fundraising.default_organization.id  \\\n",
       "0       5939a2d0-c3b0-43ad-965e-5d915206f5f9   \n",
       "1       5939a2d0-c3b0-43ad-965e-5d915206f5f9   \n",
       "2       5939a2d0-c3b0-43ad-965e-5d915206f5f9   \n",
       "3       5939a2d0-c3b0-43ad-965e-5d915206f5f9   \n",
       "4       5939a2d0-c3b0-43ad-965e-5d915206f5f9   \n",
       "...                                      ...   \n",
       "293528                                   NaN   \n",
       "293529                                   NaN   \n",
       "293530                                   NaN   \n",
       "293531                                   NaN   \n",
       "293532                                   NaN   \n",
       "\n",
       "       fundraising.default_organization.name time.start  time.end  \\\n",
       "0                              Make-A-WishÂ®   00:00:00       NaN   \n",
       "1                              Make-A-WishÂ®   00:00:00       NaN   \n",
       "2                              Make-A-WishÂ®   00:00:00       NaN   \n",
       "3                              Make-A-WishÂ®   00:00:00       NaN   \n",
       "4                              Make-A-WishÂ®   00:00:00       NaN   \n",
       "...                                      ...        ...       ...   \n",
       "293528                                   NaN   00:00:00       NaN   \n",
       "293529                                   NaN   00:00:00       NaN   \n",
       "293530                                   NaN   00:00:00       NaN   \n",
       "293531                                   NaN   00:00:00       NaN   \n",
       "293532                                   NaN   00:00:00       NaN   \n",
       "\n",
       "       categories.name                               body.id  \\\n",
       "0                  15k  583f013a-1e54-4906-87f7-2b625206f5f9   \n",
       "1                  15k  583f013a-1e54-4906-87f7-2b625206f5f9   \n",
       "2                  15k  583f013a-1e54-4906-87f7-2b625206f5f9   \n",
       "3                  15k  583f013a-1e54-4906-87f7-2b625206f5f9   \n",
       "4                  15k  583f013a-1e54-4906-87f7-2b625206f5f9   \n",
       "...                ...                                   ...   \n",
       "293528              5K  5b7ae951-7e04-4262-a599-2f745206f5f9   \n",
       "293529              5K  5b7ae951-7e04-4262-a599-2f745206f5f9   \n",
       "293530              5K  5b7ae951-7e04-4262-a599-2f745206f5f9   \n",
       "293531              5K  5b7ae951-7e04-4262-a599-2f745206f5f9   \n",
       "293532              5K  5b7ae951-7e04-4262-a599-2f745206f5f9   \n",
       "\n",
       "                                     body.name body.results_certificate  \\\n",
       "0       2017 Hot Chocolate 15k/5k - Scottsdale                    False   \n",
       "1       2017 Hot Chocolate 15k/5k - Scottsdale                    False   \n",
       "2       2017 Hot Chocolate 15k/5k - Scottsdale                    False   \n",
       "3       2017 Hot Chocolate 15k/5k - Scottsdale                    False   \n",
       "4       2017 Hot Chocolate 15k/5k - Scottsdale                    False   \n",
       "...                                        ...                      ...   \n",
       "293528              2018 Brewers Mini-Marathon                        1   \n",
       "293529              2018 Brewers Mini-Marathon                        1   \n",
       "293530              2018 Brewers Mini-Marathon                        1   \n",
       "293531              2018 Brewers Mini-Marathon                        1   \n",
       "293532              2018 Brewers Mini-Marathon                        1   \n",
       "\n",
       "          body.timezone body.type                             body.slug  \\\n",
       "0         America/Boise       Run  2017-hot-chocolate-15k-5k-scottsdale   \n",
       "1         America/Boise       Run  2017-hot-chocolate-15k-5k-scottsdale   \n",
       "2         America/Boise       Run  2017-hot-chocolate-15k-5k-scottsdale   \n",
       "3         America/Boise       Run  2017-hot-chocolate-15k-5k-scottsdale   \n",
       "4         America/Boise       Run  2017-hot-chocolate-15k-5k-scottsdale   \n",
       "...                 ...       ...                                   ...   \n",
       "293528  America/Chicago       Run            2018-brewers-mini-marathon   \n",
       "293529  America/Chicago       Run            2018-brewers-mini-marathon   \n",
       "293530  America/Chicago       Run            2018-brewers-mini-marathon   \n",
       "293531  America/Chicago       Run            2018-brewers-mini-marathon   \n",
       "293532  America/Chicago       Run            2018-brewers-mini-marathon   \n",
       "\n",
       "                                 brackets.id brackets.name brackets.type  \\\n",
       "0       5bc540b0-7370-41c9-98e5-1aa55206f5f9       Overall          OPEN   \n",
       "1       5bc540b0-7370-41c9-98e5-1aa55206f5f9       Overall          OPEN   \n",
       "2       5bc540b0-7370-41c9-98e5-1aa55206f5f9       Overall          OPEN   \n",
       "3       5bc540b0-7370-41c9-98e5-1aa55206f5f9       Overall          OPEN   \n",
       "4       5bc540b0-7370-41c9-98e5-1aa55206f5f9       Overall          OPEN   \n",
       "...                                      ...           ...           ...   \n",
       "293528  5ba47ae9-73d4-4dcf-a041-21495206f5f9       Overall          OPEN   \n",
       "293529  5ba47ae9-73d4-4dcf-a041-21495206f5f9       Overall          OPEN   \n",
       "293530  5ba47ae9-73d4-4dcf-a041-21495206f5f9       Overall          OPEN   \n",
       "293531  5ba47ae9-73d4-4dcf-a041-21495206f5f9       Overall          OPEN   \n",
       "293532  5ba47ae9-73d4-4dcf-a041-21495206f5f9       Overall          OPEN   \n",
       "\n",
       "       clean_categories.name                                    id  \\\n",
       "0                        15k  57225834-0724-455d-9f96-54365206f5f9   \n",
       "1                        15k  572258a1-2858-48cb-a631-54365206f5f9   \n",
       "2                        15k  575312c2-b73c-484a-9cf7-5af15206f5f9   \n",
       "3                        15k  575312c9-8f24-4b1c-93f1-5a8b5206f5f9   \n",
       "4                        15k  58082a0c-9ea8-4dbb-bb52-53b15206f5f9   \n",
       "...                      ...                                   ...   \n",
       "293528                    5k  5ba5a4c0-82d8-433e-bb08-3ae25206f5f9   \n",
       "293529                    5k  5ba5a4c0-8764-4016-8267-3ae25206f5f9   \n",
       "293530                    5k  5ba5a4c0-a08c-4134-a0cf-3ae25206f5f9   \n",
       "293531                    5k  5ba5a4c0-de84-4e49-a0aa-3ae25206f5f9   \n",
       "293532                    5k  5ba5b322-17ac-4ec9-b4fd-48ae5206f5f9   \n",
       "\n",
       "                               registrant_id  \\\n",
       "0       51016889-9ac4-44b6-af81-3dfcc0a86524   \n",
       "1       543efa86-c11c-49bd-b3c3-7756c0a86526   \n",
       "2       54bd1e41-0d84-47ba-beb1-7fafc0a86526   \n",
       "3       54bf4092-3bcc-4155-bbcb-444cc0a86526   \n",
       "4       58082a43-2594-4fa6-bbd8-53655206f5f9   \n",
       "...                                      ...   \n",
       "293528  5ba5a4c0-0728-4036-8abe-3ae25206f5f9   \n",
       "293529  581104a6-1900-49f3-97a1-715c5206f5f9   \n",
       "293530  5ba5a4bf-f048-40bb-bd4d-3ae25206f5f9   \n",
       "293531  5ba5a4c0-2f0c-4b68-9073-3ae25206f5f9   \n",
       "293532  5ba5b322-f8b0-4825-a762-48ae5206f5f9   \n",
       "\n",
       "                                     user_id confirmation_number  \\\n",
       "0       51016889-4b64-42d5-9f8f-3dfcc0a86524            awrhqcsz   \n",
       "1       51016889-4b64-42d5-9f8f-3dfcc0a86524            qcludofk   \n",
       "2       54bd1e41-a028-444d-a6bd-7fafc0a86526            phcncuav   \n",
       "3       54bf4092-5690-4bfb-a8c7-444cc0a86526            tlcbsjsi   \n",
       "4       58082a43-4f0c-4c87-9f48-53655206f5f9            yisfpkrj   \n",
       "...                                      ...                 ...   \n",
       "293528  5ba5a4c0-c3ac-42d1-a9d6-3ae25206f5f9                 NaN   \n",
       "293529  581104a6-ceb4-4f5e-9b27-715c5206f5f9                 NaN   \n",
       "293530  5ba5a4bf-1cd4-4ca8-bbdd-3ae25206f5f9                 NaN   \n",
       "293531  523000ba-ba24-431b-a94b-70bdc0a86524                 NaN   \n",
       "293532  5ba5b321-e954-4e7b-8a98-48ae5206f5f9                 NaN   \n",
       "\n",
       "       registration_status firstname       lastname   age     sex      bib  \\\n",
       "0                Completed     Rakhi          Batra  38.0  Female  52038.0   \n",
       "1                Completed    Harsha        Vardhan  32.0  Female  52039.0   \n",
       "2                Completed  Christie  Casuga-Nguyen  36.0  Female  52770.0   \n",
       "3                Completed      Jane      Maldonado  44.0  Female  53594.0   \n",
       "4                Completed  Cristina        Verdugo  44.0  Female  51166.0   \n",
       "...                    ...       ...            ...   ...     ...      ...   \n",
       "293528           Completed      Matt        Kinnard  36.0    Male   5349.0   \n",
       "293529           Completed    Audrey        Harwood  30.0  Female   5362.0   \n",
       "293530           Completed   Richard        Hombsch  28.0    Male   5346.0   \n",
       "293531           Completed    Trista        Tolkacz  35.0  Female   5352.0   \n",
       "293532           Completed    Sydney         Lomnes  27.0  Female   5355.0   \n",
       "\n",
       "               checkin_time     coupon coupon_type  price  \\\n",
       "0       2017-12-02 11:48:45        NaN         NaN   64.0   \n",
       "1       2017-12-02 11:49:30        NaN         NaN   64.0   \n",
       "2       2017-12-02 17:10:53  RNRSDLEIA        buff   64.0   \n",
       "3       2017-12-02 17:10:40  RNRSDLEIA        buff   64.0   \n",
       "4       2017-11-14 13:50:40        NaN         NaN   69.0   \n",
       "...                     ...        ...         ...    ...   \n",
       "293528                  NaN        NaN         NaN    0.0   \n",
       "293529                  NaN        NaN         NaN    0.0   \n",
       "293530                  NaN        NaN         NaN    0.0   \n",
       "293531                  NaN        NaN         NaN    0.0   \n",
       "293532                  NaN        NaN         NaN    0.0   \n",
       "\n",
       "                    created             modified            completed  \\\n",
       "0       2016-04-28 13:36:36                  NaN  2016-04-28 13:39:36   \n",
       "1       2016-04-28 13:38:25                  NaN  2016-04-28 13:39:37   \n",
       "2       2016-06-04 12:41:22                  NaN  2016-06-04 12:44:14   \n",
       "3       2016-06-04 12:41:29                  NaN  2016-06-04 12:44:09   \n",
       "4       2016-10-19 21:21:00                  NaN  2016-10-19 21:31:21   \n",
       "...                     ...                  ...                  ...   \n",
       "293528  2018-09-21 21:11:12  2018-09-21 21:11:12  2018-09-21 18:11:19   \n",
       "293529  2018-09-21 21:11:12  2018-09-21 21:11:12  2018-09-21 21:11:12   \n",
       "293530  2018-09-21 21:11:12  2018-09-21 21:11:12  2018-09-21 17:51:08   \n",
       "293531  2018-09-21 21:11:12  2018-09-21 21:11:12  2018-09-21 18:30:30   \n",
       "293532  2018-09-21 22:12:34  2018-09-21 22:12:34  2018-09-17 12:07:48   \n",
       "\n",
       "                                                shipments  \\\n",
       "0                                                      []   \n",
       "1                                                      []   \n",
       "2                                                      []   \n",
       "3                                                      []   \n",
       "4       [{'carrier': 'stampscom_usps', 'tracking_numbe...   \n",
       "...                                                   ...   \n",
       "293528                                                 []   \n",
       "293529                                                 []   \n",
       "293530                                                 []   \n",
       "293531                                                 []   \n",
       "293532                                                 []   \n",
       "\n",
       "                   hometown                              event.id  \\\n",
       "0             San Diego, CA  583f013a-1e54-4906-87f7-2b625206f5f9   \n",
       "1             San Diego, CA  583f013a-1e54-4906-87f7-2b625206f5f9   \n",
       "2             San Diego, CA  583f013a-1e54-4906-87f7-2b625206f5f9   \n",
       "3             San Diego, CA  583f013a-1e54-4906-87f7-2b625206f5f9   \n",
       "4                Tucson, AZ  583f013a-1e54-4906-87f7-2b625206f5f9   \n",
       "...                     ...                                   ...   \n",
       "293528      New Franken, WI  5b7ae951-7e04-4262-a599-2f745206f5f9   \n",
       "293529         Palatine, IL  5b7ae951-7e04-4262-a599-2f745206f5f9   \n",
       "293530        Milwaukee, WI  5b7ae951-7e04-4262-a599-2f745206f5f9   \n",
       "293531  South Milwaukee, WI  5b7ae951-7e04-4262-a599-2f745206f5f9   \n",
       "293532    Campbellsport, WI  5b7ae951-7e04-4262-a599-2f745206f5f9   \n",
       "\n",
       "                                    event.name event.date.start  \\\n",
       "0       2017 Hot Chocolate 15k/5k - Scottsdale       2017-12-03   \n",
       "1       2017 Hot Chocolate 15k/5k - Scottsdale       2017-12-03   \n",
       "2       2017 Hot Chocolate 15k/5k - Scottsdale       2017-12-03   \n",
       "3       2017 Hot Chocolate 15k/5k - Scottsdale       2017-12-03   \n",
       "4       2017 Hot Chocolate 15k/5k - Scottsdale       2017-12-03   \n",
       "...                                        ...              ...   \n",
       "293528              2018 Brewers Mini-Marathon       2018-09-22   \n",
       "293529              2018 Brewers Mini-Marathon       2018-09-22   \n",
       "293530              2018 Brewers Mini-Marathon       2018-09-22   \n",
       "293531              2018 Brewers Mini-Marathon       2018-09-22   \n",
       "293532              2018 Brewers Mini-Marathon       2018-09-22   \n",
       "\n",
       "       event.date.end                       event.tenant.id  \\\n",
       "0                 NaN  7f47b47a-262d-4ae6-b14d-9b15ffc1020c   \n",
       "1                 NaN  7f47b47a-262d-4ae6-b14d-9b15ffc1020c   \n",
       "2                 NaN  7f47b47a-262d-4ae6-b14d-9b15ffc1020c   \n",
       "3                 NaN  7f47b47a-262d-4ae6-b14d-9b15ffc1020c   \n",
       "4                 NaN  7f47b47a-262d-4ae6-b14d-9b15ffc1020c   \n",
       "...               ...                                   ...   \n",
       "293528            NaN  5b75b173-717c-4344-a5f6-7d325206f5f9   \n",
       "293529            NaN  5b75b173-717c-4344-a5f6-7d325206f5f9   \n",
       "293530            NaN  5b75b173-717c-4344-a5f6-7d325206f5f9   \n",
       "293531            NaN  5b75b173-717c-4344-a5f6-7d325206f5f9   \n",
       "293532            NaN  5b75b173-717c-4344-a5f6-7d325206f5f9   \n",
       "\n",
       "                      event.tenant.name   event.timezone  event.location.name  \\\n",
       "0                    Ventures Endurance    America/Boise                  NaN   \n",
       "1                    Ventures Endurance    America/Boise                  NaN   \n",
       "2                    Ventures Endurance    America/Boise                  NaN   \n",
       "3                    Ventures Endurance    America/Boise                  NaN   \n",
       "4                    Ventures Endurance    America/Boise                  NaN   \n",
       "...                                 ...              ...                  ...   \n",
       "293528  Milwaukee Brewers Baseball Club  America/Chicago                  NaN   \n",
       "293529  Milwaukee Brewers Baseball Club  America/Chicago                  NaN   \n",
       "293530  Milwaukee Brewers Baseball Club  America/Chicago                  NaN   \n",
       "293531  Milwaukee Brewers Baseball Club  America/Chicago                  NaN   \n",
       "293532  Milwaukee Brewers Baseball Club  America/Chicago                  NaN   \n",
       "\n",
       "        event.location.zip  event.location.coordinates.latitude  \\\n",
       "0                      NaN                                  NaN   \n",
       "1                      NaN                                  NaN   \n",
       "2                      NaN                                  NaN   \n",
       "3                      NaN                                  NaN   \n",
       "4                      NaN                                  NaN   \n",
       "...                    ...                                  ...   \n",
       "293528                 NaN                                  NaN   \n",
       "293529                 NaN                                  NaN   \n",
       "293530                 NaN                                  NaN   \n",
       "293531                 NaN                                  NaN   \n",
       "293532                 NaN                                  NaN   \n",
       "\n",
       "        event.location.coordinates.longitude  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "...                                      ...   \n",
       "293528                                   NaN   \n",
       "293529                                   NaN   \n",
       "293530                                   NaN   \n",
       "293531                                   NaN   \n",
       "293532                                   NaN   \n",
       "\n",
       "                                  event.images.hub.header  \\\n",
       "0       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "1       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "2       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "3       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "4       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "...                                                   ...   \n",
       "293528  https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "293529  https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "293530  https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "293531  https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "293532  https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "\n",
       "                                event.images.email.header  \\\n",
       "0       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "1       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "2       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "3       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "4       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "...                                                   ...   \n",
       "293528                                                NaN   \n",
       "293529                                                NaN   \n",
       "293530                                                NaN   \n",
       "293531                                                NaN   \n",
       "293532                                                NaN   \n",
       "\n",
       "                                event.images.email.footer  \\\n",
       "0       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "1       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "2       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "3       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "4       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "...                                                   ...   \n",
       "293528                                                NaN   \n",
       "293529                                                NaN   \n",
       "293530                                                NaN   \n",
       "293531                                                NaN   \n",
       "293532                                                NaN   \n",
       "\n",
       "                                        event.images.logo  \\\n",
       "0       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "1       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "2       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "3       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "4       https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "...                                                   ...   \n",
       "293528  https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "293529  https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "293530  https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "293531  https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "293532  https://s3.amazonaws.com/media.racebx.com/tran...   \n",
       "\n",
       "                                        event.description event.sections  \\\n",
       "0       Join the movement that's taken over the racing...             []   \n",
       "1       Join the movement that's taken over the racing...             []   \n",
       "2       Join the movement that's taken over the racing...             []   \n",
       "3       Join the movement that's taken over the racing...             []   \n",
       "4       Join the movement that's taken over the racing...             []   \n",
       "...                                                   ...            ...   \n",
       "293528  The 7th annual Brewers Mini-Marathon returns o...             []   \n",
       "293529  The 7th annual Brewers Mini-Marathon returns o...             []   \n",
       "293530  The 7th annual Brewers Mini-Marathon returns o...             []   \n",
       "293531  The 7th annual Brewers Mini-Marathon returns o...             []   \n",
       "293532  The 7th annual Brewers Mini-Marathon returns o...             []   \n",
       "\n",
       "        event.results_posted event.results_certificate event.photos_available  \\\n",
       "0                        1.0                     False                      1   \n",
       "1                        1.0                     False                      1   \n",
       "2                        1.0                     False                      1   \n",
       "3                        1.0                     False                      1   \n",
       "4                        1.0                     False                      1   \n",
       "...                      ...                       ...                    ...   \n",
       "293528                   1.0                         1                  False   \n",
       "293529                   1.0                         1                  False   \n",
       "293530                   1.0                         1                  False   \n",
       "293531                   1.0                         1                  False   \n",
       "293532                   1.0                         1                  False   \n",
       "\n",
       "       event.photos_faces  event.photos_social_sharing  \\\n",
       "0                   False                          1.0   \n",
       "1                   False                          1.0   \n",
       "2                   False                          1.0   \n",
       "3                   False                          1.0   \n",
       "4                   False                          1.0   \n",
       "...                   ...                          ...   \n",
       "293528              False                          1.0   \n",
       "293529              False                          1.0   \n",
       "293530              False                          1.0   \n",
       "293531              False                          1.0   \n",
       "293532              False                          1.0   \n",
       "\n",
       "        event.results_searchable  event.no_bib event.color  \\\n",
       "0                            1.0           0.0     #f8a138   \n",
       "1                            1.0           0.0     #f8a138   \n",
       "2                            1.0           0.0     #f8a138   \n",
       "3                            1.0           0.0     #f8a138   \n",
       "4                            1.0           0.0     #f8a138   \n",
       "...                          ...           ...         ...   \n",
       "293528                       1.0           0.0     #f8a138   \n",
       "293529                       1.0           0.0     #f8a138   \n",
       "293530                       1.0           0.0     #f8a138   \n",
       "293531                       1.0           0.0     #f8a138   \n",
       "293532                       1.0           0.0     #f8a138   \n",
       "\n",
       "                                            event.sidebar  \\\n",
       "0       <ul class=\"sponsors\"><li><a href=\"https://nuun...   \n",
       "1       <ul class=\"sponsors\"><li><a href=\"https://nuun...   \n",
       "2       <ul class=\"sponsors\"><li><a href=\"https://nuun...   \n",
       "3       <ul class=\"sponsors\"><li><a href=\"https://nuun...   \n",
       "4       <ul class=\"sponsors\"><li><a href=\"https://nuun...   \n",
       "...                                                   ...   \n",
       "293528                                                NaN   \n",
       "293529                                                NaN   \n",
       "293530                                                NaN   \n",
       "293531                                                NaN   \n",
       "293532                                                NaN   \n",
       "\n",
       "                                   event.sidebar_elements  \\\n",
       "0       [{'id': 'sidebar_5b75040fa1951', 'section_type...   \n",
       "1       [{'id': 'sidebar_5b75040fa1951', 'section_type...   \n",
       "2       [{'id': 'sidebar_5b75040fa1951', 'section_type...   \n",
       "3       [{'id': 'sidebar_5b75040fa1951', 'section_type...   \n",
       "4       [{'id': 'sidebar_5b75040fa1951', 'section_type...   \n",
       "...                                                   ...   \n",
       "293528                                                 []   \n",
       "293529                                                 []   \n",
       "293530                                                 []   \n",
       "293531                                                 []   \n",
       "293532                                                 []   \n",
       "\n",
       "                       event.sharing.twitter.default_text  \\\n",
       "0       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "1       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "2       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "3       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "4       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "...                                                   ...   \n",
       "293528  I ran the 2018 Brewers Mini-Marathon today!!  ...   \n",
       "293529  I ran the 2018 Brewers Mini-Marathon today!!  ...   \n",
       "293530  I ran the 2018 Brewers Mini-Marathon today!!  ...   \n",
       "293531  I ran the 2018 Brewers Mini-Marathon today!!  ...   \n",
       "293532  I ran the 2018 Brewers Mini-Marathon today!!  ...   \n",
       "\n",
       "                      event.sharing.facebook.default_text  \\\n",
       "0       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "1       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "2       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "3       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "4       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "...                                                   ...   \n",
       "293528  I ran the 2018 Brewers Mini-Marathon today!!  ...   \n",
       "293529  I ran the 2018 Brewers Mini-Marathon today!!  ...   \n",
       "293530  I ran the 2018 Brewers Mini-Marathon today!!  ...   \n",
       "293531  I ran the 2018 Brewers Mini-Marathon today!!  ...   \n",
       "293532  I ran the 2018 Brewers Mini-Marathon today!!  ...   \n",
       "\n",
       "                      event.sharing.email.default_subject  \\\n",
       "0       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "1       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "2       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "3       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "4       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "...                                                   ...   \n",
       "293528  Check out my results from the 2018 Brewers Min...   \n",
       "293529  Check out my results from the 2018 Brewers Min...   \n",
       "293530  Check out my results from the 2018 Brewers Min...   \n",
       "293531  Check out my results from the 2018 Brewers Min...   \n",
       "293532  Check out my results from the 2018 Brewers Min...   \n",
       "\n",
       "                         event.sharing.email.default_body  \\\n",
       "0       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "1       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "2       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "3       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "4       I ran 2017 Hot Chocolate 15k/5k - Scottsdale t...   \n",
       "...                                                   ...   \n",
       "293528  I ran the 2018 Brewers Mini-Marathon today!!  ...   \n",
       "293529  I ran the 2018 Brewers Mini-Marathon today!!  ...   \n",
       "293530  I ran the 2018 Brewers Mini-Marathon today!!  ...   \n",
       "293531  I ran the 2018 Brewers Mini-Marathon today!!  ...   \n",
       "293532  I ran the 2018 Brewers Mini-Marathon today!!  ...   \n",
       "\n",
       "                      category.registered.id category.registered.name  \\\n",
       "0       583f013a-16bc-4212-9659-2b625206f5f9                      15k   \n",
       "1       583f013a-16bc-4212-9659-2b625206f5f9                      15k   \n",
       "2       583f013a-16bc-4212-9659-2b625206f5f9                      15k   \n",
       "3       583f013a-16bc-4212-9659-2b625206f5f9                      15k   \n",
       "4       583f013a-16bc-4212-9659-2b625206f5f9                      15k   \n",
       "...                                      ...                      ...   \n",
       "293528  5b7ae951-8164-4e97-b024-2f745206f5f9                       5K   \n",
       "293529  5b7ae951-8164-4e97-b024-2f745206f5f9                       5K   \n",
       "293530  5b7ae951-8164-4e97-b024-2f745206f5f9                       5K   \n",
       "293531  5b7ae951-8164-4e97-b024-2f745206f5f9                       5K   \n",
       "293532  5b7ae951-8164-4e97-b024-2f745206f5f9                       5K   \n",
       "\n",
       "       category.registered.date  category.registered.distance.quantity  \\\n",
       "0                    2017-12-03                                   15.0   \n",
       "1                    2017-12-03                                   15.0   \n",
       "2                    2017-12-03                                   15.0   \n",
       "3                    2017-12-03                                   15.0   \n",
       "4                    2017-12-03                                   15.0   \n",
       "...                         ...                                    ...   \n",
       "293528               2018-09-22                                    5.0   \n",
       "293529               2018-09-22                                    5.0   \n",
       "293530               2018-09-22                                    5.0   \n",
       "293531               2018-09-22                                    5.0   \n",
       "293532               2018-09-22                                    5.0   \n",
       "\n",
       "       category.registered.distance.unit category.registered.distance.name  \\\n",
       "0                                     km                               15K   \n",
       "1                                     km                               15K   \n",
       "2                                     km                               15K   \n",
       "3                                     km                               15K   \n",
       "4                                     km                               15K   \n",
       "...                                  ...                               ...   \n",
       "293528                                km                                5K   \n",
       "293529                                km                                5K   \n",
       "293530                                km                                5K   \n",
       "293531                                km                                5K   \n",
       "293532                                km                                5K   \n",
       "\n",
       "        category.registered.results_log_allow  \\\n",
       "0                                         0.0   \n",
       "1                                         0.0   \n",
       "2                                         0.0   \n",
       "3                                         0.0   \n",
       "4                                         0.0   \n",
       "...                                       ...   \n",
       "293528                                    0.0   \n",
       "293529                                    0.0   \n",
       "293530                                    0.0   \n",
       "293531                                    0.0   \n",
       "293532                                    0.0   \n",
       "\n",
       "        category.registered.user_photo_upload_allow  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "...                                             ...   \n",
       "293528                                          0.0   \n",
       "293529                                          0.0   \n",
       "293530                                          0.0   \n",
       "293531                                          0.0   \n",
       "293532                                          0.0   \n",
       "\n",
       "                       category.completed.id category.completed.name  \\\n",
       "0       5bc540af-23fc-497f-98e3-1aa55206f5f9                     15k   \n",
       "1       5bc540af-23fc-497f-98e3-1aa55206f5f9                     15k   \n",
       "2       5bc540af-23fc-497f-98e3-1aa55206f5f9                     15k   \n",
       "3       5bc540af-23fc-497f-98e3-1aa55206f5f9                     15k   \n",
       "4       5bc540af-23fc-497f-98e3-1aa55206f5f9                     15k   \n",
       "...                                      ...                     ...   \n",
       "293528  5ba47ae8-5ed4-4539-9bd0-21495206f5f9                      5K   \n",
       "293529  5ba47ae8-5ed4-4539-9bd0-21495206f5f9                      5K   \n",
       "293530  5ba47ae8-5ed4-4539-9bd0-21495206f5f9                      5K   \n",
       "293531  5ba47ae8-5ed4-4539-9bd0-21495206f5f9                      5K   \n",
       "293532  5ba47ae8-5ed4-4539-9bd0-21495206f5f9                      5K   \n",
       "\n",
       "       category.completed.date  category.completed.distance.quantity  \\\n",
       "0                   2017-12-03                                  15.0   \n",
       "1                   2017-12-03                                  15.0   \n",
       "2                   2017-12-03                                  15.0   \n",
       "3                   2017-12-03                                  15.0   \n",
       "4                   2017-12-03                                  15.0   \n",
       "...                        ...                                   ...   \n",
       "293528              2018-09-22                                   5.0   \n",
       "293529              2018-09-22                                   5.0   \n",
       "293530              2018-09-22                                   5.0   \n",
       "293531              2018-09-22                                   5.0   \n",
       "293532              2018-09-22                                   5.0   \n",
       "\n",
       "       category.completed.distance.unit category.completed.distance.name  \\\n",
       "0                                    km                              15K   \n",
       "1                                    km                              15K   \n",
       "2                                    km                              15K   \n",
       "3                                    km                              15K   \n",
       "4                                    km                              15K   \n",
       "...                                 ...                              ...   \n",
       "293528                               km                               5K   \n",
       "293529                               km                               5K   \n",
       "293530                               km                               5K   \n",
       "293531                               km                               5K   \n",
       "293532                               km                               5K   \n",
       "\n",
       "        corral.id  corral.name  corral.wave  corral.time.close  \\\n",
       "0             NaN          NaN          NaN                NaN   \n",
       "1             NaN          NaN          NaN                NaN   \n",
       "2             NaN          NaN          NaN                NaN   \n",
       "3             NaN          NaN          NaN                NaN   \n",
       "4             NaN          NaN          NaN                NaN   \n",
       "...           ...          ...          ...                ...   \n",
       "293528        NaN          NaN          NaN                NaN   \n",
       "293529        NaN          NaN          NaN                NaN   \n",
       "293530        NaN          NaN          NaN                NaN   \n",
       "293531        NaN          NaN          NaN                NaN   \n",
       "293532        NaN          NaN          NaN                NaN   \n",
       "\n",
       "        corral.time.start team.id team.name  team.bib  result.provider  \\\n",
       "0                     NaN     NaN       NaN       NaN              1.0   \n",
       "1                     NaN     NaN       NaN       NaN              1.0   \n",
       "2                     NaN     NaN       NaN       NaN              1.0   \n",
       "3                     NaN     NaN       NaN       NaN              1.0   \n",
       "4                     NaN     NaN       NaN       NaN              1.0   \n",
       "...                   ...     ...       ...       ...              ...   \n",
       "293528                NaN     NaN       NaN       NaN              1.0   \n",
       "293529                NaN     NaN       NaN       NaN              1.0   \n",
       "293530                NaN     NaN       NaN       NaN              1.0   \n",
       "293531                NaN     NaN       NaN       NaN              1.0   \n",
       "293532                NaN     NaN       NaN       NaN              1.0   \n",
       "\n",
       "            result.hometown result.race_name result.primary_bracket  \\\n",
       "0             San Diego, CA              15k                Overall   \n",
       "1             San Diego, CA              15k                Overall   \n",
       "2             San Diego, CA              15k                Overall   \n",
       "3             San Diego, CA              15k                Overall   \n",
       "4                Tucson, AZ              15k                Overall   \n",
       "...                     ...              ...                    ...   \n",
       "293528      New Franken, WI               5K                Overall   \n",
       "293529         Palatine, IL               5K                Overall   \n",
       "293530        Milwaukee, WI               5K                Overall   \n",
       "293531  South Milwaukee, WI               5K                Overall   \n",
       "293532    Campbellsport, WI               5K                Overall   \n",
       "\n",
       "                          result.category_id result.duration.chip  \\\n",
       "0       5bc540af-23fc-497f-98e3-1aa55206f5f9             01:51:13   \n",
       "1       5bc540af-23fc-497f-98e3-1aa55206f5f9             01:37:40   \n",
       "2       5bc540af-23fc-497f-98e3-1aa55206f5f9             02:18:00   \n",
       "3       5bc540af-23fc-497f-98e3-1aa55206f5f9             02:18:01   \n",
       "4       5bc540af-23fc-497f-98e3-1aa55206f5f9             01:35:45   \n",
       "...                                      ...                  ...   \n",
       "293528  5ba47ae8-5ed4-4539-9bd0-21495206f5f9             00:28:53   \n",
       "293529  5ba47ae8-5ed4-4539-9bd0-21495206f5f9             00:30:46   \n",
       "293530  5ba47ae8-5ed4-4539-9bd0-21495206f5f9             00:31:14   \n",
       "293531  5ba47ae8-5ed4-4539-9bd0-21495206f5f9             00:30:20   \n",
       "293532  5ba47ae8-5ed4-4539-9bd0-21495206f5f9             00:33:19   \n",
       "\n",
       "       result.duration.pace  \\\n",
       "0                  00:11:56   \n",
       "1                  00:10:29   \n",
       "2                  00:14:49   \n",
       "3                  00:14:49   \n",
       "4                  00:10:17   \n",
       "...                     ...   \n",
       "293528             00:09:18   \n",
       "293529             00:09:54   \n",
       "293530             00:10:03   \n",
       "293531             00:09:46   \n",
       "293532             00:10:44   \n",
       "\n",
       "                                          result.rankings  \\\n",
       "0       [{'order': '1', 'name': 'Overall', 'rank': '2,...   \n",
       "1       [{'order': '1', 'name': 'Overall', 'rank': '1,...   \n",
       "2       [{'order': '1', 'name': 'Overall', 'rank': '3,...   \n",
       "3       [{'order': '1', 'name': 'Overall', 'rank': '3,...   \n",
       "4       [{'order': '1', 'name': 'Overall', 'rank': '1,...   \n",
       "...                                                   ...   \n",
       "293528  [{'order': '1', 'name': 'Overall', 'rank': '21...   \n",
       "293529  [{'order': '1', 'name': 'Overall', 'rank': '33...   \n",
       "293530  [{'order': '1', 'name': 'Overall', 'rank': '35...   \n",
       "293531  [{'order': '1', 'name': 'Overall', 'rank': '31...   \n",
       "293532  [{'order': '1', 'name': 'Overall', 'rank': '47...   \n",
       "\n",
       "                                            result.splits result.videos  \\\n",
       "0       [{'name': '5K', 'time': '00:33:21', 'pace': '1...            []   \n",
       "1       [{'name': '5K', 'time': '00:29:19', 'pace': '0...            []   \n",
       "2       [{'name': '5K', 'time': '00:43:45', 'pace': '1...            []   \n",
       "3       [{'name': '5K', 'time': '00:43:46', 'pace': '1...            []   \n",
       "4       [{'name': '5K', 'time': '00:30:06', 'pace': '0...            []   \n",
       "...                                                   ...           ...   \n",
       "293528  [{'name': 'Full Course', 'time': '00:28:53', '...            []   \n",
       "293529  [{'name': 'Full Course', 'time': '00:30:46', '...            []   \n",
       "293530  [{'name': 'Full Course', 'time': '00:31:14', '...            []   \n",
       "293531  [{'name': 'Full Course', 'time': '00:30:20', '...            []   \n",
       "293532  [{'name': 'Full Course', 'time': '00:33:19', '...            []   \n",
       "\n",
       "        result.finished  result.disqualified result.duration  photo  \\\n",
       "0                  True                False             NaN    NaN   \n",
       "1                  True                False             NaN    NaN   \n",
       "2                  True                False             NaN    NaN   \n",
       "3                  True                False             NaN    NaN   \n",
       "4                  True                False             NaN    NaN   \n",
       "...                 ...                  ...             ...    ...   \n",
       "293528             True                False             NaN    NaN   \n",
       "293529             True                False             NaN    NaN   \n",
       "293530             True                False             NaN    NaN   \n",
       "293531             True                False             NaN    NaN   \n",
       "293532             True                False             NaN    NaN   \n",
       "\n",
       "       event.race.id clean_category.completed.name  \\\n",
       "0                NaN                           15k   \n",
       "1                NaN                           15k   \n",
       "2                NaN                           15k   \n",
       "3                NaN                           15k   \n",
       "4                NaN                           15k   \n",
       "...              ...                           ...   \n",
       "293528           NaN                            5k   \n",
       "293529           NaN                            5k   \n",
       "293530           NaN                            5k   \n",
       "293531           NaN                            5k   \n",
       "293532           NaN                            5k   \n",
       "\n",
       "       clean_category.registered.name sequence_id  overall_ranking  \n",
       "0                                 15k         NaN           2117.0  \n",
       "1                                 15k         NaN           1343.0  \n",
       "2                                 15k         NaN           3084.0  \n",
       "3                                 15k         NaN           3085.0  \n",
       "4                                 15k         NaN           1241.0  \n",
       "...                               ...         ...              ...  \n",
       "293528                             5k         NaN            214.0  \n",
       "293529                             5k         NaN            337.0  \n",
       "293530                             5k         NaN            358.0  \n",
       "293531                             5k         NaN            311.0  \n",
       "293532                             5k         NaN            471.0  \n",
       "\n",
       "[293533 rows x 126 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bef1505d-94b0-46f3-8213-14fbc4d069f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "pickle data was truncated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 591>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    589\u001b[0m cloudpickle\u001b[38;5;241m.\u001b[39mdump(fitted_reg, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpipeline.cloudpickle\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    590\u001b[0m \u001b[38;5;66;03m# Then telling the autograder function to fire\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m \u001b[43mautograde\u001b[49m\u001b[43m(\u001b[49m\u001b[43mholdout_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mautograde\u001b[0;34m(holdout_data)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mautograde\u001b[39m(holdout_data):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# Run prediction on each group\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     results\u001b[38;5;241m=\u001b[39m\u001b[43mholdout_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevent.id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclean_categories.name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# Display the results, uncomment this for your own display\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     results\u001b[38;5;241m.\u001b[39mreset_index()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar();\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1414\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1414\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1416\u001b[0m         \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m         \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1424\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group_selection_context():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1455\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1434\u001b[0m     not_indexed_same: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1435\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   1436\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1437\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1438\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1455\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1458\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmutated\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/groupby/ops.py:761\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    760\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 761\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    763\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1388\u001b[0m, in \u001b[0;36mGroupBy.apply.<locals>.f\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(g):\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1388\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(data, pipeline_file)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(data, pipeline_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpipeline.cloudpickle\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# Load student pipeline\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     fitted_pipe \u001b[38;5;241m=\u001b[39m \u001b[43mcloudpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpipeline_file\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Separate out the X and y\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;241m-\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall_ranking\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: pickle data was truncated"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4: Think about the predictive modelling workflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Now that we have out outcome to predict, we want to think about what variables might\n",
    "# be useful in predicting this. For running it's well known that sex and age have impacts\n",
    "# at a population level, so we can start with those. But while age is numeric, sex is not.\n",
    "# If you look at the data, you'll see that sex actually has a host of different values,\n",
    "# and you can think about how to clean those. But for linear regression we need to make\n",
    "# this numeric. While there are various ways to do this, one hot encoding is a pretty\n",
    "# common one. So the strategy for this first model is to one hot encode sex with a binary\n",
    "# split of Male/Female, and to just use age as is, and train a linear regression model\n",
    "# with default parameters and then convert that timing into a ranking down the road.\n",
    "\n",
    "# There are several ways to do this. The autograder is expecting that you will have\n",
    "# saved a python object and that it has a predict(X) function where X is a pandas\n",
    "# DataFrame object that has all of the columns in the holdout data but only for one\n",
    "# combination of event.id and clean_categories.name. There are two high level strategies\n",
    "# here:\n",
    "#  1. Roll your own object, where you create your own object that has the predict()\n",
    "#     function and just does all the work in there however you want it to.\n",
    "#  2. Use sklearn.pipeline.Pipeline objects, where you leverage some of the resuable\n",
    "#     sklearn pipeline objects which were build for this purpose.\n",
    "\n",
    "# Importantly, there are non-exclusive options, and you can blend however you see fit.\n",
    "# I'll show examples of both, first being the roll your own\n",
    "\n",
    "def roll_own()->object:\n",
    "    \"\"\"This function returns a fitted object with a predict(x) function\"\"\"\n",
    "    \n",
    "    # First I'm going to create a new class with a predict function, and that class\n",
    "    # is just going to call the regression object it is setup with and then rerank\n",
    "    # all of the values which come back\n",
    "    class RollingRegressor():\n",
    "        \n",
    "        # For this class I'm going to assume it has been given a fitted model, so\n",
    "        # I'm choosing not to implement the fit() function.\n",
    "        def __init__(self, fitted_model):\n",
    "            self.regressor=fitted_model\n",
    "        \n",
    "        # For the prediction we are just given our dataframe, so we have to do our\n",
    "        # data cleaning here.\n",
    "        def predict(self, X):\n",
    "            # We need to be careful and *not* drop rows. The autograder is expecting\n",
    "            # a rank back for every row in X! Lets just grab out the two columns of\n",
    "            # interest\n",
    "            df=X[[\"age\",\"sex\",\"clean_categories.name\",\"body.type\",\"event.id\",\"location.state\",\"location.city\",\"body.timezone\", \"event.tenant.name\",\n",
    "                  \"result.primary_bracket\", \"counts.participants.registered\"]]   \n",
    "            #\"event.images.email.header\",\"event.images.email.footer\",\"category.registered.distance.quantity\",\"category.registered.distance.unit\",\n",
    "            \n",
    "            df=df.rename(columns={'event.id':'event_id'})\n",
    "    \n",
    "            #df.loc[df['sex'] == 'F', 'sex'] = 'Female'\n",
    "            #df.loc[df['sex'] == 'M', 'sex'] = 'Male'\n",
    "            \n",
    "            df.loc[df.query(\"`sex` not in ['Male','Female']\").index, 'sex']=np.nan\n",
    "\n",
    "            df.loc[df.query(\"`sex` == 'Male'\").index, 'sex']=2\n",
    "            df.loc[df.query(\"`sex` == 'Female'\").index, 'sex']=1\n",
    "\n",
    "            # Now just do whatever you want with missing values, this below doesn't seem ideal\n",
    "            #df['sex']=df['sex'].fillna(0)\n",
    "            \n",
    "            df.loc[df.query(\"`age` >= 119\").index, 'age']=np.nan\n",
    "            df.loc[df.query(\"`age` <= 18\").index, 'age']=np.nan\n",
    "\n",
    "            df.loc[df['age'] == 'nan', 'age'] = 38\n",
    "            \n",
    "            \n",
    "            df['body.type'].replace(['Run', 'nan'],[1, 0], inplace=True)\n",
    "            \n",
    "            \n",
    "            df['body.timezone'].replace(['America/Boise', 'America/Los_Angeles', 'America/Denver',\n",
    "       'America/New_York', 'America/Chicago', 'America/Detroit'],[1,2,3,4,5,6], inplace=True)\n",
    "            #df.loc[df['body.type'] == 'nan', 'body.type'] = 'No-Run'\n",
    "            #df.loc[df['location.city'] == 'Oklahoma City, OK', 'location.city'] = 'Oklahoma City'\n",
    "    \n",
    "    \n",
    "            #df=df.loc[(df['age']>= 18) & (df['age'] <= 118)]\n",
    "\n",
    "            df['location.state'].replace(['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "             'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI'],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22], inplace=True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            df['result.primary_bracket'].replace(['WHEELCHAIR','nan','Male 25-29','Male 40-44','Female 25-29','Female 20-24','wheelchair'],['Wheelchair',\n",
    "                                'Overall','Male','Male','Female','Female','Wheelchair'], inplace=True)\n",
    "            df['result.primary_bracket'].replace(['Overall','Wheelchair','Male','Female'],[1,2,3,4], inplace=True)\n",
    "      \n",
    "     \n",
    "            df['event.tenant.name'].replace(['Ventures Endurance', 'Avenue of the Giants Marathon',\n",
    "       'Lincoln Park Zoo', 'Strides for Peace Run/Walk',\n",
    "       'Leukemia Research Foundation', 'Chicago Bears',\n",
    "       'Greater Illinois Pediatric Palliative Care Coalition',\n",
    "       'Frank Lloyd Wright Races', 'Worldwide Sport and Social Club',\n",
    "       'St. Clair County Mental Healthy Authority',\n",
    "       'Genesee County Free Medical Clinic', 'Riverbend Striders',\n",
    "       'Everal Race Management', 'CheeseTown Races',\n",
    "       'Higgins Lake 5K/10K/Half Marathon', 'Plymouth YMCA',\n",
    "       'Pickerel Run', 'Habitat for Humanity - Genesee County',\n",
    "       'Scheurer Hospital', 'Atwood 10K Committee', 'Crim Foundation',\n",
    "       'Milford Labor Day 30K', 'RunMackinac Events', 'Dino Dash',\n",
    "       'EnMotive Michigan', 'Detroit Marathon',\n",
    "       'Howell Area Chamber of Commerce', 'EnMotive OKC',\n",
    "       'Ohio Challenge Series', 'HCCC ColorRun ', 'Bowerman 5k ',\n",
    "       'Rotary River Fest Salem', 'Corvallis Lions Club',\n",
    "       'LifeNet Health', 'Allen Stone Memorial Races',\n",
    "       'Chesapeake Beach Civic League', 'Commonwealth Race Management',\n",
    "       'Town Of West Point', 'Cape Henry Collegiate',\n",
    "       'News And Sentinel Half Marathon',\n",
    "       'Milwaukee Brewers Baseball Club'],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41], inplace=True)\n",
    "\n",
    "            df['location.city'].replace(['Scottsdale', 'San Francisco', 'San Diego', 'Arcata', 'Denver',\n",
    "       'Tampa', 'Atlanta', 'Chicago', 'Highland Park',\n",
    "       'Elk Grove Village', 'Oak Park', 'Indianapolis', 'Port Huron',\n",
    "       'Flint', 'Swartz Creek', 'Royal Oak', 'Pinconning', 'Roscommon',\n",
    "       'Plymouth', 'Algonac', 'Fenton', 'Detroit', 'Pigeon',\n",
    "       'Bloomfield Hills', 'Rogers City', 'Caseville', 'Montrose',\n",
    "       'Milford', 'Mackinac Island', 'Sault Ste. Marie', 'East Lansing',\n",
    "       'Williamston', 'Howell', 'Minneapolis', 'St. Louis', 'Santa Fe',\n",
    "       'Charlotte', 'Columbus', 'Canal Fulton', 'Brewster', 'Hartville',\n",
    "       'Strasburg', 'North Canton', 'Clinton', 'Cadiz', 'Dalton',\n",
    "       'Alliance', 'Barberton', 'Millersburg', 'Peninsula', 'Bolivar',\n",
    "       'Massillon', 'Canton', 'Akron', 'Oklahoma City', 'Tulsa', 'Oklahoma City, OK',\n",
    "       'Norman', 'Edmond', 'Lawton', 'Stillwater',\n",
    "       'Moore', 'Perry', 'Seiling', 'Bethany', 'Elk City', 'Sulphur',\n",
    "       'Yukon', 'Beaverton', 'Salem', 'Albany', 'Philadelphia',\n",
    "       'Nashville', 'Houston', 'Dallas', 'Virginia Beach', 'Fairfax',\n",
    "       'West Point', 'Seattle', 'Parkersburg', 'Milwaukee'],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81], inplace=True)\n",
    "\n",
    "    \n",
    "            df['clean_categories.name'].replace(['15k', '5k', 'marathon', 'half marathon', '10k', '5 mile', '8k',\n",
    "       '5k run', '3k walk', '10k run', 'youth mile', '5k run/walk',\n",
    "       '5k walk', '5 mile run', '1 mile run', '15k run', '10k walk',\n",
    "       '6k run', '6k walk', '1 mile walk', '8k run', '8k walk',\n",
    "       '10 mile run', '10 mile walk', '5 mile walk', '30k run',\n",
    "       '30k bike', '8 mile run', '8 mile walk', 'bridge run',\n",
    "       'international half marathon', 'u.s. only half marathon', '1 mile',\n",
    "       '5.7 mile run', '5.7 mile walk', '5k competitive walk',\n",
    "       'half marathon run', '5k fun walk', '5k wheelchair',\n",
    "       '1 mile fun run', '2 mile run', '2 mile walk', '4 mile run/walk',\n",
    "       'life time commitment day 5k', 'midnight streak',\n",
    "       'commitment day 5k - master', 'quarter marathon', '5k walk/run',\n",
    "       '1 mile fun run/walk', 'one mile fun run', '5 km run',\n",
    "       'fire fighter', 'olympic triathlon', 'sprint triathlon',\n",
    "       'olympic duathlon', 'sprint duathlon', '10k scenic challenge',\n",
    "       'run swim run', 'half marathon walk', 'mini-marathon'],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60], inplace=True)\n",
    "\n",
    "            df['event_id'].replace(['583f013a-1e54-4906-87f7-2b625206f5f9',\n",
    "       '5a0dec07-5730-4099-b7a9-6cc05206f5f9',\n",
    "       '5840463a-70d0-46c2-8954-6dbf5206f5f9',\n",
    "       '58405447-64f8-44f8-a81f-01985206f5f9',\n",
    "       '5a5b9a23-ecfc-46ef-8c9f-01e45206f5f9',\n",
    "       '57ed3e2f-5ee8-4195-acf7-4ea75206f5f9',\n",
    "       '59c93fda-556c-4a1c-8609-13895206f5f9',\n",
    "       '583f31b0-c090-4558-b0f6-46c65206f5f9',\n",
    "       '5a2d3288-0390-4f2e-a09a-3b065206f5f9',\n",
    "       '58404d26-eaa8-4c04-82e5-7d045206f5f9',\n",
    "       '5c5cb866-391c-404a-a9f7-540a5206f5f9',\n",
    "       '57bdcd1f-a474-43e0-8e54-5f3a5206f5f9',\n",
    "       '57f3d359-f5d4-4a03-b9f3-29a15206f5f9',\n",
    "       '58fa2ce7-8fe8-4fdc-9675-32785206f5f9',\n",
    "       '590b73b9-2960-4c3f-8b5e-31b35206f5f9',\n",
    "       '59318b7f-12a8-4e32-917b-7b435206f5f9',\n",
    "       '5af9d47d-8c68-4bd0-bee8-58085206f5f9',\n",
    "       '5a317d2c-c22c-4c30-bfab-245c5206f5f9',\n",
    "       '59e90517-5ed0-4796-95fd-77225206f5f9',\n",
    "       '5a8717a6-4e94-4cb0-8a25-0a5c5206f5f9',\n",
    "       '59a99331-e614-4004-8634-16bc5206f5f9',\n",
    "       '59af0a5d-513c-4ed7-9daf-6d845206f5f9',\n",
    "       '5af9a8b2-06a4-40b4-acf6-07ea5206f5f9',\n",
    "       '59c2bd2d-fc20-4efb-86a1-33955206f5f9',\n",
    "       '5a3039c7-7a38-4d18-a7d7-5b765206f5f9',\n",
    "       '590b4d4c-1110-47b9-af8b-202e5206f5f9',\n",
    "       '5a09be9b-336c-4208-a96c-2d505206f5f9',\n",
    "       '5a4d1178-d4d0-4a04-95b5-54d85206f5f9',\n",
    "       '59230b2f-bdb4-45cc-b3ff-76e55206f5f9',\n",
    "       '5a81ddce-186c-4903-adc8-21565206f5f9',\n",
    "       '5a565410-6288-4eeb-8f45-78ea5206f5f9',\n",
    "       '5aa1a8ff-1294-4b04-9044-576b5206f5f9',\n",
    "       '5a980634-efb4-4849-aa0f-17b05206f5f9',\n",
    "       '5a8206d3-d2b4-49b3-843b-11bc5206f5f9',\n",
    "       '5a58fc3d-37d4-43a1-992b-45a55206f5f9',\n",
    "       '5a562b13-b310-42d6-badf-1ad65206f5f9',\n",
    "       '5a70fdf7-cb30-440e-af77-14f75206f5f9',\n",
    "       '5ad8ae00-e10c-4a35-a5c6-5cb35206f5f9',\n",
    "       '5abeadde-ace8-46e4-b456-0fea5206f5f9',\n",
    "       '5aba67c1-a8c8-4f55-a83a-3a0a5206f5f9',\n",
    "       '5aa9724c-b8a8-47e5-98cc-21e65206f5f9',\n",
    "       '5ade1d25-f28c-4137-a080-64105206f5f9',\n",
    "       '5ad385d7-fcd4-423e-ac99-33625206f5f9',\n",
    "       '5b687f64-1074-4f2d-88ca-3d365206f5f9',\n",
    "       '5b217282-ef14-4990-a436-20f55206f5f9',\n",
    "       '5b2bb89e-3204-461e-b6a1-099f5206f5f9',\n",
    "       '5b6b34d6-40b8-483c-826e-68525206f5f9',\n",
    "       '5a43b245-4738-4607-8ed3-1f3c5206f5f9',\n",
    "       '59a4a07f-fa60-4de0-911c-699a5206f5f9',\n",
    "       '5a302f88-f984-4076-aaa1-47c15206f5f9',\n",
    "       '5b153ba0-5f0c-41e7-959c-3fcf5206f5f9',\n",
    "       '5b7adab1-2654-4345-9cc2-0a785206f5f9',\n",
    "       '5b92ca90-34e0-4019-a17b-52bb5206f5f9',\n",
    "       '59a06537-01fc-4bc1-81b7-7ad25206f5f9',\n",
    "       '5b5a2703-9660-4860-b221-32ca5206f5f9',\n",
    "       '58405524-3c70-49fc-a996-6dbf5206f5f9',\n",
    "       '583f2c80-ea88-48bd-a4ba-3f035206f5f9',\n",
    "       '5a1c7352-b910-474e-86c1-40705206f5f9',\n",
    "       '5c6b6a37-8198-40cd-8442-67fc5206f5f9',\n",
    "       '5c6b6b95-7668-471c-934c-5ddb5206f5f9',\n",
    "       '590a3af0-8e04-4e06-ae1b-12405206f5f9',\n",
    "       '583352f9-d400-4da5-a7c8-48645206f5f9',\n",
    "       '59df7a08-d680-41a2-b33e-2eae5206f5f9',\n",
    "       '5a257762-6988-416b-8f13-1f735206f5f9',\n",
    "       '5a4693eb-0408-48d9-ad3c-306c5206f5f9',\n",
    "       '5a6740c3-72d8-4fc3-a844-735e5206f5f9',\n",
    "       '59fba6af-bbe4-442d-972e-3d715206f5f9',\n",
    "       '5a7345e7-3ee8-4b47-a700-30f15206f5f9',\n",
    "       '5a13452c-8df0-4900-8616-2e185206f5f9',\n",
    "       '5a60be6b-8038-4793-b9eb-23255206f5f9',\n",
    "       '5a14428f-9d48-4017-a644-6e8d5206f5f9',\n",
    "       '5a4f98e5-4e38-466e-8669-122a5206f5f9',\n",
    "       '59a2e4ef-2f84-4dd6-a7fe-3ed15206f5f9',\n",
    "       '5a2ec6eb-8c24-4e9c-87aa-41bd5206f5f9',\n",
    "       '59dd4424-fe1c-485c-b6cd-1b485206f5f9',\n",
    "       '5a4fd1c7-b21c-4023-b545-263f5206f5f9',\n",
    "       '5a53aa79-184c-47a6-a2a3-313a5206f5f9',\n",
    "       '5a2ace7a-7b24-4d2a-b676-6c9d5206f5f9',\n",
    "       '5a8ae3f2-7158-495b-ba25-3c085206f5f9',\n",
    "       '59ea2b38-4154-40c8-8aed-6b395206f5f9',\n",
    "       '5a57b9dd-93f0-4abd-81c8-28bc5206f5f9',\n",
    "       '5a66533b-d89c-4478-8f6c-37015206f5f9',\n",
    "       '5a9efd91-b278-458b-9eb4-608a5206f5f9',\n",
    "       '5c6b4275-d2d4-4c55-98a6-44785206f5f9',\n",
    "       '5c87e429-1794-419e-8c84-08485206f5f9',\n",
    "       '5c6b457c-e7dc-47cb-bba7-34db5206f5f9',\n",
    "       '5c7fe534-32c8-45dc-8f21-01bf5206f5f9',\n",
    "       '5c87e6c4-ae88-4da5-ab6d-0e975206f5f9',\n",
    "       '5c6b4b03-157c-4a28-8236-1c545206f5f9',\n",
    "       '5c7ff378-5284-49ef-90d3-31965206f5f9',\n",
    "       '5c6c391e-8e18-4106-8e5a-7aaf5206f5f9',\n",
    "       '5c6c733f-631c-42a9-9b02-11855206f5f9',\n",
    "       '5c6b4dbc-f87c-463c-962e-19915206f5f9',\n",
    "       '5c8941fc-5b00-4c1d-8063-5a7e5206f5f9',\n",
    "       '5c803365-3704-4b3f-8c79-5bfb5206f5f9',\n",
    "       '5c87ee2c-3534-46ba-a49e-08485206f5f9',\n",
    "       '5c6c3c5b-94cc-4f8d-8833-128e5206f5f9',\n",
    "       '5c6c7600-7848-414e-a503-2ca25206f5f9',\n",
    "       '5c802215-eb68-415c-8b78-76555206f5f9',\n",
    "       '5c6b5dbd-ad4c-4558-aecf-5dbe5206f5f9',\n",
    "       '5c802a0a-6190-483b-bd7c-19725206f5f9',\n",
    "       '5c6b30ac-036c-4073-b9e4-198e5206f5f9',\n",
    "       '5c818e6a-0cd4-443a-8d8f-46285206f5f9',\n",
    "       '5c6b3aa2-9b50-43ea-908e-0e4a5206f5f9',\n",
    "       '5c87f0b2-d280-40bd-a827-15405206f5f9',\n",
    "       '5c892c06-6cf0-468b-872d-68695206f5f9',\n",
    "       '5c8025b5-e930-4ab5-b87c-19715206f5f9',\n",
    "       '5c89333f-b684-4593-b87c-7aac5206f5f9',\n",
    "       '5c66f565-61d0-4834-9d32-6c675206f5f9',\n",
    "       '5c6b5e5a-00cc-4c97-a95b-5dd95206f5f9',\n",
    "       '5c6b3572-56a0-4d27-a23e-44785206f5f9',\n",
    "       '5c6c70fc-fd20-4769-9ee1-088e5206f5f9',\n",
    "       '5c802fca-1ee4-4f10-a2be-0e805206f5f9',\n",
    "       '5c89366f-5600-491a-9c27-1f965206f5f9',\n",
    "       '5c82ba4e-aca8-40d8-9ed8-0cbe5206f5f9',\n",
    "       '5c6b3f3c-2ba0-4dad-8764-19915206f5f9',\n",
    "       '5c6c7c8b-bde8-4bc9-91ef-533d5206f5f9',\n",
    "       '5c7fdb4d-3688-46a2-b808-45615206f5f9',\n",
    "       '5c82ca25-1eec-4427-871f-7b095206f5f9',\n",
    "       '5c87f30e-bf94-41ab-b234-15415206f5f9',\n",
    "       '5c6b5ef7-6c28-4774-afbc-67d45206f5f9',\n",
    "       '5c893fc1-44d8-48e7-8844-5a785206f5f9',\n",
    "       '5c019c1b-b370-4732-aa47-1db25206f5f9',\n",
    "       '5bcf4f57-8658-4484-84b4-165c5206f5f9',\n",
    "       '59b6bd5d-1008-4d2c-8194-263b5206f5f9',\n",
    "       '5a54f181-e37c-41da-9f62-42925206f5f9',\n",
    "       '5a393a3a-7628-4bce-b9ea-556b5206f5f9',\n",
    "       '584054cb-f3d8-4c38-b560-03135206f5f9',\n",
    "       '5840533c-27a0-4c85-8603-7a475206f5f9',\n",
    "       '590a3e6e-ac64-4341-af5b-18165206f5f9',\n",
    "       '5840528b-6010-4133-8fef-7d065206f5f9',\n",
    "       '5e862221-758c-48b1-a7cf-11bcc0a80a41',\n",
    "       '5e860049-7e9c-4f9d-9911-37c4c0a80a41',\n",
    "       '5e8622bc-0ef4-472a-a19b-6f4bc0a80a41',\n",
    "       '5e83a2da-3c78-430f-95aa-236fc0a80a41',\n",
    "       '5e86018d-79d4-4d30-998e-69e6c0a80a41',\n",
    "       '5e862439-c108-40be-b3ec-36b6c0a80a41',\n",
    "       '5e791e51-81d0-48f5-a6c1-31e3c0a80a41',\n",
    "       '59f0f5dc-31bc-41b6-860b-0a415206f5f9',\n",
    "       '5e83a579-e5c4-45a1-82bd-792ec0a80a41',\n",
    "       '5e86031d-5590-4c2b-97a6-44d6c0a80a41',\n",
    "       '5d24927d-161c-4287-9ef7-7494c0a80a41',\n",
    "       '58405401-f23c-46b2-8dfc-032d5206f5f9',\n",
    "       '5a5e3aba-95d4-4577-bbe8-67375206f5f9',\n",
    "       '5b7ae951-7e04-4262-a599-2f745206f5f9'],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145], inplace=True)\n",
    "\n",
    "            df=df.fillna(0)\n",
    "            \n",
    "            # For brevity let's get rid of any sex that isn't Male/Female and replace with nan\n",
    "            # A better approach would be to inspect and map this data accordingly, but I'll leave\n",
    "            # that as an enhancement.\n",
    "            #df.loc[df.query(\"`sex` not in ['Male','Female']\").index, 'sex']=np.nan\n",
    "            \n",
    "            # Now that this is binary we can convert this column into a numeric value\n",
    "            #df.loc[df.query(\"`sex` == 'Male'\").index, 'sex']=1\n",
    "            #df.loc[df.query(\"`sex` == 'Female'\").index, 'sex']=0\n",
    "            \n",
    "            # Now just do whatever you want with missing values, this below doesn't seem ideal\n",
    "            #df=df.fillna(0)\n",
    "            \n",
    "            # With the data cleaning done, we can now predict the times for our data\n",
    "            times=self.regressor.predict(df)\n",
    "            \n",
    "            # We can't return the times directly - the autograder wants ranks. We can\n",
    "            # use a similar method those to return ranks\n",
    "            return times.squeeze().argsort()+1\n",
    "    \n",
    "    # Our return class is done, now we just need to initalize it with a fitted\n",
    "    # model. To fit the model we just do all of the cleaning over, and add in some training.\n",
    "    # It would be a better ideal to put this all in the class itself, but I want to\n",
    "    # show you that this isn't needed -- the autograder is NOT going to try and fit()\n",
    "    # your model, it is only going to call predict(), so you can do whatever you want\n",
    "    # within that predict()\n",
    "    \n",
    "   #\"event.date.start\" \"counts.participants.expected\",\n",
    "    df=train[[\"age\",\"sex\",\"clean_categories.name\",\"body.type\",\"event.id\",\"location.state\",\"location.city\",\"body.timezone\", \"event.tenant.name\",\n",
    "              \"result.primary_bracket\",\"counts.participants.registered\"]]   \n",
    "            #\"event.images.email.header\",\"event.images.email.footer\",\"category.registered.distance.quantity\",\"category.registered.distance.unit\",\n",
    "    \n",
    "    df=df.rename(columns={'event.id':'event_id'})\n",
    "    \n",
    "    df.loc[df.query(\"`sex` not in ['Male','Female']\").index, 'sex']=np.nan\n",
    "    df.loc[df.query(\"`sex` == 'Male'\").index, 'sex']=1\n",
    "    df.loc[df.query(\"`sex` == 'Female'\").index, 'sex']=0\n",
    "    #df=df.fillna(0)\n",
    "    \n",
    "    #df['event.date.start'] = df['event.date.start'].astype(float)\n",
    "    #df.loc[df['sex'] == 'F', 'sex'] = 'Female'\n",
    "    #df.loc[df['sex'] == 'M', 'sex'] = 'Male'\n",
    "    #df.loc[df.query(\"`sex` not in ['Male','Female']\").index, 'sex']=np.nan\n",
    "\n",
    "    #df.loc[df.query(\"`sex` == 'Male'\").index, 'sex']=2\n",
    "    #df.loc[df.query(\"`sex` == 'Female'\").index, 'sex']=1\n",
    "\n",
    "    # Now just do whatever you want with missing values, this below doesn't seem ideal\n",
    "    #df['sex']=df['sex'].dropna()\n",
    "    \n",
    "    df.loc[df.query(\"`age` >= 119\").index, 'age']=np.nan\n",
    "    df.loc[df.query(\"`age` <= 18\").index, 'age']=np.nan\n",
    "    \n",
    "    df.loc[df['age'] == 'nan', 'age'] = 38\n",
    "    \n",
    "    df['body.type'].replace(['Run', 'nan'],[1, 0], inplace=True)\n",
    "\n",
    "    \n",
    "    df['body.timezone'].replace(['America/Boise', 'America/Los_Angeles', 'America/Denver',\n",
    "       'America/New_York', 'America/Chicago', 'America/Detroit'],[1,2,3,4,5,6], inplace=True)\n",
    "    \n",
    "    #df.loc[df['body.type'] == 'nan', 'body.type'] = 'No-Run'\n",
    "    #df.loc[df['location.city'] == 'Oklahoma City, OK', 'location.city'] = 'Oklahoma City'\n",
    "    \n",
    "    \n",
    "    #df=df.loc[(df['age']>= 18) & (df['age'] <= 118)]\n",
    "    \n",
    "    df['location.state'].replace(['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI'],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22], inplace=True)\n",
    "    \n",
    "    df['result.primary_bracket'].replace(['WHEELCHAIR','nan','Male 25-29','Male 40-44','Female 25-29','Female 20-24','wheelchair'],['Wheelchair','Overall','Male','Male','Female','Female','Wheelchair'], inplace=True)\n",
    "    df['result.primary_bracket'].replace(['Overall','Wheelchair','Male','Female'],[1,2,3,4], inplace=True)\n",
    "    \n",
    "    \n",
    "    df['event.tenant.name'].replace(['Ventures Endurance', 'Avenue of the Giants Marathon',\n",
    "       'Lincoln Park Zoo', 'Strides for Peace Run/Walk',\n",
    "       'Leukemia Research Foundation', 'Chicago Bears',\n",
    "       'Greater Illinois Pediatric Palliative Care Coalition',\n",
    "       'Frank Lloyd Wright Races', 'Worldwide Sport and Social Club',\n",
    "       'St. Clair County Mental Healthy Authority',\n",
    "       'Genesee County Free Medical Clinic', 'Riverbend Striders',\n",
    "       'Everal Race Management', 'CheeseTown Races',\n",
    "       'Higgins Lake 5K/10K/Half Marathon', 'Plymouth YMCA',\n",
    "       'Pickerel Run', 'Habitat for Humanity - Genesee County',\n",
    "       'Scheurer Hospital', 'Atwood 10K Committee', 'Crim Foundation',\n",
    "       'Milford Labor Day 30K', 'RunMackinac Events', 'Dino Dash',\n",
    "       'EnMotive Michigan', 'Detroit Marathon',\n",
    "       'Howell Area Chamber of Commerce', 'EnMotive OKC',\n",
    "       'Ohio Challenge Series', 'HCCC ColorRun ', 'Bowerman 5k ',\n",
    "       'Rotary River Fest Salem', 'Corvallis Lions Club',\n",
    "       'LifeNet Health', 'Allen Stone Memorial Races',\n",
    "       'Chesapeake Beach Civic League', 'Commonwealth Race Management',\n",
    "       'Town Of West Point', 'Cape Henry Collegiate',\n",
    "       'News And Sentinel Half Marathon',\n",
    "       'Milwaukee Brewers Baseball Club'],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41], inplace=True)\n",
    "    \n",
    "    df['location.city'].replace(['Scottsdale', 'San Francisco', 'San Diego', 'Arcata', 'Denver',\n",
    "       'Tampa', 'Atlanta', 'Chicago', 'Highland Park',\n",
    "       'Elk Grove Village', 'Oak Park', 'Indianapolis', 'Port Huron',\n",
    "       'Flint', 'Swartz Creek', 'Royal Oak', 'Pinconning', 'Roscommon',\n",
    "       'Plymouth', 'Algonac', 'Fenton', 'Detroit', 'Pigeon',\n",
    "       'Bloomfield Hills', 'Rogers City', 'Caseville', 'Montrose',\n",
    "       'Milford', 'Mackinac Island', 'Sault Ste. Marie', 'East Lansing',\n",
    "       'Williamston', 'Howell', 'Minneapolis', 'St. Louis', 'Santa Fe',\n",
    "       'Charlotte', 'Columbus', 'Canal Fulton', 'Brewster', 'Hartville',\n",
    "       'Strasburg', 'North Canton', 'Clinton', 'Cadiz', 'Dalton',\n",
    "       'Alliance', 'Barberton', 'Millersburg', 'Peninsula', 'Bolivar',\n",
    "       'Massillon', 'Canton', 'Akron', 'Oklahoma City', 'Tulsa', 'Oklahoma City, OK',\n",
    "       'Norman', 'Edmond', 'Lawton', 'Stillwater',\n",
    "       'Moore', 'Perry', 'Seiling', 'Bethany', 'Elk City', 'Sulphur',\n",
    "       'Yukon', 'Beaverton', 'Salem', 'Albany', 'Philadelphia',\n",
    "       'Nashville', 'Houston', 'Dallas', 'Virginia Beach', 'Fairfax',\n",
    "       'West Point', 'Seattle', 'Parkersburg', 'Milwaukee'],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81], inplace=True)\n",
    "    \n",
    "    \n",
    "    df['clean_categories.name'].replace(['15k', '5k', 'marathon', 'half marathon', '10k', '5 mile', '8k',\n",
    "       '5k run', '3k walk', '10k run', 'youth mile', '5k run/walk',\n",
    "       '5k walk', '5 mile run', '1 mile run', '15k run', '10k walk',\n",
    "       '6k run', '6k walk', '1 mile walk', '8k run', '8k walk',\n",
    "       '10 mile run', '10 mile walk', '5 mile walk', '30k run',\n",
    "       '30k bike', '8 mile run', '8 mile walk', 'bridge run',\n",
    "       'international half marathon', 'u.s. only half marathon', '1 mile',\n",
    "       '5.7 mile run', '5.7 mile walk', '5k competitive walk',\n",
    "       'half marathon run', '5k fun walk', '5k wheelchair',\n",
    "       '1 mile fun run', '2 mile run', '2 mile walk', '4 mile run/walk',\n",
    "       'life time commitment day 5k', 'midnight streak',\n",
    "       'commitment day 5k - master', 'quarter marathon', '5k walk/run',\n",
    "       '1 mile fun run/walk', 'one mile fun run', '5 km run',\n",
    "       'fire fighter', 'olympic triathlon', 'sprint triathlon',\n",
    "       'olympic duathlon', 'sprint duathlon', '10k scenic challenge',\n",
    "       'run swim run', 'half marathon walk', 'mini-marathon'],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60], inplace=True)\n",
    "    \n",
    "    df['event_id'].replace(['583f013a-1e54-4906-87f7-2b625206f5f9',\n",
    "       '5a0dec07-5730-4099-b7a9-6cc05206f5f9',\n",
    "       '5840463a-70d0-46c2-8954-6dbf5206f5f9',\n",
    "       '58405447-64f8-44f8-a81f-01985206f5f9',\n",
    "       '5a5b9a23-ecfc-46ef-8c9f-01e45206f5f9',\n",
    "       '57ed3e2f-5ee8-4195-acf7-4ea75206f5f9',\n",
    "       '59c93fda-556c-4a1c-8609-13895206f5f9',\n",
    "       '583f31b0-c090-4558-b0f6-46c65206f5f9',\n",
    "       '5a2d3288-0390-4f2e-a09a-3b065206f5f9',\n",
    "       '58404d26-eaa8-4c04-82e5-7d045206f5f9',\n",
    "       '5c5cb866-391c-404a-a9f7-540a5206f5f9',\n",
    "       '57bdcd1f-a474-43e0-8e54-5f3a5206f5f9',\n",
    "       '57f3d359-f5d4-4a03-b9f3-29a15206f5f9',\n",
    "       '58fa2ce7-8fe8-4fdc-9675-32785206f5f9',\n",
    "       '590b73b9-2960-4c3f-8b5e-31b35206f5f9',\n",
    "       '59318b7f-12a8-4e32-917b-7b435206f5f9',\n",
    "       '5af9d47d-8c68-4bd0-bee8-58085206f5f9',\n",
    "       '5a317d2c-c22c-4c30-bfab-245c5206f5f9',\n",
    "       '59e90517-5ed0-4796-95fd-77225206f5f9',\n",
    "       '5a8717a6-4e94-4cb0-8a25-0a5c5206f5f9',\n",
    "       '59a99331-e614-4004-8634-16bc5206f5f9',\n",
    "       '59af0a5d-513c-4ed7-9daf-6d845206f5f9',\n",
    "       '5af9a8b2-06a4-40b4-acf6-07ea5206f5f9',\n",
    "       '59c2bd2d-fc20-4efb-86a1-33955206f5f9',\n",
    "       '5a3039c7-7a38-4d18-a7d7-5b765206f5f9',\n",
    "       '590b4d4c-1110-47b9-af8b-202e5206f5f9',\n",
    "       '5a09be9b-336c-4208-a96c-2d505206f5f9',\n",
    "       '5a4d1178-d4d0-4a04-95b5-54d85206f5f9',\n",
    "       '59230b2f-bdb4-45cc-b3ff-76e55206f5f9',\n",
    "       '5a81ddce-186c-4903-adc8-21565206f5f9',\n",
    "       '5a565410-6288-4eeb-8f45-78ea5206f5f9',\n",
    "       '5aa1a8ff-1294-4b04-9044-576b5206f5f9',\n",
    "       '5a980634-efb4-4849-aa0f-17b05206f5f9',\n",
    "       '5a8206d3-d2b4-49b3-843b-11bc5206f5f9',\n",
    "       '5a58fc3d-37d4-43a1-992b-45a55206f5f9',\n",
    "       '5a562b13-b310-42d6-badf-1ad65206f5f9',\n",
    "       '5a70fdf7-cb30-440e-af77-14f75206f5f9',\n",
    "       '5ad8ae00-e10c-4a35-a5c6-5cb35206f5f9',\n",
    "       '5abeadde-ace8-46e4-b456-0fea5206f5f9',\n",
    "       '5aba67c1-a8c8-4f55-a83a-3a0a5206f5f9',\n",
    "       '5aa9724c-b8a8-47e5-98cc-21e65206f5f9',\n",
    "       '5ade1d25-f28c-4137-a080-64105206f5f9',\n",
    "       '5ad385d7-fcd4-423e-ac99-33625206f5f9',\n",
    "       '5b687f64-1074-4f2d-88ca-3d365206f5f9',\n",
    "       '5b217282-ef14-4990-a436-20f55206f5f9',\n",
    "       '5b2bb89e-3204-461e-b6a1-099f5206f5f9',\n",
    "       '5b6b34d6-40b8-483c-826e-68525206f5f9',\n",
    "       '5a43b245-4738-4607-8ed3-1f3c5206f5f9',\n",
    "       '59a4a07f-fa60-4de0-911c-699a5206f5f9',\n",
    "       '5a302f88-f984-4076-aaa1-47c15206f5f9',\n",
    "       '5b153ba0-5f0c-41e7-959c-3fcf5206f5f9',\n",
    "       '5b7adab1-2654-4345-9cc2-0a785206f5f9',\n",
    "       '5b92ca90-34e0-4019-a17b-52bb5206f5f9',\n",
    "       '59a06537-01fc-4bc1-81b7-7ad25206f5f9',\n",
    "       '5b5a2703-9660-4860-b221-32ca5206f5f9',\n",
    "       '58405524-3c70-49fc-a996-6dbf5206f5f9',\n",
    "       '583f2c80-ea88-48bd-a4ba-3f035206f5f9',\n",
    "       '5a1c7352-b910-474e-86c1-40705206f5f9',\n",
    "       '5c6b6a37-8198-40cd-8442-67fc5206f5f9',\n",
    "       '5c6b6b95-7668-471c-934c-5ddb5206f5f9',\n",
    "       '590a3af0-8e04-4e06-ae1b-12405206f5f9',\n",
    "       '583352f9-d400-4da5-a7c8-48645206f5f9',\n",
    "       '59df7a08-d680-41a2-b33e-2eae5206f5f9',\n",
    "       '5a257762-6988-416b-8f13-1f735206f5f9',\n",
    "       '5a4693eb-0408-48d9-ad3c-306c5206f5f9',\n",
    "       '5a6740c3-72d8-4fc3-a844-735e5206f5f9',\n",
    "       '59fba6af-bbe4-442d-972e-3d715206f5f9',\n",
    "       '5a7345e7-3ee8-4b47-a700-30f15206f5f9',\n",
    "       '5a13452c-8df0-4900-8616-2e185206f5f9',\n",
    "       '5a60be6b-8038-4793-b9eb-23255206f5f9',\n",
    "       '5a14428f-9d48-4017-a644-6e8d5206f5f9',\n",
    "       '5a4f98e5-4e38-466e-8669-122a5206f5f9',\n",
    "       '59a2e4ef-2f84-4dd6-a7fe-3ed15206f5f9',\n",
    "       '5a2ec6eb-8c24-4e9c-87aa-41bd5206f5f9',\n",
    "       '59dd4424-fe1c-485c-b6cd-1b485206f5f9',\n",
    "       '5a4fd1c7-b21c-4023-b545-263f5206f5f9',\n",
    "       '5a53aa79-184c-47a6-a2a3-313a5206f5f9',\n",
    "       '5a2ace7a-7b24-4d2a-b676-6c9d5206f5f9',\n",
    "       '5a8ae3f2-7158-495b-ba25-3c085206f5f9',\n",
    "       '59ea2b38-4154-40c8-8aed-6b395206f5f9',\n",
    "       '5a57b9dd-93f0-4abd-81c8-28bc5206f5f9',\n",
    "       '5a66533b-d89c-4478-8f6c-37015206f5f9',\n",
    "       '5a9efd91-b278-458b-9eb4-608a5206f5f9',\n",
    "       '5c6b4275-d2d4-4c55-98a6-44785206f5f9',\n",
    "       '5c87e429-1794-419e-8c84-08485206f5f9',\n",
    "       '5c6b457c-e7dc-47cb-bba7-34db5206f5f9',\n",
    "       '5c7fe534-32c8-45dc-8f21-01bf5206f5f9',\n",
    "       '5c87e6c4-ae88-4da5-ab6d-0e975206f5f9',\n",
    "       '5c6b4b03-157c-4a28-8236-1c545206f5f9',\n",
    "       '5c7ff378-5284-49ef-90d3-31965206f5f9',\n",
    "       '5c6c391e-8e18-4106-8e5a-7aaf5206f5f9',\n",
    "       '5c6c733f-631c-42a9-9b02-11855206f5f9',\n",
    "       '5c6b4dbc-f87c-463c-962e-19915206f5f9',\n",
    "       '5c8941fc-5b00-4c1d-8063-5a7e5206f5f9',\n",
    "       '5c803365-3704-4b3f-8c79-5bfb5206f5f9',\n",
    "       '5c87ee2c-3534-46ba-a49e-08485206f5f9',\n",
    "       '5c6c3c5b-94cc-4f8d-8833-128e5206f5f9',\n",
    "       '5c6c7600-7848-414e-a503-2ca25206f5f9',\n",
    "       '5c802215-eb68-415c-8b78-76555206f5f9',\n",
    "       '5c6b5dbd-ad4c-4558-aecf-5dbe5206f5f9',\n",
    "       '5c802a0a-6190-483b-bd7c-19725206f5f9',\n",
    "       '5c6b30ac-036c-4073-b9e4-198e5206f5f9',\n",
    "       '5c818e6a-0cd4-443a-8d8f-46285206f5f9',\n",
    "       '5c6b3aa2-9b50-43ea-908e-0e4a5206f5f9',\n",
    "       '5c87f0b2-d280-40bd-a827-15405206f5f9',\n",
    "       '5c892c06-6cf0-468b-872d-68695206f5f9',\n",
    "       '5c8025b5-e930-4ab5-b87c-19715206f5f9',\n",
    "       '5c89333f-b684-4593-b87c-7aac5206f5f9',\n",
    "       '5c66f565-61d0-4834-9d32-6c675206f5f9',\n",
    "       '5c6b5e5a-00cc-4c97-a95b-5dd95206f5f9',\n",
    "       '5c6b3572-56a0-4d27-a23e-44785206f5f9',\n",
    "       '5c6c70fc-fd20-4769-9ee1-088e5206f5f9',\n",
    "       '5c802fca-1ee4-4f10-a2be-0e805206f5f9',\n",
    "       '5c89366f-5600-491a-9c27-1f965206f5f9',\n",
    "       '5c82ba4e-aca8-40d8-9ed8-0cbe5206f5f9',\n",
    "       '5c6b3f3c-2ba0-4dad-8764-19915206f5f9',\n",
    "       '5c6c7c8b-bde8-4bc9-91ef-533d5206f5f9',\n",
    "       '5c7fdb4d-3688-46a2-b808-45615206f5f9',\n",
    "       '5c82ca25-1eec-4427-871f-7b095206f5f9',\n",
    "       '5c87f30e-bf94-41ab-b234-15415206f5f9',\n",
    "       '5c6b5ef7-6c28-4774-afbc-67d45206f5f9',\n",
    "       '5c893fc1-44d8-48e7-8844-5a785206f5f9',\n",
    "       '5c019c1b-b370-4732-aa47-1db25206f5f9',\n",
    "       '5bcf4f57-8658-4484-84b4-165c5206f5f9',\n",
    "       '59b6bd5d-1008-4d2c-8194-263b5206f5f9',\n",
    "       '5a54f181-e37c-41da-9f62-42925206f5f9',\n",
    "       '5a393a3a-7628-4bce-b9ea-556b5206f5f9',\n",
    "       '584054cb-f3d8-4c38-b560-03135206f5f9',\n",
    "       '5840533c-27a0-4c85-8603-7a475206f5f9',\n",
    "       '590a3e6e-ac64-4341-af5b-18165206f5f9',\n",
    "       '5840528b-6010-4133-8fef-7d065206f5f9',\n",
    "       '5e862221-758c-48b1-a7cf-11bcc0a80a41',\n",
    "       '5e860049-7e9c-4f9d-9911-37c4c0a80a41',\n",
    "       '5e8622bc-0ef4-472a-a19b-6f4bc0a80a41',\n",
    "       '5e83a2da-3c78-430f-95aa-236fc0a80a41',\n",
    "       '5e86018d-79d4-4d30-998e-69e6c0a80a41',\n",
    "       '5e862439-c108-40be-b3ec-36b6c0a80a41',\n",
    "       '5e791e51-81d0-48f5-a6c1-31e3c0a80a41',\n",
    "       '59f0f5dc-31bc-41b6-860b-0a415206f5f9',\n",
    "       '5e83a579-e5c4-45a1-82bd-792ec0a80a41',\n",
    "       '5e86031d-5590-4c2b-97a6-44d6c0a80a41',\n",
    "       '5d24927d-161c-4287-9ef7-7494c0a80a41',\n",
    "       '58405401-f23c-46b2-8dfc-032d5206f5f9',\n",
    "       '5a5e3aba-95d4-4577-bbe8-67375206f5f9',\n",
    "       '5b7ae951-7e04-4262-a599-2f745206f5f9'],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145], inplace=True)\n",
    "    \n",
    "    df=df.fillna(0)\n",
    "    \n",
    "    # Since we have decided it's a regression problem, we can decide to use a simple linear\n",
    "    # model for our first attempt too, so I'll create that now\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    reg=RandomForestRegressor()\n",
    "    reg.fit(df,y)\n",
    "    \n",
    "    # Now we just return the object that the autograder will want\n",
    "    return RollingRegressor(reg)\n",
    "    \n",
    "# We can test this out by instantiating it\n",
    "fitted_reg=roll_own()\n",
    "# Then saving it to a file\n",
    "cloudpickle.dump(fitted_reg, open('pipeline.cloudpickle','wb'))\n",
    "# Then telling the autograder function to fire\n",
    "autograde(holdout_data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebc8a32-7e2a-41ce-9332-436a0a10efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, GridSearchCV, cross_validate, KFold\n",
    "#X_train = train.filter(items=[\"age\",\"sex\",\"clean_categories.name\",\"body.type\",\"event.id\",\"location.state\",\"location.city\",\"body.timezone\", \"event.tenant.name\",\n",
    "#              \"result.primary_bracket\",\"counts.participants.registered\"])\n",
    "#y_train = train.filter(items=['overall_ranking'])\n",
    "\n",
    "#X_holdout = holdout.filter(items=[\"age\",\"sex\",\"clean_categories.name\",\"body.type\",\"event.id\",\"location.state\",\"location.city\",\"body.timezone\", \"event.tenant.name\",\n",
    "#              \"result.primary_bracket\",\"counts.participants.registered\"])\n",
    "#y_holdout = holdout.filter(items=['overall_ranking'])\n",
    "\n",
    "#X_test = test.filter(items=[\"age\",\"sex\",\"clean_categories.name\",\"body.type\",\"event.id\",\"location.state\",\"location.city\",\"body.timezone\", \"event.tenant.name\",\n",
    "#              \"result.primary_bracket\",\"counts.participants.registered\"])\n",
    "#y_test = test.filter(items=['overall_ranking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "114faceb-be86-489b-8579-287fe6cfc8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;sex&#x27;,\n",
       "                                                  OneHotEncoder(categories=[[&#x27;Male&#x27;,\n",
       "                                                                             &#x27;Female&#x27;]],\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;sex&#x27;]),\n",
       "                                                 (&#x27;age&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [&#x27;age&#x27;]),\n",
       "                                                 (&#x27;event.date.start&#x27;,\n",
       "                                                  OneHotEncoder(categories=[[&#x27;2017-12-03&#x27;,\n",
       "                                                                             &#x27;2018-12-02&#x27;,\n",
       "                                                                             &#x27;2018-01-07&#x27;,\n",
       "                                                                             &#x27;2018-03-18&#x27;,\n",
       "                                                                             &#x27;2018-05-06&#x27;,\n",
       "                                                                             &#x27;2017-10-01&#x27;,\n",
       "                                                                             &#x27;2018-10-07&#x27;,\n",
       "                                                                             &#x27;2017-12-17&#x27;,\n",
       "                                                                             &#x27;2018-12-16&#x27;,\n",
       "                                                                             &#x27;2018-02-04...\n",
       "                                                  [&#x27;event.tenant.name&#x27;]),\n",
       "                                                 (&#x27;result.primary_bracket&#x27;,\n",
       "                                                  OneHotEncoder(categories=[[&#x27;Overall&#x27;,\n",
       "                                                                             &#x27;Wheelchair&#x27;,\n",
       "                                                                             &#x27;Male&#x27;,\n",
       "                                                                             &#x27;Female&#x27;]],\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;result.primary_bracket&#x27;])])),\n",
       "                (&#x27;fix_nans&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                (&#x27;regressor&#x27;,\n",
       "                 TransformedTargetRegressor(inverse_func=&lt;function evaluation_function at 0x7f9c9ddf2d30&gt;,\n",
       "                                            regressor=RandomForestRegressor()))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;sex&#x27;,\n",
       "                                                  OneHotEncoder(categories=[[&#x27;Male&#x27;,\n",
       "                                                                             &#x27;Female&#x27;]],\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;sex&#x27;]),\n",
       "                                                 (&#x27;age&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [&#x27;age&#x27;]),\n",
       "                                                 (&#x27;event.date.start&#x27;,\n",
       "                                                  OneHotEncoder(categories=[[&#x27;2017-12-03&#x27;,\n",
       "                                                                             &#x27;2018-12-02&#x27;,\n",
       "                                                                             &#x27;2018-01-07&#x27;,\n",
       "                                                                             &#x27;2018-03-18&#x27;,\n",
       "                                                                             &#x27;2018-05-06&#x27;,\n",
       "                                                                             &#x27;2017-10-01&#x27;,\n",
       "                                                                             &#x27;2018-10-07&#x27;,\n",
       "                                                                             &#x27;2017-12-17&#x27;,\n",
       "                                                                             &#x27;2018-12-16&#x27;,\n",
       "                                                                             &#x27;2018-02-04...\n",
       "                                                  [&#x27;event.tenant.name&#x27;]),\n",
       "                                                 (&#x27;result.primary_bracket&#x27;,\n",
       "                                                  OneHotEncoder(categories=[[&#x27;Overall&#x27;,\n",
       "                                                                             &#x27;Wheelchair&#x27;,\n",
       "                                                                             &#x27;Male&#x27;,\n",
       "                                                                             &#x27;Female&#x27;]],\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;result.primary_bracket&#x27;])])),\n",
       "                (&#x27;fix_nans&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                (&#x27;regressor&#x27;,\n",
       "                 TransformedTargetRegressor(inverse_func=&lt;function evaluation_function at 0x7f9c9ddf2d30&gt;,\n",
       "                                            regressor=RandomForestRegressor()))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cleaner: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;sex&#x27;,\n",
       "                                 OneHotEncoder(categories=[[&#x27;Male&#x27;, &#x27;Female&#x27;]],\n",
       "                                               handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;sex&#x27;]),\n",
       "                                (&#x27;age&#x27;, &#x27;passthrough&#x27;, [&#x27;age&#x27;]),\n",
       "                                (&#x27;event.date.start&#x27;,\n",
       "                                 OneHotEncoder(categories=[[&#x27;2017-12-03&#x27;,\n",
       "                                                            &#x27;2018-12-02&#x27;,\n",
       "                                                            &#x27;2018-01-07&#x27;,\n",
       "                                                            &#x27;2018-03-18&#x27;,\n",
       "                                                            &#x27;2018-05-06&#x27;,\n",
       "                                                            &#x27;2017-10-01&#x27;,\n",
       "                                                            &#x27;2018-10-07&#x27;,\n",
       "                                                            &#x27;2017-12-17&#x27;,\n",
       "                                                            &#x27;2018-12-16&#x27;,\n",
       "                                                            &#x27;2018-02-04&#x27;,\n",
       "                                                            &#x27;2017-06-04&#x27;,\n",
       "                                                            &#x27;2017-09-09&#x27;...\n",
       "                                                            &#x27;RunMackinac &#x27;\n",
       "                                                            &#x27;Events&#x27;,\n",
       "                                                            &#x27;Dino Dash&#x27;,\n",
       "                                                            &#x27;EnMotive Michigan&#x27;,\n",
       "                                                            &#x27;Detroit Marathon&#x27;,\n",
       "                                                            &#x27;Howell Area &#x27;\n",
       "                                                            &#x27;Chamber of &#x27;\n",
       "                                                            &#x27;Commerce&#x27;,\n",
       "                                                            &#x27;EnMotive OKC&#x27;,\n",
       "                                                            &#x27;Ohio Challenge &#x27;\n",
       "                                                            &#x27;Series&#x27;,\n",
       "                                                            &#x27;HCCC ColorRun &#x27;, ...]],\n",
       "                                               handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;event.tenant.name&#x27;]),\n",
       "                                (&#x27;result.primary_bracket&#x27;,\n",
       "                                 OneHotEncoder(categories=[[&#x27;Overall&#x27;,\n",
       "                                                            &#x27;Wheelchair&#x27;,\n",
       "                                                            &#x27;Male&#x27;, &#x27;Female&#x27;]],\n",
       "                                               handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;result.primary_bracket&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">sex</label><div class=\"sk-toggleable__content\"><pre>[&#x27;sex&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(categories=[[&#x27;Male&#x27;, &#x27;Female&#x27;]], handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">age</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" ><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">event.date.start</label><div class=\"sk-toggleable__content\"><pre>[&#x27;event.date.start&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(categories=[[&#x27;2017-12-03&#x27;, &#x27;2018-12-02&#x27;, &#x27;2018-01-07&#x27;,\n",
       "                           &#x27;2018-03-18&#x27;, &#x27;2018-05-06&#x27;, &#x27;2017-10-01&#x27;,\n",
       "                           &#x27;2018-10-07&#x27;, &#x27;2017-12-17&#x27;, &#x27;2018-12-16&#x27;,\n",
       "                           &#x27;2018-02-04&#x27;, &#x27;2017-06-04&#x27;, &#x27;2017-09-09&#x27;,\n",
       "                           &#x27;2017-10-29&#x27;, &#x27;2018-04-29&#x27;, &#x27;2018-05-05&#x27;,\n",
       "                           &#x27;2018-06-03&#x27;, &#x27;2018-06-07&#x27;, &#x27;2018-06-21&#x27;,\n",
       "                           &#x27;2018-06-23&#x27;, &#x27;2018-09-08&#x27;, &#x27;2018-09-30&#x27;,\n",
       "                           &#x27;2018-10-14&#x27;, &#x27;2018-10-20&#x27;, &#x27;2018-10-21&#x27;,\n",
       "                           &#x27;2018-11-04&#x27;, &#x27;2018-11-22&#x27;, &#x27;2018-12-31&#x27;,\n",
       "                           &#x27;2018-03-24&#x27;, &#x27;2018-05-12&#x27;, &#x27;2018-05-31&#x27;, ...]],\n",
       "              handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">clean_categories.name</label><div class=\"sk-toggleable__content\"><pre>[&#x27;clean_categories.name&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(categories=[[&#x27;15k&#x27;, &#x27;5k&#x27;, &#x27;marathon&#x27;, &#x27;half marathon&#x27;, &#x27;10k&#x27;,\n",
       "                           &#x27;5 mile&#x27;, &#x27;8k&#x27;, &#x27;5k run&#x27;, &#x27;3k walk&#x27;, &#x27;10k run&#x27;,\n",
       "                           &#x27;youth mile&#x27;, &#x27;5k run/walk&#x27;, &#x27;5k walk&#x27;, &#x27;5 mile run&#x27;,\n",
       "                           &#x27;1 mile run&#x27;, &#x27;15k run&#x27;, &#x27;10k walk&#x27;, &#x27;6k run&#x27;,\n",
       "                           &#x27;6k walk&#x27;, &#x27;1 mile walk&#x27;, &#x27;8k run&#x27;, &#x27;8k walk&#x27;,\n",
       "                           &#x27;10 mile run&#x27;, &#x27;10 mile walk&#x27;, &#x27;5 mile walk&#x27;,\n",
       "                           &#x27;30k run&#x27;, &#x27;30k bike&#x27;, &#x27;8 mile run&#x27;, &#x27;8 mile walk&#x27;,\n",
       "                           &#x27;bridge run&#x27;, ...]],\n",
       "              handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" ><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">location.state</label><div class=\"sk-toggleable__content\"><pre>[&#x27;location.state&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-84\" type=\"checkbox\" ><label for=\"sk-estimator-id-84\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(categories=[[&#x27;AZ&#x27;, &#x27;CA&#x27;, &#x27;CO&#x27;, &#x27;FL&#x27;, &#x27;GA&#x27;, &#x27;IL&#x27;, &#x27;IN&#x27;, &#x27;MI&#x27;, &#x27;MN&#x27;,\n",
       "                           &#x27;MO&#x27;, &#x27;NM&#x27;, &#x27;NC&#x27;, &#x27;OH&#x27;, &#x27;OK&#x27;, &#x27;OR&#x27;, &#x27;PA&#x27;, &#x27;TN&#x27;, &#x27;TX&#x27;,\n",
       "                           &#x27;VA&#x27;, &#x27;WA&#x27;, &#x27;WV&#x27;, &#x27;WI&#x27;]],\n",
       "              handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-85\" type=\"checkbox\" ><label for=\"sk-estimator-id-85\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">location.city</label><div class=\"sk-toggleable__content\"><pre>[&#x27;location.city&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-86\" type=\"checkbox\" ><label for=\"sk-estimator-id-86\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(categories=[[&#x27;Scottsdale&#x27;, &#x27;San Francisco&#x27;, &#x27;San Diego&#x27;, &#x27;Arcata&#x27;,\n",
       "                           &#x27;Denver&#x27;, &#x27;Tampa&#x27;, &#x27;Atlanta&#x27;, &#x27;Chicago&#x27;,\n",
       "                           &#x27;Highland Park&#x27;, &#x27;Elk Grove Village&#x27;, &#x27;Oak Park&#x27;,\n",
       "                           &#x27;Indianapolis&#x27;, &#x27;Port Huron&#x27;, &#x27;Flint&#x27;,\n",
       "                           &#x27;Swartz Creek&#x27;, &#x27;Royal Oak&#x27;, &#x27;Pinconning&#x27;,\n",
       "                           &#x27;Roscommon&#x27;, &#x27;Plymouth&#x27;, &#x27;Algonac&#x27;, &#x27;Fenton&#x27;,\n",
       "                           &#x27;Detroit&#x27;, &#x27;Pigeon&#x27;, &#x27;Bloomfield Hills&#x27;,\n",
       "                           &#x27;Rogers City&#x27;, &#x27;Caseville&#x27;, &#x27;Montrose&#x27;, &#x27;Milford&#x27;,\n",
       "                           &#x27;Mackinac Island&#x27;, &#x27;Sault Ste. Marie&#x27;, ...]],\n",
       "              handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-87\" type=\"checkbox\" ><label for=\"sk-estimator-id-87\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">event.id</label><div class=\"sk-toggleable__content\"><pre>[&#x27;event.id&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-88\" type=\"checkbox\" ><label for=\"sk-estimator-id-88\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(categories=[[&#x27;583f013a-1e54-4906-87f7-2b625206f5f9&#x27;,\n",
       "                           &#x27;5a0dec07-5730-4099-b7a9-6cc05206f5f9&#x27;,\n",
       "                           &#x27;5840463a-70d0-46c2-8954-6dbf5206f5f9&#x27;,\n",
       "                           &#x27;58405447-64f8-44f8-a81f-01985206f5f9&#x27;,\n",
       "                           &#x27;5a5b9a23-ecfc-46ef-8c9f-01e45206f5f9&#x27;,\n",
       "                           &#x27;57ed3e2f-5ee8-4195-acf7-4ea75206f5f9&#x27;,\n",
       "                           &#x27;59c93fda-556c-4a1c-8609-13895206f5f9&#x27;,\n",
       "                           &#x27;583f31b0-c090-4558-b0f6-46c65206f5f9&#x27;,\n",
       "                           &#x27;5a2d3288-0...\n",
       "                           &#x27;59af0a5d-513c-4ed7-9daf-6d845206f5f9&#x27;,\n",
       "                           &#x27;5af9a8b2-06a4-40b4-acf6-07ea5206f5f9&#x27;,\n",
       "                           &#x27;59c2bd2d-fc20-4efb-86a1-33955206f5f9&#x27;,\n",
       "                           &#x27;5a3039c7-7a38-4d18-a7d7-5b765206f5f9&#x27;,\n",
       "                           &#x27;590b4d4c-1110-47b9-af8b-202e5206f5f9&#x27;,\n",
       "                           &#x27;5a09be9b-336c-4208-a96c-2d505206f5f9&#x27;,\n",
       "                           &#x27;5a4d1178-d4d0-4a04-95b5-54d85206f5f9&#x27;,\n",
       "                           &#x27;59230b2f-bdb4-45cc-b3ff-76e55206f5f9&#x27;,\n",
       "                           &#x27;5a81ddce-186c-4903-adc8-21565206f5f9&#x27;, ...]],\n",
       "              handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-89\" type=\"checkbox\" ><label for=\"sk-estimator-id-89\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">event.tenant.name</label><div class=\"sk-toggleable__content\"><pre>[&#x27;event.tenant.name&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-90\" type=\"checkbox\" ><label for=\"sk-estimator-id-90\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(categories=[[&#x27;Ventures Endurance&#x27;,\n",
       "                           &#x27;Avenue of the Giants Marathon&#x27;, &#x27;Lincoln Park Zoo&#x27;,\n",
       "                           &#x27;Strides for Peace Run/Walk&#x27;,\n",
       "                           &#x27;Leukemia Research Foundation&#x27;, &#x27;Chicago Bears&#x27;,\n",
       "                           &#x27;Greater Illinois Pediatric Palliative Care &#x27;\n",
       "                           &#x27;Coalition&#x27;,\n",
       "                           &#x27;Frank Lloyd Wright Races&#x27;,\n",
       "                           &#x27;Worldwide Sport and Social Club&#x27;,\n",
       "                           &#x27;St. Clair County Mental Healthy Authority&#x27;,\n",
       "                           &#x27;Genesee County Free Medical Clinic&#x27;,\n",
       "                           &#x27;Riverbend...\n",
       "                           &#x27;Higgins Lake 5K/10K/Half Marathon&#x27;, &#x27;Plymouth YMCA&#x27;,\n",
       "                           &#x27;Pickerel Run&#x27;,\n",
       "                           &#x27;Habitat for Humanity - Genesee County&#x27;,\n",
       "                           &#x27;Scheurer Hospital&#x27;, &#x27;Atwood 10K Committee&#x27;,\n",
       "                           &#x27;Crim Foundation&#x27;, &#x27;Milford Labor Day 30K&#x27;,\n",
       "                           &#x27;RunMackinac Events&#x27;, &#x27;Dino Dash&#x27;,\n",
       "                           &#x27;EnMotive Michigan&#x27;, &#x27;Detroit Marathon&#x27;,\n",
       "                           &#x27;Howell Area Chamber of Commerce&#x27;, &#x27;EnMotive OKC&#x27;,\n",
       "                           &#x27;Ohio Challenge Series&#x27;, &#x27;HCCC ColorRun &#x27;, ...]],\n",
       "              handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-91\" type=\"checkbox\" ><label for=\"sk-estimator-id-91\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">result.primary_bracket</label><div class=\"sk-toggleable__content\"><pre>[&#x27;result.primary_bracket&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-92\" type=\"checkbox\" ><label for=\"sk-estimator-id-92\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(categories=[[&#x27;Overall&#x27;, &#x27;Wheelchair&#x27;, &#x27;Male&#x27;, &#x27;Female&#x27;]],\n",
       "              handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-93\" type=\"checkbox\" ><label for=\"sk-estimator-id-93\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-94\" type=\"checkbox\" ><label for=\"sk-estimator-id-94\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">regressor: TransformedTargetRegressor</label><div class=\"sk-toggleable__content\"><pre>TransformedTargetRegressor(inverse_func=&lt;function evaluation_function at 0x7f9c9ddf2d30&gt;,\n",
       "                           regressor=RandomForestRegressor())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-95\" type=\"checkbox\" ><label for=\"sk-estimator-id-95\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">regressor: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-96\" type=\"checkbox\" ><label for=\"sk-estimator-id-96\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cleaner',\n",
       "                 ColumnTransformer(transformers=[('sex',\n",
       "                                                  OneHotEncoder(categories=[['Male',\n",
       "                                                                             'Female']],\n",
       "                                                                handle_unknown='ignore'),\n",
       "                                                  ['sex']),\n",
       "                                                 ('age', 'passthrough',\n",
       "                                                  ['age']),\n",
       "                                                 ('event.date.start',\n",
       "                                                  OneHotEncoder(categories=[['2017-12-03',\n",
       "                                                                             '2018-12-02',\n",
       "                                                                             '2018-01-07',\n",
       "                                                                             '2018-03-18',\n",
       "                                                                             '2018-05-06',\n",
       "                                                                             '2017-10-01',\n",
       "                                                                             '2018-10-07',\n",
       "                                                                             '2017-12-17',\n",
       "                                                                             '2018-12-16',\n",
       "                                                                             '2018-02-04...\n",
       "                                                  ['event.tenant.name']),\n",
       "                                                 ('result.primary_bracket',\n",
       "                                                  OneHotEncoder(categories=[['Overall',\n",
       "                                                                             'Wheelchair',\n",
       "                                                                             'Male',\n",
       "                                                                             'Female']],\n",
       "                                                                handle_unknown='ignore'),\n",
       "                                                  ['result.primary_bracket'])])),\n",
       "                ('fix_nans', SimpleImputer(strategy='median')),\n",
       "                ('regressor',\n",
       "                 TransformedTargetRegressor(inverse_func=<function evaluation_function at 0x7f9c9ddf2d30>,\n",
       "                                            regressor=RandomForestRegressor()))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# That assignment should pass the autograder. A more pythonic way to do this, and certainly\n",
    "# the goal of the sklearn team, is to use pipelines, and reuse transformer objects to do the\n",
    "# data cleaning. In sklearn pipelines are made up of a sequence of Transformers with the last\n",
    "# item in the pipeline being an Estimator. You can have Estimators throughout the pipeline\n",
    "# too, creating new features through modeling. For instance, you could use PCA to reduce the\n",
    "# dimensionality of features and then learn on principal components instead.\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# We can write a similar model to the above using pipelines and transformers. A good example\n",
    "# would be to first create a transformer for the columns of sex and age, and get rid of\n",
    "# everything else while one hot encoding sex\n",
    "\n",
    "df.loc[df.query(\"`age` >= 119\").index, 'age']=np.nan\n",
    "df.loc[df.query(\"`age` <= 18\").index, 'age']=np.nan\n",
    "df.loc[df['age'] == 'nan', 'age'] = 38\n",
    "\n",
    "df['result.primary_bracket'].replace(['WHEELCHAIR','nan','Male 25-29','Male 40-44','Female 25-29','Female 20-24','wheelchair'],['Wheelchair','Overall','Male','Male','Female','Female','Wheelchair'], inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "cleaner = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"sex\", OneHotEncoder(categories=[['Male','Female']], handle_unknown='ignore'), ['sex']),\n",
    "        ('age', 'passthrough', ['age']),\n",
    "        ('event.date.start', OneHotEncoder(categories=[['2017-12-03', '2018-12-02', '2018-01-07', '2018-03-18',\n",
    "       '2018-05-06', '2017-10-01', '2018-10-07', '2017-12-17',\n",
    "       '2018-12-16', '2018-02-04', '2017-06-04', '2017-09-09',\n",
    "       '2017-10-29', '2018-04-29', '2018-05-05', '2018-06-03',\n",
    "       '2018-06-07', '2018-06-21', '2018-06-23', '2018-09-08',\n",
    "       '2018-09-30', '2018-10-14', '2018-10-20', '2018-10-21',\n",
    "       '2018-11-04', '2018-11-22', '2018-12-31', '2018-03-24',\n",
    "       '2018-05-12', '2018-05-31', '2018-06-02', '2018-06-16',\n",
    "       '2018-06-17', '2018-06-30', '2018-07-14', '2018-07-15',\n",
    "       '2018-07-19', '2018-07-21', '2018-07-28', '2018-08-04',\n",
    "       '2018-08-11', '2018-08-16', '2018-08-19', '2018-08-25',\n",
    "       '2018-09-01', '2018-09-29', '2018-10-13', '2018-10-27',\n",
    "       '2018-11-23', '2018-04-14', '2017-12-10', '2018-12-09',\n",
    "       '2017-09-17', '2018-09-16', '2018-02-10', '2017-11-05',\n",
    "       '2018-06-01', '2018-07-27', '2018-09-03', '2018-10-06',\n",
    "       '2018-11-18', '2018-12-22', '2012-08-11', '2013-01-01',\n",
    "       '2013-08-10', '2014-09-27', '2015-01-01', '2015-08-15',\n",
    "       '2015-09-26', '2015-12-12', '2016-03-12', '2016-08-20',\n",
    "       '2016-08-27', '2016-10-02', '2016-10-22', '2016-12-10',\n",
    "       '2017-03-11', '2017-08-26', '2017-09-16', '2017-09-23',\n",
    "       '2017-09-30', '2017-10-28', '2018-03-31', '2018-09-15',\n",
    "       '2018-11-03', '2018-11-17', '2018-12-01', '2018-09-23',\n",
    "       '2018-04-07', '2018-02-17', '2018-01-28', '2018-02-03',\n",
    "       '2016-03-26', '2016-07-16', '2017-03-25', '2017-06-10',\n",
    "       '2017-07-15', '2018-06-09', '2018-06-10', '2018-03-04',\n",
    "       '2018-08-18', '2018-09-22']], handle_unknown='ignore'), ['event.date.start']),\n",
    "        ('clean_categories.name', OneHotEncoder(categories=[['15k', '5k', 'marathon', 'half marathon', '10k', '5 mile', '8k',\n",
    "       '5k run', '3k walk', '10k run', 'youth mile', '5k run/walk',\n",
    "       '5k walk', '5 mile run', '1 mile run', '15k run', '10k walk',\n",
    "       '6k run', '6k walk', '1 mile walk', '8k run', '8k walk',\n",
    "       '10 mile run', '10 mile walk', '5 mile walk', '30k run',\n",
    "       '30k bike', '8 mile run', '8 mile walk', 'bridge run',\n",
    "       'international half marathon', 'u.s. only half marathon', '1 mile',\n",
    "       '5.7 mile run', '5.7 mile walk', '5k competitive walk',\n",
    "       'half marathon run', '5k fun walk', '5k wheelchair',\n",
    "       '1 mile fun run', '2 mile run', '2 mile walk', '4 mile run/walk',\n",
    "       'life time commitment day 5k', 'midnight streak',\n",
    "       'commitment day 5k - master', 'quarter marathon', '5k walk/run',\n",
    "       '1 mile fun run/walk', 'one mile fun run', '5 km run',\n",
    "       'fire fighter', 'olympic triathlon', 'sprint triathlon',\n",
    "       'olympic duathlon', 'sprint duathlon', '10k scenic challenge',\n",
    "       'run swim run', 'half marathon walk', 'mini-marathon']], handle_unknown='ignore'), ['clean_categories.name']),\n",
    "        #('body.type', OneHotEncoder(categories=[['Run','nan']], handle_unknown='ignore'), ['body.type']),\n",
    "        #('body.timezone', OneHotEncoder(categories=[['America/Boise', 'America/Los_Angeles', 'America/Denver',\n",
    "       #'America/New_York', 'America/Chicago', 'America/Detroit']], handle_unknown='ignore'), ['body.timezone']),\n",
    "        ('location.state', OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "        ('location.city', OneHotEncoder(categories=[['Scottsdale', 'San Francisco', 'San Diego', 'Arcata', 'Denver',\n",
    "       'Tampa', 'Atlanta', 'Chicago', 'Highland Park',\n",
    "       'Elk Grove Village', 'Oak Park', 'Indianapolis', 'Port Huron',\n",
    "       'Flint', 'Swartz Creek', 'Royal Oak', 'Pinconning', 'Roscommon',\n",
    "       'Plymouth', 'Algonac', 'Fenton', 'Detroit', 'Pigeon',\n",
    "       'Bloomfield Hills', 'Rogers City', 'Caseville', 'Montrose',\n",
    "       'Milford', 'Mackinac Island', 'Sault Ste. Marie', 'East Lansing',\n",
    "       'Williamston', 'Howell', 'Minneapolis', 'St. Louis', 'Santa Fe',\n",
    "       'Charlotte', 'Columbus', 'Canal Fulton', 'Brewster', 'Hartville',\n",
    "       'Strasburg', 'North Canton', 'Clinton', 'Cadiz', 'Dalton',\n",
    "       'Alliance', 'Barberton', 'Millersburg', 'Peninsula', 'Bolivar',\n",
    "       'Massillon', 'Canton', 'Akron', 'Oklahoma City', 'Tulsa',\n",
    "       'Oklahoma City, OK', 'Norman', 'Edmond', 'Lawton', 'Stillwater',\n",
    "       'Moore', 'Perry', 'Seiling', 'Bethany', 'Elk City', 'Sulphur',\n",
    "       'Yukon', 'Beaverton', 'Salem', 'Albany', 'Philadelphia',\n",
    "       'Nashville', 'Houston', 'Dallas', 'Virginia Beach', 'Fairfax',\n",
    "       'West Point', 'Seattle', 'Parkersburg', 'Milwaukee']], handle_unknown='ignore'), ['location.city']),\n",
    "        ('event.id', OneHotEncoder(categories=[['583f013a-1e54-4906-87f7-2b625206f5f9',\n",
    "       '5a0dec07-5730-4099-b7a9-6cc05206f5f9',\n",
    "       '5840463a-70d0-46c2-8954-6dbf5206f5f9',\n",
    "       '58405447-64f8-44f8-a81f-01985206f5f9',\n",
    "       '5a5b9a23-ecfc-46ef-8c9f-01e45206f5f9',\n",
    "       '57ed3e2f-5ee8-4195-acf7-4ea75206f5f9',\n",
    "       '59c93fda-556c-4a1c-8609-13895206f5f9',\n",
    "       '583f31b0-c090-4558-b0f6-46c65206f5f9',\n",
    "       '5a2d3288-0390-4f2e-a09a-3b065206f5f9',\n",
    "       '58404d26-eaa8-4c04-82e5-7d045206f5f9',\n",
    "       '5c5cb866-391c-404a-a9f7-540a5206f5f9',\n",
    "       '57bdcd1f-a474-43e0-8e54-5f3a5206f5f9',\n",
    "       '57f3d359-f5d4-4a03-b9f3-29a15206f5f9',\n",
    "       '58fa2ce7-8fe8-4fdc-9675-32785206f5f9',\n",
    "       '590b73b9-2960-4c3f-8b5e-31b35206f5f9',\n",
    "       '59318b7f-12a8-4e32-917b-7b435206f5f9',\n",
    "       '5af9d47d-8c68-4bd0-bee8-58085206f5f9',\n",
    "       '5a317d2c-c22c-4c30-bfab-245c5206f5f9',\n",
    "       '59e90517-5ed0-4796-95fd-77225206f5f9',\n",
    "       '5a8717a6-4e94-4cb0-8a25-0a5c5206f5f9',\n",
    "       '59a99331-e614-4004-8634-16bc5206f5f9',\n",
    "       '59af0a5d-513c-4ed7-9daf-6d845206f5f9',\n",
    "       '5af9a8b2-06a4-40b4-acf6-07ea5206f5f9',\n",
    "       '59c2bd2d-fc20-4efb-86a1-33955206f5f9',\n",
    "       '5a3039c7-7a38-4d18-a7d7-5b765206f5f9',\n",
    "       '590b4d4c-1110-47b9-af8b-202e5206f5f9',\n",
    "       '5a09be9b-336c-4208-a96c-2d505206f5f9',\n",
    "       '5a4d1178-d4d0-4a04-95b5-54d85206f5f9',\n",
    "       '59230b2f-bdb4-45cc-b3ff-76e55206f5f9',\n",
    "       '5a81ddce-186c-4903-adc8-21565206f5f9',\n",
    "       '5a565410-6288-4eeb-8f45-78ea5206f5f9',\n",
    "       '5aa1a8ff-1294-4b04-9044-576b5206f5f9',\n",
    "       '5a980634-efb4-4849-aa0f-17b05206f5f9',\n",
    "       '5a8206d3-d2b4-49b3-843b-11bc5206f5f9',\n",
    "       '5a58fc3d-37d4-43a1-992b-45a55206f5f9',\n",
    "       '5a562b13-b310-42d6-badf-1ad65206f5f9',\n",
    "       '5a70fdf7-cb30-440e-af77-14f75206f5f9',\n",
    "       '5ad8ae00-e10c-4a35-a5c6-5cb35206f5f9',\n",
    "       '5abeadde-ace8-46e4-b456-0fea5206f5f9',\n",
    "       '5aba67c1-a8c8-4f55-a83a-3a0a5206f5f9',\n",
    "       '5aa9724c-b8a8-47e5-98cc-21e65206f5f9',\n",
    "       '5ade1d25-f28c-4137-a080-64105206f5f9',\n",
    "       '5ad385d7-fcd4-423e-ac99-33625206f5f9',\n",
    "       '5b687f64-1074-4f2d-88ca-3d365206f5f9',\n",
    "       '5b217282-ef14-4990-a436-20f55206f5f9',\n",
    "       '5b2bb89e-3204-461e-b6a1-099f5206f5f9',\n",
    "       '5b6b34d6-40b8-483c-826e-68525206f5f9',\n",
    "       '5a43b245-4738-4607-8ed3-1f3c5206f5f9',\n",
    "       '59a4a07f-fa60-4de0-911c-699a5206f5f9',\n",
    "       '5a302f88-f984-4076-aaa1-47c15206f5f9',\n",
    "       '5b153ba0-5f0c-41e7-959c-3fcf5206f5f9',\n",
    "       '5b7adab1-2654-4345-9cc2-0a785206f5f9',\n",
    "       '5b92ca90-34e0-4019-a17b-52bb5206f5f9',\n",
    "       '59a06537-01fc-4bc1-81b7-7ad25206f5f9',\n",
    "       '5b5a2703-9660-4860-b221-32ca5206f5f9',\n",
    "       '58405524-3c70-49fc-a996-6dbf5206f5f9',\n",
    "       '583f2c80-ea88-48bd-a4ba-3f035206f5f9',\n",
    "       '5a1c7352-b910-474e-86c1-40705206f5f9',\n",
    "       '5c6b6a37-8198-40cd-8442-67fc5206f5f9',\n",
    "       '5c6b6b95-7668-471c-934c-5ddb5206f5f9',\n",
    "       '590a3af0-8e04-4e06-ae1b-12405206f5f9',\n",
    "       '583352f9-d400-4da5-a7c8-48645206f5f9',\n",
    "       '59df7a08-d680-41a2-b33e-2eae5206f5f9',\n",
    "       '5a257762-6988-416b-8f13-1f735206f5f9',\n",
    "       '5a4693eb-0408-48d9-ad3c-306c5206f5f9',\n",
    "       '5a6740c3-72d8-4fc3-a844-735e5206f5f9',\n",
    "       '59fba6af-bbe4-442d-972e-3d715206f5f9',\n",
    "       '5a7345e7-3ee8-4b47-a700-30f15206f5f9',\n",
    "       '5a13452c-8df0-4900-8616-2e185206f5f9',\n",
    "       '5a60be6b-8038-4793-b9eb-23255206f5f9',\n",
    "       '5a14428f-9d48-4017-a644-6e8d5206f5f9',\n",
    "       '5a4f98e5-4e38-466e-8669-122a5206f5f9',\n",
    "       '59a2e4ef-2f84-4dd6-a7fe-3ed15206f5f9',\n",
    "       '5a2ec6eb-8c24-4e9c-87aa-41bd5206f5f9',\n",
    "       '59dd4424-fe1c-485c-b6cd-1b485206f5f9',\n",
    "       '5a4fd1c7-b21c-4023-b545-263f5206f5f9',\n",
    "       '5a53aa79-184c-47a6-a2a3-313a5206f5f9',\n",
    "       '5a2ace7a-7b24-4d2a-b676-6c9d5206f5f9',\n",
    "       '5a8ae3f2-7158-495b-ba25-3c085206f5f9',\n",
    "       '59ea2b38-4154-40c8-8aed-6b395206f5f9',\n",
    "       '5a57b9dd-93f0-4abd-81c8-28bc5206f5f9',\n",
    "       '5a66533b-d89c-4478-8f6c-37015206f5f9',\n",
    "       '5a9efd91-b278-458b-9eb4-608a5206f5f9',\n",
    "       '5c6b4275-d2d4-4c55-98a6-44785206f5f9',\n",
    "       '5c87e429-1794-419e-8c84-08485206f5f9',\n",
    "       '5c6b457c-e7dc-47cb-bba7-34db5206f5f9',\n",
    "       '5c7fe534-32c8-45dc-8f21-01bf5206f5f9',\n",
    "       '5c87e6c4-ae88-4da5-ab6d-0e975206f5f9',\n",
    "       '5c6b4b03-157c-4a28-8236-1c545206f5f9',\n",
    "       '5c7ff378-5284-49ef-90d3-31965206f5f9',\n",
    "       '5c6c391e-8e18-4106-8e5a-7aaf5206f5f9',\n",
    "       '5c6c733f-631c-42a9-9b02-11855206f5f9',\n",
    "       '5c6b4dbc-f87c-463c-962e-19915206f5f9',\n",
    "       '5c8941fc-5b00-4c1d-8063-5a7e5206f5f9',\n",
    "       '5c803365-3704-4b3f-8c79-5bfb5206f5f9',\n",
    "       '5c87ee2c-3534-46ba-a49e-08485206f5f9',\n",
    "       '5c6c3c5b-94cc-4f8d-8833-128e5206f5f9',\n",
    "       '5c6c7600-7848-414e-a503-2ca25206f5f9',\n",
    "       '5c802215-eb68-415c-8b78-76555206f5f9',\n",
    "       '5c6b5dbd-ad4c-4558-aecf-5dbe5206f5f9',\n",
    "       '5c802a0a-6190-483b-bd7c-19725206f5f9',\n",
    "       '5c6b30ac-036c-4073-b9e4-198e5206f5f9',\n",
    "       '5c818e6a-0cd4-443a-8d8f-46285206f5f9',\n",
    "       '5c6b3aa2-9b50-43ea-908e-0e4a5206f5f9',\n",
    "       '5c87f0b2-d280-40bd-a827-15405206f5f9',\n",
    "       '5c892c06-6cf0-468b-872d-68695206f5f9',\n",
    "       '5c8025b5-e930-4ab5-b87c-19715206f5f9',\n",
    "       '5c89333f-b684-4593-b87c-7aac5206f5f9',\n",
    "       '5c66f565-61d0-4834-9d32-6c675206f5f9',\n",
    "       '5c6b5e5a-00cc-4c97-a95b-5dd95206f5f9',\n",
    "       '5c6b3572-56a0-4d27-a23e-44785206f5f9',\n",
    "       '5c6c70fc-fd20-4769-9ee1-088e5206f5f9',\n",
    "       '5c802fca-1ee4-4f10-a2be-0e805206f5f9',\n",
    "       '5c89366f-5600-491a-9c27-1f965206f5f9',\n",
    "       '5c82ba4e-aca8-40d8-9ed8-0cbe5206f5f9',\n",
    "       '5c6b3f3c-2ba0-4dad-8764-19915206f5f9',\n",
    "       '5c6c7c8b-bde8-4bc9-91ef-533d5206f5f9',\n",
    "       '5c7fdb4d-3688-46a2-b808-45615206f5f9',\n",
    "       '5c82ca25-1eec-4427-871f-7b095206f5f9',\n",
    "       '5c87f30e-bf94-41ab-b234-15415206f5f9',\n",
    "       '5c6b5ef7-6c28-4774-afbc-67d45206f5f9',\n",
    "       '5c893fc1-44d8-48e7-8844-5a785206f5f9',\n",
    "       '5c019c1b-b370-4732-aa47-1db25206f5f9',\n",
    "       '5bcf4f57-8658-4484-84b4-165c5206f5f9',\n",
    "       '59b6bd5d-1008-4d2c-8194-263b5206f5f9',\n",
    "       '5a54f181-e37c-41da-9f62-42925206f5f9',\n",
    "       '5a393a3a-7628-4bce-b9ea-556b5206f5f9',\n",
    "       '584054cb-f3d8-4c38-b560-03135206f5f9',\n",
    "       '5840533c-27a0-4c85-8603-7a475206f5f9',\n",
    "       '590a3e6e-ac64-4341-af5b-18165206f5f9',\n",
    "       '5840528b-6010-4133-8fef-7d065206f5f9',\n",
    "       '5e862221-758c-48b1-a7cf-11bcc0a80a41',\n",
    "       '5e860049-7e9c-4f9d-9911-37c4c0a80a41',\n",
    "       '5e8622bc-0ef4-472a-a19b-6f4bc0a80a41',\n",
    "       '5e83a2da-3c78-430f-95aa-236fc0a80a41',\n",
    "       '5e86018d-79d4-4d30-998e-69e6c0a80a41',\n",
    "       '5e862439-c108-40be-b3ec-36b6c0a80a41',\n",
    "       '5e791e51-81d0-48f5-a6c1-31e3c0a80a41',\n",
    "       '59f0f5dc-31bc-41b6-860b-0a415206f5f9',\n",
    "       '5e83a579-e5c4-45a1-82bd-792ec0a80a41',\n",
    "       '5e86031d-5590-4c2b-97a6-44d6c0a80a41',\n",
    "       '5d24927d-161c-4287-9ef7-7494c0a80a41',\n",
    "       '58405401-f23c-46b2-8dfc-032d5206f5f9',\n",
    "       '5a5e3aba-95d4-4577-bbe8-67375206f5f9',\n",
    "       '5b7ae951-7e04-4262-a599-2f745206f5f9']], handle_unknown='ignore'), ['event.id']),\n",
    "         ('event.tenant.name', OneHotEncoder(categories=[['Ventures Endurance', 'Avenue of the Giants Marathon',\n",
    "       'Lincoln Park Zoo', 'Strides for Peace Run/Walk',\n",
    "       'Leukemia Research Foundation', 'Chicago Bears',\n",
    "       'Greater Illinois Pediatric Palliative Care Coalition',\n",
    "       'Frank Lloyd Wright Races', 'Worldwide Sport and Social Club',\n",
    "       'St. Clair County Mental Healthy Authority',\n",
    "       'Genesee County Free Medical Clinic', 'Riverbend Striders',\n",
    "       'Everal Race Management', 'CheeseTown Races',\n",
    "       'Higgins Lake 5K/10K/Half Marathon', 'Plymouth YMCA',\n",
    "       'Pickerel Run', 'Habitat for Humanity - Genesee County',\n",
    "       'Scheurer Hospital', 'Atwood 10K Committee', 'Crim Foundation',\n",
    "       'Milford Labor Day 30K', 'RunMackinac Events', 'Dino Dash',\n",
    "       'EnMotive Michigan', 'Detroit Marathon',\n",
    "       'Howell Area Chamber of Commerce', 'EnMotive OKC',\n",
    "       'Ohio Challenge Series', 'HCCC ColorRun ', 'Bowerman 5k ',\n",
    "       'Rotary River Fest Salem', 'Corvallis Lions Club',\n",
    "       'LifeNet Health', 'Allen Stone Memorial Races',\n",
    "       'Chesapeake Beach Civic League', 'Commonwealth Race Management',\n",
    "       'Town Of West Point', 'Cape Henry Collegiate',\n",
    "       'News And Sentinel Half Marathon',\n",
    "       'Milwaukee Brewers Baseball Club']], handle_unknown='ignore'), ['event.tenant.name']),\n",
    "        \n",
    "\n",
    "         ('result.primary_bracket', OneHotEncoder(categories=[['Overall','Wheelchair','Male','Female']], handle_unknown='ignore'), ['result.primary_bracket']), \n",
    "    ], remainder='drop')\n",
    "\n",
    "# Then we create a three stage pipeline, where the first step applies the column transformer,\n",
    "# the next step fills our missing values, and the third step is a regression model. But remember,\n",
    "# this isn't a simple regression, we need an ordinal classification. To do this we can wrap\n",
    "# the linear regressor in another class which will transform the regression output. This class\n",
    "# is called the TransformedTargetRegressor, and we can tell it what function we want to apply\n",
    "# to the final output before returning the predictions.\n",
    "\n",
    "def evaluation_function(x):\n",
    "    '''Must return a ndarray of the rankings in order, the autograder will then create\n",
    "    a dataframe out of this with x.index as the index. Props to Rachell Calhoun!'''\n",
    "    return pd.Series(x.squeeze()).rank().values\n",
    "\n",
    "# We can wrap a linear regressor by setting the inverse_func to evaluation_function\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg=TransformedTargetRegressor(regressor=RandomForestRegressor(n_estimators=100, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None), inverse_func=evaluation_function)\n",
    "\n",
    "# Now we can build our three part pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"cleaner\", cleaner),\n",
    "        (\"fix_nans\", SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        (\"regressor\", reg)\n",
    "    ])\n",
    "\n",
    "# We can display the pipeline to see what it looks like and get a sense of data flow\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "display(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed5079e9-2244-45c8-b7db-9b65f3a01557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2156786821700012\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can then fit the data in the pipeline\n",
    "fitted_pipe=pipe.fit(train,y)\n",
    "\n",
    "# And we can save it to an output file\n",
    "cloudpickle.dump(fitted_pipe, open('pipeline.cloudpickle','wb'))\n",
    "# Then telling the autograder function to fire\n",
    "autograde(holdout_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d16d284-a776-4408-8dfd-e568eb2a8bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That assignment should pass the autograder. A more pythonic way to do this, and certainly\n",
    "# the goal of the sklearn team, is to use pipelines, and reuse transformer objects to do the\n",
    "# data cleaning. In sklearn pipelines are made up of a sequence of Transformers with the last\n",
    "# item in the pipeline being an Estimator. You can have Estimators throughout the pipeline\n",
    "# too, creating new features through modeling. For instance, you could use PCA to reduce the\n",
    "# dimensionality of features and then learn on principal components instead.\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# We can write a similar model to the above using pipelines and transformers. A good example\n",
    "# would be to first create a transformer for the columns of sex and age, and get rid of\n",
    "# everything else while one hot encoding sex\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "cleaner = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"sex\", OneHotEncoder(categories=[['Male','Female']], handle_unknown='ignore'), ['sex']),\n",
    "        ('age', 'passthrough', ['age']),\n",
    "    ], remainder='drop')\n",
    "\n",
    "# Then we create a three stage pipeline, where the first step applies the column transformer,\n",
    "# the next step fills our missing values, and the third step is a regression model. But remember,\n",
    "# this isn't a simple regression, we need an ordinal classification. To do this we can wrap\n",
    "# the linear regressor in another class which will transform the regression output. This class\n",
    "# is called the TransformedTargetRegressor, and we can tell it what function we want to apply\n",
    "# to the final output before returning the predictions.\n",
    "\n",
    "def evaluation_function(x):\n",
    "    '''Must return a ndarray of the rankings in order, the autograder will then create\n",
    "    a dataframe out of this with x.index as the index. Props to Rachell Calhoun!'''\n",
    "    return pd.Series(x.squeeze()).rank().values\n",
    "\n",
    "# We can wrap a linear regressor by setting the inverse_func to evaluation_function\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg=TransformedTargetRegressor(regressor=RandomForestRegressor(), inverse_func=evaluation_function)\n",
    "\n",
    "# Now we can build our three part pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"cleaner\", cleaner),\n",
    "        (\"fix_nans\", SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)),\n",
    "        (\"regressor\", reg)\n",
    "    ])\n",
    "\n",
    "# We can display the pipeline to see what it looks like and get a sense of data flow\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "display(pipe)\n",
    "\n",
    "# We can then fit the data in the pipeline\n",
    "fitted_pipe=pipe.fit(train,y)\n",
    "\n",
    "# And we can save it to an output file\n",
    "cloudpickle.dump(fitted_pipe, open('pipeline.cloudpickle','wb'))\n",
    "# Then telling the autograder function to fire\n",
    "autograde(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76d903f-00a4-4b01-a243-4b8edaa66f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Now that this is binary we can convert this column into a numeric value\n",
    "train.loc[train['sex'] == 'F', 'sex'] = 'Female'\n",
    "train.loc[train['sex'] == 'M', 'sex'] = 'Male'\n",
    "train.loc[train.query(\"`sex` not in ['Male','Female']\").index, 'sex']=np.nan\n",
    "\n",
    "train.loc[train.query(\"`sex` == 'Male'\").index, 'sex']=2\n",
    "train.loc[train.query(\"`sex` == 'Female'\").index, 'sex']=1\n",
    "\n",
    "# Now just do whatever you want with missing values, this below doesn't seem ideal\n",
    "train['sex']=train['sex'].fillna(0)\n",
    "\n",
    "\n",
    "holdout.loc[holdout['sex'] == 'F', 'sex'] = 'Female'\n",
    "holdout.loc[holdout['sex'] == 'M', 'sex'] = 'Male'\n",
    "holdout.loc[holdout.query(\"`sex` not in ['Male','Female']\").index, 'sex']=np.nan\n",
    "\n",
    "holdout.loc[holdout.query(\"`sex` == 'Male'\").index, 'sex']=2\n",
    "holdout.loc[holdout.query(\"`sex` == 'Female'\").index, 'sex']=1\n",
    "\n",
    "# Now just do whatever you want with missing values, this below doesn't seem ideal\n",
    "holdout['sex']=holdout['sex'].fillna(0)\n",
    "\n",
    "\n",
    "test.loc[test['sex'] == 'F', 'sex'] = 'Female'\n",
    "test.loc[test['sex'] == 'M', 'sex'] = 'Male'\n",
    "test.loc[test.query(\"`sex` not in ['Male','Female']\").index, 'sex']=np.nan\n",
    "\n",
    "test.loc[test.query(\"`sex` == 'Male'\").index, 'sex']=2\n",
    "test.loc[test.query(\"`sex` == 'Female'\").index, 'sex']=1\n",
    "\n",
    "# Now just do whatever you want with missing values, this below doesn't seem ideal\n",
    "test['sex']=test['sex'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f652e61-3756-486d-9f7d-b7fd8f24f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df.filter(items=['event_id','location.state','location.city','event.date.start','categories.name','age','sex','X_result.duration.chip','X_result.duration.pace'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5babd54-0f88-4e28-a25a-1089a31ce324",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1eecbb-0185-4166-a100-0b651323bad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577000cc-9c41-4f3e-bf2b-7f130896725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['sequence_id'].unique()\n",
    "#df3 = df[df['sequence_id']!=0]\n",
    "#df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e037d1-aa1b-47e8-80b2-2c918faa0053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y=pd.to_timedelta(train['result.duration.chip']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba854904-a479-4c66-957d-fa713c0dcc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['event.date.start'].min()\n",
    "#df['X_event.date.start'] = pd.to_timedelta(train['event.date.start']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd0515-04f1-420a-8630-90d94d4f110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['X_result.duration.chip'] = pd.to_timedelta(train['result.duration.chip']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865fc26b-ae59-453e-b048-d0cd29ed7cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['X_result.duration.pace'] = pd.to_timedelta(train['result.duration.pace']).astype(int)\n",
    "#df['X_result.duration.chip'] = pd.to_timedelta(train['result.duration.chip']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4684e61-5d24-45ac-895e-a922137dde02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[ df['X_result.duration.pace'] == '00:00:00', 'X_result.duration.pace'] = '01:12:37'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c4765b-9d54-4ff0-a8b4-b7663c800974",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_nan = holdout['clean_categories.name'].isnull().sum()\n",
    "check_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4165bdd3-8a9d-499b-8610-44139d052071",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['location.city'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2505461-e3c1-4179-8c91-d77518676154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['X_result.duration.pace']=df['X_result.duration.pace'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac366ba8-9c3c-4d49-a0f7-e0064ff0b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['X_result.duration.chip']=df['X_result.duration.chip'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae5d35-8f20-4f79-904a-bec2201fe75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['overall_ranking']=df['overall_ranking'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9624d5-ee62-4b26-8ee1-df1b3c54a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['age'] == 'nan', 'age'] = 38\n",
    "holdout.loc[holdout['age'] == 'nan', 'age'] = 38\n",
    "test.loc[test['age'] == 'nan', 'age'] = 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5874c497-8ba6-4f97-8882-7bbf5f792d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fe4003-8e51-433d-8bee-befc39786e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['age'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1332f05-cec1-4d91-9c7b-ea4e4730ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['body.type'] == 'nan', 'body.type'] = 'No-Run'\n",
    "holdout.loc[holdout['body.type'] == 'nan', 'body.type'] = 'No-Run'\n",
    "test.loc[test['body.type'] == 'nan', 'body.type'] = 'No-Run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ac5691-5b5f-41b1-85f2-47d3a9d5979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['location.city'] == 'Oklahoma City, OK', 'location.city'] = 'Oklahoma City'\n",
    "holdout.loc[holdout['location.city'] == 'Oklahoma City, OK', 'location.city'] = 'Oklahoma City'\n",
    "test.loc[test['location.city'] == 'Oklahoma City, OK', 'location.city'] = 'Oklahoma City'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b995a57-911a-4b0d-a784-77378e89d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[ df['body.results_certificate'] == 'False', 'body.results_certificate'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab3880-8ca0-4569-bdb8-4936ed7ef55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5003c3-c225-460a-aaff-b6c3363b4415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['result.duration.pace']=(df[df['result.duration.pace']=='00:00:00']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d6e0c-3d91-4dc3-af7b-32df5df8f870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f263c344-f14a-46be-a934-9d803fbc39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(holdout)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715ef1d9-1205-45b7-92fc-e2adb48e9138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5 = df[df['sequence_id']==0]\n",
    "#df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f51b10-bf1a-4a59-9089-e335699191a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.rename(columns={'event.id':'event_id'})\n",
    "holdout=holdout.rename(columns={'event.id':'event_id'})\n",
    "test=test.rename(columns={'event.id':'event_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849412d0-4dab-42f5-9a90-392c90e59a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['overall_ranking']=df['overall_ranking'].dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66567f4c-1c47-48ac-a257-3a59f86dc91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.loc[(train['age']>= 18) & (train['age'] <= 118)]\n",
    "holdout = holdout.loc[(holdout['age']>= 18) & (holdout['age'] <= 118)]\n",
    "test = test.loc[(test['age']>= 18) & (test['age'] <= 118)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da30d80-58b0-4ccd-bdcc-f914d93f4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#holdout = holdout.filter(items=['event_id','location.state','location.city','categories.name','event.date.start','body.results_certificate','counts.participants.expected','age','sex','X_result.duration.chip','X_result.duration.pace','overall_ranking'])\n",
    "#df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69872dc7-9e06-4a4e-aa59-4e11889bd9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c2e50a-22ba-4906-862e-5e709cb645e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3451b039-3fc4-4f39-afd5-f3eab4273ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0495484-8e8f-4064-aac0-5bbd5b65af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.loc[ df1['sequence_id'] == 'NaN', 'sequence_id'] = 0\n",
    "#df1.loc[ df1['sequence_id'] == 'nan', 'sequence_id'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d0042c-f473-45a0-b5a5-8889273cc2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_nan = df['overall_ranking'].isnull().sum()\n",
    "#check_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c2eb3-40f2-4382-b8ae-c3299dcaf8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['sequence_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcdd5dd-95d8-4994-a604-5682498afc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overall_ranking'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c4146-8511-4949-9732-8c15ded7ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['overall_ranking']=train['overall_ranking'].astype(str)\n",
    "#holdout['overall_ranking']=holdout['overall_ranking'].astype(str)\n",
    "#test['overall_ranking']=test['overall_ranking'].astype(str)\n",
    "\n",
    "#train['overall_ranking']=train['overall_ranking'].dropna()\n",
    "#holdout['overall_ranking']=holdout['overall_ranking'].dropna()\n",
    "#test['overall_ranking']=test['overall_ranking'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ff721f-a594-4e2d-852f-0190b80e81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data=df.query(\"sequence_id in [0, '5a5b9a23-ecfc-46ef-8c9f-01e45206f5f9','57bdcd1f-a474-43e0-8e54-5f3a5206f5f9','590b73b9-2960-4c3f-8b5e-31b35206f5f9','59318b7f-12a8-4e32-917b-7b435206f5f9','5af9d47d-8c68-4bd0-bee8-58085206f5f9','5a317d2c-c22c-4c30-bfab-245c5206f5f9','59af0a5d-513c-4ed7-9daf-6d845206f5f9','5af9a8b2-06a4-40b4-acf6-07ea5206f5f9','59c2bd2d-fc20-4efb-86a1-33955206f5f9','5a09be9b-336c-4208-a96c-2d505206f5f9','59230b2f-bdb4-45cc-b3ff-76e55206f5f9','5a81ddce-186c-4903-adc8-21565206f5f9','5a565410-6288-4eeb-8f45-78ea5206f5f9','5a980634-efb4-4849-aa0f-17b05206f5f9','5a8206d3-d2b4-49b3-843b-11bc5206f5f9','5a58fc3d-37d4-43a1-992b-45a55206f5f9','5a562b13-b310-42d6-badf-1ad65206f5f9','5abeadde-ace8-46e4-b456-0fea5206f5f9','5aba67c1-a8c8-4f55-a83a-3a0a5206f5f9','5aa9724c-b8a8-47e5-98cc-21e65206f5f9','5ade1d25-f28c-4137-a080-64105206f5f9','5ad385d7-fcd4-423e-ac99-33625206f5f9','5b687f64-1074-4f2d-88ca-3d365206f5f9','5b2bb89e-3204-461e-b6a1-099f5206f5f9','5b6b34d6-40b8-483c-826e-68525206f5f9','5a43b245-4738-4607-8ed3-1f3c5206f5f9','59a4a07f-fa60-4de0-911c-699a5206f5f9','5a302f88-f984-4076-aaa1-47c15206f5f9','5b153ba0-5f0c-41e7-959c-3fcf5206f5f9','5b7adab1-2654-4345-9cc2-0a785206f5f9','59a06537-01fc-4bc1-81b7-7ad25206f5f9','5b5a2703-9660-4860-b221-32ca5206f5f9','5c6b6a37-8198-40cd-8442-67fc5206f5f9','590a3af0-8e04-4e06-ae1b-12405206f5f9','59df7a08-d680-41a2-b33e-2eae5206f5f9','5a257762-6988-416b-8f13-1f735206f5f9','5a4693eb-0408-48d9-ad3c-306c5206f5f9','5a6740c3-72d8-4fc3-a844-735e5206f5f9','59fba6af-bbe4-442d-972e-3d715206f5f9','5a7345e7-3ee8-4b47-a700-30f15206f5f9','5a13452c-8df0-4900-8616-2e185206f5f9','5a60be6b-8038-4793-b9eb-23255206f5f9','5a14428f-9d48-4017-a644-6e8d5206f5f9','5a4f98e5-4e38-466e-8669-122a5206f5f9','59a2e4ef-2f84-4dd6-a7fe-3ed15206f5f9','5a2ec6eb-8c24-4e9c-87aa-41bd5206f5f9','59dd4424-fe1c-485c-b6cd-1b485206f5f9','5a53aa79-184c-47a6-a2a3-313a5206f5f9','5a2ace7a-7b24-4d2a-b676-6c9d5206f5f9','5a57b9dd-93f0-4abd-81c8-28bc5206f5f9','5a9efd91-b278-458b-9eb4-608a5206f5f9','5c6b4275-d2d4-4c55-98a6-44785206f5f9','5c87e429-1794-419e-8c84-08485206f5f9','5c7fe534-32c8-45dc-8f21-01bf5206f5f9','5c6c391e-8e18-4106-8e5a-7aaf5206f5f9','5c6c733f-631c-42a9-9b02-11855206f5f9','5c8941fc-5b00-4c1d-8063-5a7e5206f5f9','5c803365-3704-4b3f-8c79-5bfb5206f5f9','5c87ee2c-3534-46ba-a49e-08485206f5f9','5c802215-eb68-415c-8b78-76555206f5f9','5c6b5dbd-ad4c-4558-aecf-5dbe5206f5f9','5c802a0a-6190-483b-bd7c-19725206f5f9','5c6b30ac-036c-4073-b9e4-198e5206f5f9','5c6b3aa2-9b50-43ea-908e-0e4a5206f5f9','5c892c06-6cf0-468b-872d-68695206f5f9','5c89333f-b684-4593-b87c-7aac5206f5f9','5c66f565-61d0-4834-9d32-6c675206f5f9','5c6c70fc-fd20-4769-9ee1-088e5206f5f9','5c89366f-5600-491a-9c27-1f965206f5f9','5c6c7c8b-bde8-4bc9-91ef-533d5206f5f9','5c7fdb4d-3688-46a2-b808-45615206f5f9','5c82ca25-1eec-4427-871f-7b095206f5f9','5c6b5ef7-6c28-4774-afbc-67d45206f5f9','5c893fc1-44d8-48e7-8844-5a785206f5f9','5c019c1b-b370-4732-aa47-1db25206f5f9','5bcf4f57-8658-4484-84b4-165c5206f5f9','59b6bd5d-1008-4d2c-8194-263b5206f5f9','5a54f181-e37c-41da-9f62-42925206f5f9','5a393a3a-7628-4bce-b9ea-556b5206f5f9','590a3e6e-ac64-4341-af5b-18165206f5f9','5e862221-758c-48b1-a7cf-11bcc0a80a41','59f0f5dc-31bc-41b6-860b-0a415206f5f9','5e83a579-e5c4-45a1-82bd-792ec0a80a41','5d24927d-161c-4287-9ef7-7494c0a80a41','5a5e3aba-95d4-4577-bbe8-67375206f5f9']\")\n",
    "#data=df1.query(\"event_id in ['583f013a-1e54-4906-87f7-2b625206f5f9','5a0dec07-5730-4099-b7a9-6cc05206f5f9','5840463a-70d0-46c2-8954-6dbf5206f5f9','58405447-64f8-44f8-a81f-01985206f5f9','5a5b9a23-ecfc-46ef-8c9f-01e45206f5f9','57ed3e2f-5ee8-4195-acf7-4ea75206f5f9','59c93fda-556c-4a1c-8609-13895206f5f9','583f31b0-c090-4558-b0f6-46c65206f5f9','5a2d3288-0390-4f2e-a09a-3b065206f5f9','58404d26-eaa8-4c04-82e5-7d045206f5f9','5c5cb866-391c-404a-a9f7-540a5206f5f9','57bdcd1f-a474-43e0-8e54-5f3a5206f5f9','57f3d359-f5d4-4a03-b9f3-29a15206f5f9','58fa2ce7-8fe8-4fdc-9675-32785206f5f9','590b73b9-2960-4c3f-8b5e-31b35206f5f9','59318b7f-12a8-4e32-917b-7b435206f5f9','5af9d47d-8c68-4bd0-bee8-58085206f5f9','5a317d2c-c22c-4c30-bfab-245c5206f5f9','59e90517-5ed0-4796-95fd-77225206f5f9','5a8717a6-4e94-4cb0-8a25-0a5c5206f5f9','59a99331-e614-4004-8634-16bc5206f5f9','59af0a5d-513c-4ed7-9daf-6d845206f5f9','5af9a8b2-06a4-40b4-acf6-07ea5206f5f9','59c2bd2d-fc20-4efb-86a1-33955206f5f9','5a3039c7-7a38-4d18-a7d7-5b765206f5f9','590b4d4c-1110-47b9-af8b-202e5206f5f9','5a09be9b-336c-4208-a96c-2d505206f5f9','5a4d1178-d4d0-4a04-95b5-54d85206f5f9','59230b2f-bdb4-45cc-b3ff-76e55206f5f9','5a81ddce-186c-4903-adc8-21565206f5f9','5a565410-6288-4eeb-8f45-78ea5206f5f9','5aa1a8ff-1294-4b04-9044-576b5206f5f9','5a980634-efb4-4849-aa0f-17b05206f5f9','5a8206d3-d2b4-49b3-843b-11bc5206f5f9','5a58fc3d-37d4-43a1-992b-45a55206f5f9','5a562b13-b310-42d6-badf-1ad65206f5f9','5a70fdf7-cb30-440e-af77-14f75206f5f9','5ad8ae00-e10c-4a35-a5c6-5cb35206f5f9','5abeadde-ace8-46e4-b456-0fea5206f5f9','5aba67c1-a8c8-4f55-a83a-3a0a5206f5f9','5aa9724c-b8a8-47e5-98cc-21e65206f5f9','5ade1d25-f28c-4137-a080-64105206f5f9','5ad385d7-fcd4-423e-ac99-33625206f5f9','5b687f64-1074-4f2d-88ca-3d365206f5f9','5b217282-ef14-4990-a436-20f55206f5f9','5b2bb89e-3204-461e-b6a1-099f5206f5f9','5b6b34d6-40b8-483c-826e-68525206f5f9','5a43b245-4738-4607-8ed3-1f3c5206f5f9','59a4a07f-fa60-4de0-911c-699a5206f5f9','5a302f88-f984-4076-aaa1-47c15206f5f9','5b153ba0-5f0c-41e7-959c-3fcf5206f5f9','5b7adab1-2654-4345-9cc2-0a785206f5f9','5b92ca90-34e0-4019-a17b-52bb5206f5f9','59a06537-01fc-4bc1-81b7-7ad25206f5f9','5b5a2703-9660-4860-b221-32ca5206f5f9','58405524-3c70-49fc-a996-6dbf5206f5f9','583f2c80-ea88-48bd-a4ba-3f035206f5f9','5a1c7352-b910-474e-86c1-40705206f5f9','5c6b6a37-8198-40cd-8442-67fc5206f5f9','5c6b6b95-7668-471c-934c-5ddb5206f5f9','590a3af0-8e04-4e06-ae1b-12405206f5f9','583352f9-d400-4da5-a7c8-48645206f5f9','59df7a08-d680-41a2-b33e-2eae5206f5f9','5a257762-6988-416b-8f13-1f735206f5f9','5a4693eb-0408-48d9-ad3c-306c5206f5f9','5a6740c3-72d8-4fc3-a844-735e5206f5f9','59fba6af-bbe4-442d-972e-3d715206f5f9','5a7345e7-3ee8-4b47-a700-30f15206f5f9','5a13452c-8df0-4900-8616-2e185206f5f9','5a60be6b-8038-4793-b9eb-23255206f5f9','5a14428f-9d48-4017-a644-6e8d5206f5f9','5a4f98e5-4e38-466e-8669-122a5206f5f9','59a2e4ef-2f84-4dd6-a7fe-3ed15206f5f9','5a2ec6eb-8c24-4e9c-87aa-41bd5206f5f9','59dd4424-fe1c-485c-b6cd-1b485206f5f9','5a4fd1c7-b21c-4023-b545-263f5206f5f9','5a53aa79-184c-47a6-a2a3-313a5206f5f9','5a2ace7a-7b24-4d2a-b676-6c9d5206f5f9','5a8ae3f2-7158-495b-ba25-3c085206f5f9','59ea2b38-4154-40c8-8aed-6b395206f5f9','5a57b9dd-93f0-4abd-81c8-28bc5206f5f9','5a66533b-d89c-4478-8f6c-37015206f5f9','5a9efd91-b278-458b-9eb4-608a5206f5f9','5c6b4275-d2d4-4c55-98a6-44785206f5f9','5c87e429-1794-419e-8c84-08485206f5f9','5c6b457c-e7dc-47cb-bba7-34db5206f5f9','5c7fe534-32c8-45dc-8f21-01bf5206f5f9','5c87e6c4-ae88-4da5-ab6d-0e975206f5f9','5c6b4b03-157c-4a28-8236-1c545206f5f9','5c7ff378-5284-49ef-90d3-31965206f5f9','5c6c391e-8e18-4106-8e5a-7aaf5206f5f9','5c6c733f-631c-42a9-9b02-11855206f5f9','5c6b4dbc-f87c-463c-962e-19915206f5f9','5c8941fc-5b00-4c1d-8063-5a7e5206f5f9','5c803365-3704-4b3f-8c79-5bfb5206f5f9','5c87ee2c-3534-46ba-a49e-08485206f5f9','5c6c3c5b-94cc-4f8d-8833-128e5206f5f9','5c6c7600-7848-414e-a503-2ca25206f5f9','5c802215-eb68-415c-8b78-76555206f5f9','5c6b5dbd-ad4c-4558-aecf-5dbe5206f5f9','5c802a0a-6190-483b-bd7c-19725206f5f9','5c6b30ac-036c-4073-b9e4-198e5206f5f9','5c818e6a-0cd4-443a-8d8f-46285206f5f9','5c6b3aa2-9b50-43ea-908e-0e4a5206f5f9','5c87f0b2-d280-40bd-a827-15405206f5f9','5c892c06-6cf0-468b-872d-68695206f5f9','5c8025b5-e930-4ab5-b87c-19715206f5f9','5c89333f-b684-4593-b87c-7aac5206f5f9','5c66f565-61d0-4834-9d32-6c675206f5f9','5c6b5e5a-00cc-4c97-a95b-5dd95206f5f9','5c6b3572-56a0-4d27-a23e-44785206f5f9','5c6c70fc-fd20-4769-9ee1-088e5206f5f9','5c802fca-1ee4-4f10-a2be-0e805206f5f9','5c89366f-5600-491a-9c27-1f965206f5f9','5c82ba4e-aca8-40d8-9ed8-0cbe5206f5f9','5c6b3f3c-2ba0-4dad-8764-19915206f5f9','5c6c7c8b-bde8-4bc9-91ef-533d5206f5f9','5c7fdb4d-3688-46a2-b808-45615206f5f9','5c82ca25-1eec-4427-871f-7b095206f5f9','5c87f30e-bf94-41ab-b234-15415206f5f9','5c6b5ef7-6c28-4774-afbc-67d45206f5f9','5c893fc1-44d8-48e7-8844-5a785206f5f9','5c019c1b-b370-4732-aa47-1db25206f5f9','5bcf4f57-8658-4484-84b4-165c5206f5f9','59b6bd5d-1008-4d2c-8194-263b5206f5f9','5a54f181-e37c-41da-9f62-42925206f5f9','5a393a3a-7628-4bce-b9ea-556b5206f5f9','584054cb-f3d8-4c38-b560-03135206f5f9','5840533c-27a0-4c85-8603-7a475206f5f9','590a3e6e-ac64-4341-af5b-18165206f5f9','5840528b-6010-4133-8fef-7d065206f5f9','5e862221-758c-48b1-a7cf-11bcc0a80a41','5e860049-7e9c-4f9d-9911-37c4c0a80a41','5e8622bc-0ef4-472a-a19b-6f4bc0a80a41','5e83a2da-3c78-430f-95aa-236fc0a80a41','5e86018d-79d4-4d30-998e-69e6c0a80a41','5e862439-c108-40be-b3ec-36b6c0a80a41','5e791e51-81d0-48f5-a6c1-31e3c0a80a41','59f0f5dc-31bc-41b6-860b-0a415206f5f9','5e83a579-e5c4-45a1-82bd-792ec0a80a41','5e86031d-5590-4c2b-97a6-44d6c0a80a41','5d24927d-161c-4287-9ef7-7494c0a80a41','58405401-f23c-46b2-8dfc-032d5206f5f9','5a5e3aba-95d4-4577-bbe8-67375206f5f9','5b7ae951-7e04-4262-a599-2f745206f5f9']\")\n",
    "#data.groupby(['event_id','location.city']).apply(len)\n",
    "#data\n",
    "\n",
    "\n",
    "#data1 = data.sort_values(by=['location.city'],ascending=False) \n",
    "#data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd0f252-f72d-4b36-8b47-59d4fd36c793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273dab76-4c0e-4707-9c99-dbc1c2d891df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1 = data1.rename(columns={0: 'qty'})\n",
    "#data2 = data1.sort_values(by=['qty'],ascending=False)\n",
    "#data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbadf40a-1ad5-40a7-8489-563ab5912acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=df.query('lineage.event_series.id in [\"4d7f441a-4fbc-4a3e-b0d1-4e1b7f000001\",\"599c4cc7-e910-45d2-9706-4cbe5206f5f9\"]')\n",
    "#data.groupby(['lineage.event_series.id','event.id']).apply(len)\n",
    "\n",
    "#data=df.query(\"`event_id` in ['57f3d359-f5d4-4a03-b9f3-29a15206f5f9', '5e862439-c108-40be-b3ec-36b6c0a80a41', '583f013a-1e54-4906-87f7-2b625206f5f9', '5e8622bc-0ef4-472a-a19b-6f4bc0a80a41']\")\n",
    "\n",
    "\n",
    "#data.shape\n",
    "#data.groupby(['sequence_id','event.id']).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dcc753-1010-4f3e-ba01-e23db1a8151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2['qty'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb169bc-251d-4e04-a7d0-2063c4f2c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that these two sequences have historical event data, and different numbers of runners\n",
    "# so lets separate this into a training and validation set\n",
    "#test=data.query(\"`event_id` in ['590b4d4c-1110-47b9-af8b-202e5206f5f9', '57f3d359-f5d4-4a03-b9f3-29a15206f5f9']\")\n",
    "#train=data.query(\"`event_id` not in ['590b4d4c-1110-47b9-af8b-202e5206f5f9', '57f3d359-f5d4-4a03-b9f3-29a15206f5f9']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff552ce-c774-4b8b-9a0d-5b762a33a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d33f00-55fa-445c-894d-5a7f0a1140fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say that I want to include in my pipeline the ratio of men to non-men\n",
    "# in the race. I can create that with the following:\n",
    "#sequence_stats=train.groupby(['event_id','location.city']).apply(lambda x: sum(x['sex']==2)/len(x)).groupby(['location.city']).apply(np.mean)\n",
    "#sequence_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0838579c-7461-4d75-b8a8-005cee74a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To embed this data in my pipeline, I need to add it to one of the steps - either\n",
    "# a transformer or an estimator - as an object. Then when this gets serialized as\n",
    "# part of the pickle process it will be there for estimation. Let's create a new\n",
    "# transformer which does this, our strategy will be that the __init__ function\n",
    "# will calculate our sequence stats data and store it in the object, while our\n",
    "# transform function will add that to unseen data as a column\n",
    "#import numpy as np\n",
    "\n",
    "class EventSexRatio(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator):\n",
    "    \n",
    "    # this will be called when we first make our pipeline, so we can store things\n",
    "    def __init__(self, train):\n",
    "        # as we want to visualize this later we have to have something in the train\n",
    "        # attribute, which is the parameter to this function. I'll just make this the \n",
    "        # first row of the data coming in.\n",
    "        self.train=train.iloc[0]\n",
    "        \n",
    "        self.sequence_stats=train.groupby(['event_id','location.city']).apply(\n",
    "            lambda x: sum(x['sex']=='Male')/len(x)).groupby(['event_id']).apply(np.mean)\n",
    "        # you need to name a series in order to merge it later\n",
    "        self.sequence_stats.name='sex_event_ratio'\n",
    "    \n",
    "    # this does nothing interesting\n",
    "    def fit(self, data=None, y=None):\n",
    "        return self\n",
    "    # this will be called when we want to predict our data, since it will transform\n",
    "    def transform(self, data):\n",
    "        # we can print out some diagnostics here, let's check how many sequences in the\n",
    "        # data we are trying to transform existing in our historical dataset\n",
    "        print(f'The number of sequences which are also in our historical data are {len(set(data[\"event_id\"].unique()).intersection(self.sequence_stats.index))}')\n",
    "        # align on index via a left join\n",
    "        newdata=pd.merge(data,self.sequence_stats,left_on='event_id',right_index=True,how='left')\n",
    "        # set our new sex_sequence_ratio column \n",
    "        data['EventSexRatio']=newdata['sex_event_ratio']\n",
    "        # return all of the data to the next stage of the pipeline\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a75c33-5742-4e12-9f67-dd7888d21fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can build a little pipeline and use this column as a predictor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"EventSexRatio\", EventSexRatio(train)),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.city\", OneHotEncoder(categories=[['Scottsdale', 'San Francisco', 'San Diego', 'Arcata', 'Denver',\n",
    "       'Tampa', 'Atlanta', 'Chicago', 'Highland Park',\n",
    "       'Elk Grove Village', 'Oak Park', 'Indianapolis', 'Port Huron',\n",
    "       'Flint', 'Swartz Creek', 'Royal Oak', 'Pinconning', 'Roscommon',\n",
    "       'Plymouth', 'Algonac', 'Fenton', 'Detroit', 'Pigeon',\n",
    "       'Bloomfield Hills', 'Rogers City', 'Caseville', 'Montrose',\n",
    "       'Milford', 'Mackinac Island', 'Sault Ste. Marie', 'East Lansing',\n",
    "       'Williamston', 'Howell', 'Minneapolis', 'St. Louis', 'Santa Fe',\n",
    "       'Charlotte', 'Columbus', 'Canal Fulton', 'Brewster', 'Hartville',\n",
    "       'Strasburg', 'North Canton', 'Clinton', 'Cadiz', 'Dalton',\n",
    "       'Alliance', 'Barberton', 'Millersburg', 'Peninsula', 'Bolivar',\n",
    "       'Massillon', 'Canton', 'Akron', 'Oklahoma City', 'Tulsa', 'Norman',\n",
    "       'Edmond', 'Lawton', 'Stillwater', 'Moore', 'Perry', 'Seiling',\n",
    "       'Bethany', 'Elk City', 'Sulphur', 'Yukon', 'Beaverton', 'Salem',\n",
    "       'Albany', 'Philadelphia', 'Nashville', 'Houston', 'Dallas',\n",
    "       'Virginia Beach', 'Fairfax', 'West Point', 'Seattle',\n",
    "       'Parkersburg', 'Milwaukee']], handle_unknown='ignore'), ['location.city']),\n",
    "            ('cols_to_keep', 'passthrough', ['age','EventSexRatio']),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"regressor\", RandomForestRegressor())\n",
    "    ])\n",
    "\n",
    "# now let's visually inspect our pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "display(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93646fbc-8ee5-4886-b0ff-4e667add84fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['overall_ranking'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee08508-1386-49a9-944f-da575924b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train=train.loc[train['overall_ranking'] == 'nan', 'overall_ranking'] = 1753\n",
    "#holdout=holdout.loc[holdout['overall_ranking'] == 'nan', 'overall_ranking'] = 1628\n",
    "#test=test.loc[test['overall_ranking'] == 'nan', 'overall_ranking'] = 1107\n",
    "\n",
    "#train=train.loc[train['overall_ranking'] == 'NaN', 'overall_ranking'] = 1753\n",
    "#holdout=holdout.loc[holdout['overall_ranking'] == 'NaN', 'overall_ranking'] = 1628\n",
    "#test=test.loc[test['overall_ranking'] == 'NaN', 'overall_ranking'] = 1107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53828c4-6d15-4d84-88b6-4276fece2478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['overall_ranking']=train['overall_ranking'].dropna()\n",
    "#holdout['overall_ranking']=holdout['overall_ranking'].dropna()\n",
    "#test['overall_ranking']=test['overall_ranking'].dropna()\n",
    "\n",
    "train=train.dropna(subset=['overall_ranking'])\n",
    "holdout=holdout.dropna(subset=['overall_ranking'])\n",
    "test=test.dropna(subset=['overall_ranking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a70bca3-d1a8-4f80-9e33-ee3d3080ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.filter(items=['event.date.start', 'clean_categories.name','counts.participants.expected','age','sex','event_id', 'location.state','location.city','categories.name'])\n",
    "y_train = train.filter(items=['overall_ranking'])\n",
    "\n",
    "X_holdout = holdout.filter(items=['event.date.start', 'clean_categories.name','counts.participants.expected','age','sex','event_id', 'location.state','location.city','categories.name'])\n",
    "y_holdout = holdout.filter(items=['overall_ranking'])\n",
    "\n",
    "X_test = test.filter(items=['event.date.start','clean_categories.name','counts.participants.expected','age','sex','event_id', 'location.state','location.city','categories.name'])\n",
    "y_test = test.filter(items=['overall_ranking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3dfa4a-c234-49ef-bb4a-3740f1849621",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_nan = holdout['overall_ranking'].isnull().sum()\n",
    "check_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5807f1a-c4cc-4919-a267-769e733356f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have a pipeline that will first add in our new column of data then\n",
    "# pass this on to the rest of the pipeline. Importantly, the new data is\n",
    "# added when we create the object, through the constructor, and is merged\n",
    "# with the data we are fitting to or predicting on when the transform()\n",
    "# function is called. Since the object is *not* created when we predict, and\n",
    "# instead is loaded through the pickle process, it means we can embed historical\n",
    "# data in the pipeline for use in the future.\n",
    "\n",
    "# We now have to fit out pipeline, this will just call the transform() and fit()\n",
    "# functions of the objects in the pipeline, but will not create new objects.\n",
    "fitted_train_pipe=pipe.fit(X_train, y_train)\n",
    "#fitted_holdout_pipe=pipe.fit(X_train, y_train)\n",
    "#fitted_test_pipe=pipe.fit(X_train, y_train)\n",
    "\n",
    "# And we can take that final regression object and observe the coefficients\n",
    "# to verify that we have four, two for sex, one for sexsequenceratio, and\n",
    "# one age\n",
    "#fitted_pipe.steps[-1][1].coef_\n",
    "\n",
    "#cloudpickle.dump(fitted_pipe, open('pipeline.cloudpickle','wb'))\n",
    "#autograde(holdout)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6697d4-4a38-425d-b1c5-7c82cc4dedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitted_holdout_pipe=pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa2a55-c056-4736-b853-1ef1bf945125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitted_test_pipe=pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a4bf7a-37c5-490f-b75f-311c6546e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "\n",
    "#holdout=holdout.rename(columns={'event.id':'event_id'})\n",
    "\n",
    "# This code simulates the autograder. It is not the full autograder implementation\n",
    "# but shares an API with the autograder. It expects that your fitted pipeline is\n",
    "# submitted with the name pipeline.cloudpickle as demonstrated above. This object\n",
    "# must implement the predict() function. This is done automatically by the sklearn\n",
    "# Pipeline object if the last element of your pipeline is a classifier which has\n",
    "# a predict() function. If you are not submitting a Pipeline, and want to do something\n",
    "# different, you *must* have a predict() function of the same method signature, e.g.:\n",
    "#\n",
    "#   predict(self, X, **predict_params)->np.ndarray\n",
    "\n",
    "# Load holdout data, in this case I'll simulate it by loading the training data\n",
    "#df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "\n",
    "# And evaluate on all 5k races that we didn't consider for training\n",
    "#holdout_data=df.query(\"`event.id`!='583f013a-1e54-4906-87f7-2b625206f5f9' and `clean_categories.name`=='5k'\")\n",
    "\n",
    "\n",
    "# This is the scoring function to determine model fitness\n",
    "def score(left: pd.DataFrame, right: pd.DataFrame):\n",
    "    '''\n",
    "    Calculates the difference between the left and the right when considering rank of items. \n",
    "    This scoring function requires that the two DataFrames have identical indicies, and that\n",
    "    they each contain only one column of values and no missing values. Props to Blake Atkinson\n",
    "    for providing MWE indicating issues with autograder version #1.\n",
    "    '''\n",
    "    assert(type(left)==pd.DataFrame)\n",
    "    assert(type(right)==pd.DataFrame)\n",
    "    assert(len(left)==len(right))\n",
    "    assert(not np.any(np.isnan(left)))\n",
    "    assert(not np.any(np.isnan(right)))\n",
    "    assert(left.index.equals(right.index))\n",
    "    # convert to ndarrays\n",
    "    left=left.squeeze()\n",
    "    right=right.squeeze()\n",
    "    return np.sum(np.abs(left-right))/(len(left)*(len(left)-1))\n",
    "\n",
    "# This function runs the prediction model agains a given event/category pair. It\n",
    "# intentionally loads the student model each time to avoid accidental leakage of data\n",
    "# between events.\n",
    "def evaluate(data, pipeline_file='pipeline.cloudpickle'):\n",
    "    # Load student pipeline\n",
    "    fitted_pipe = cloudpickle.load(open(pipeline_file,'rb'))\n",
    "    \n",
    "    # Separate out the X and y\n",
    "    X=list(set(data.columns)-{'overall_ranking'})\n",
    "    y=['overall_ranking']\n",
    "    \n",
    "    # Drop any missing results (DNFs)\n",
    "    data=data.dropna(subset=['overall_ranking'])\n",
    "    \n",
    "    # Ensure there is data to actually predict on\n",
    "    if len(data)==0:\n",
    "        return np.nan\n",
    "\n",
    "    # Predict on unseen data\n",
    "    from IPython.utils import io\n",
    "    with io.capture_output() as captured:\n",
    "        predictions=pd.DataFrame(fitted_pipe.predict(data[X]),data.index)\n",
    "    observed=data[y]\n",
    "    \n",
    "    # Generate rankings within this bracket\n",
    "    observed=pd.DataFrame(data[y].rank(),data.index)\n",
    "    \n",
    "    # Return the ratio of the student score\n",
    "    return pd.Series({\"score\":score(observed,predictions)})\n",
    "\n",
    "# Student solution\n",
    "pipeline_file='pipeline.cloudpickle'\n",
    "\n",
    "\n",
    "\n",
    "# Run prediction on each group\n",
    "results=holdout.groupby(['event_id','clean_categories.name']).apply(evaluate, pipeline_file)\n",
    "\n",
    "# Display the results, uncomment this for your own display\n",
    "results.reset_index()['score'].plot.bar();\n",
    "\n",
    "# This is the student final grade\n",
    "np.average(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2d0565-8298-4ca3-b461-de07668d7862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we can now try this on unseen data\n",
    "fitted_pipe.score(test, test['X_result.duration.chip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd1fb0e-a7c1-4d48-9916-2444e678d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ab72bd-23be-4fb0-b413-646a62bf6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = ['age','sex','X_result.duration.chip','X_result.duration.pace'].split()\n",
    "\n",
    "#event = df['event.id']\n",
    "#overall_ranking = df['overall_ranking']\n",
    "\n",
    "\n",
    "#y = overall_ranking\n",
    "#y=pd.to_timedelta(train['result.duration.chip']).astype(int)\n",
    "#X = df1\n",
    "\n",
    "\n",
    "\n",
    "#X = df1.filter(items=['age','sex','X_result.duration.chip','X_result.duration.pace'])\n",
    "#X_rem = df1.filter(items=['age','sex','X_result.duration.chip','X_result.duration.pace'])\n",
    "#y = df1.filter(items=['event_id'])\n",
    "#y_rem = df1.filter(items=['event_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12a5909-5123-46ea-87df-af0e8bd7abe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "preprocessor = StandardScaler()\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641ec2a-d10f-4201-a342-65f28118787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_LinR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('LinearRegression', LinearRegression())\n",
    "    ])\n",
    "\n",
    "pipe_LogR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('LogisticRegression', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "pipe_BR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('BaggingRegressor', BaggingRegressor())\n",
    "    ])\n",
    "\n",
    "pipe_ETR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('ExtraTreesRegressor', ExtraTreesRegressor())\n",
    "    ])\n",
    "\n",
    "pipe_ABR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('AdaBoostRegressor', AdaBoostRegressor())\n",
    "    ])\n",
    "\n",
    "pipe_GBR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('GradientBoostingRegressor', GradientBoostingRegressor())\n",
    "    ])\n",
    "\n",
    "pipe_XGBR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('XGBRegressor', XGBRegressor())\n",
    "    ])\n",
    "\n",
    "pipe_VR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('VotingRegressor', VotingRegressor(estimators=10))\n",
    "    ])\n",
    "\n",
    "pipe_SR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('StackingRegressor', StackingRegressor(estimators=10))\n",
    "    ])\n",
    "\n",
    "pipe_HGBR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('HistGradientBoostingRegressor', HistGradientBoostingRegressor())\n",
    "    ])\n",
    "\n",
    "pipe_RFR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('RandomForestRegressor', RandomForestRegressor())\n",
    "    ])\n",
    "\n",
    "# Creating pipeline for categorical variables with missing value should be \"None\"\n",
    "cat_pipeline_none = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant',fill_value='None')),\n",
    "        ('encoder', OneHotEncoder(sparse=False,handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "# Creating pipeline for categorical variables where we plug missing value with most frequent value\n",
    "cat_pipeline_freq = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(sparse=False,handle_unknown='ignore'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5148eaf3-b890-4c47-aee6-415fe5e21408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#holdout['event_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb8bb7-1294-4565-997e-e26970300199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can build a little pipeline and use this column as a predictor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"holdout_data\", holdout),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.city\", OneHotEncoder(categories=[['Scottsdale', 'San Francisco', 'San Diego', 'Arcata', 'Denver',\n",
    "       'Tampa', 'Atlanta', 'Chicago', 'Highland Park',\n",
    "       'Elk Grove Village', 'Oak Park', 'Indianapolis', 'Port Huron',\n",
    "       'Flint', 'Swartz Creek', 'Royal Oak', 'Pinconning', 'Roscommon',\n",
    "       'Plymouth', 'Algonac', 'Fenton', 'Detroit', 'Pigeon',\n",
    "       'Bloomfield Hills', 'Rogers City', 'Caseville', 'Montrose',\n",
    "       'Milford', 'Mackinac Island', 'Sault Ste. Marie', 'East Lansing',\n",
    "       'Williamston', 'Howell', 'Minneapolis', 'St. Louis', 'Santa Fe',\n",
    "       'Charlotte', 'Columbus', 'Canal Fulton', 'Brewster', 'Hartville',\n",
    "       'Strasburg', 'North Canton', 'Clinton', 'Cadiz', 'Dalton',\n",
    "       'Alliance', 'Barberton', 'Millersburg', 'Peninsula', 'Bolivar',\n",
    "       'Massillon', 'Canton', 'Akron', 'Oklahoma City', 'Tulsa', 'Norman',\n",
    "       'Edmond', 'Lawton', 'Stillwater', 'Moore', 'Perry', 'Seiling',\n",
    "       'Bethany', 'Elk City', 'Sulphur', 'Yukon', 'Beaverton', 'Salem',\n",
    "       'Albany', 'Philadelphia', 'Nashville', 'Houston', 'Dallas',\n",
    "       'Virginia Beach', 'Fairfax', 'West Point', 'Seattle',\n",
    "       'Parkersburg', 'Milwaukee']], handle_unknown='ignore'), ['location.city']),\n",
    "             \n",
    "             (\"categories.name\", OneHotEncoder(categories=[['15k', '5k', 'marathon', 'half marathon', '15K', '5K', '10k',\n",
    "       '5 mile', 'Half Marathon', '8k', '5k run', '3k walk', '10k run',\n",
    "       'youth mile', '10K', '5k run/walk', '5k walk', '5 mile run',\n",
    "       '10k Run', '5k Run', '1 Mile Run', '15k run', '5k Walk', '10K Run',\n",
    "       '10K Walk', '6k run', '6k walk', '1 mile run', '1 mile walk',\n",
    "       '5K Run', '5K Walk', '8k Run', '10 Mile Run', '10 Mile Walk',\n",
    "       '5 Mile Run', '5 Mile Walk', '30k run', '30k bike', '8 mile run',\n",
    "       '8 mile walk', 'bridge run', 'Marathon',\n",
    "       'International Half Marathon', 'U.S. Only Half Marathon', '1 Mile',\n",
    "       '5.7 mile run', '5.7 mile walk', '5k competitive walk',\n",
    "       'half marathon run', '5k fun walk', '5k wheelchair',\n",
    "       '1 mile fun run', '2 mile run', '2 mile walk', '10k walk',\n",
    "       '4 mile run/walk', 'life time commitment day 5k',\n",
    "       'midnight streak', 'commitment day 5k - master',\n",
    "       'quarter marathon', '5k walk/run', '1 mile fun run/walk',\n",
    "       '5 km run', 'olympic triathlon', 'sprint triathlon',\n",
    "       'olympic duathlon', 'sprint duathlon', '10k scenic challenge',\n",
    "       'run swim run', '1 mile', 'Half Marathon Run',\n",
    "       'Half Marathon Walk', '2 Mile Run', '2 Mile Walk', 'Mini-Marathon']], handle_unknown='ignore'), ['categories.name']),\n",
    "             \n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "             \n",
    "            (\"event_id\", OneHotEncoder(categories=[['583f013a-1e54-4906-87f7-2b625206f5f9',\n",
    "       '5a0dec07-5730-4099-b7a9-6cc05206f5f9',\n",
    "       '5840463a-70d0-46c2-8954-6dbf5206f5f9',\n",
    "       '58405447-64f8-44f8-a81f-01985206f5f9',\n",
    "       '5a5b9a23-ecfc-46ef-8c9f-01e45206f5f9',\n",
    "       '57ed3e2f-5ee8-4195-acf7-4ea75206f5f9',\n",
    "       '59c93fda-556c-4a1c-8609-13895206f5f9',\n",
    "       '583f31b0-c090-4558-b0f6-46c65206f5f9',\n",
    "       '5a2d3288-0390-4f2e-a09a-3b065206f5f9',\n",
    "       '58404d26-eaa8-4c04-82e5-7d045206f5f9',\n",
    "       '5c5cb866-391c-404a-a9f7-540a5206f5f9',\n",
    "       '57bdcd1f-a474-43e0-8e54-5f3a5206f5f9',\n",
    "       '57f3d359-f5d4-4a03-b9f3-29a15206f5f9',\n",
    "       '58fa2ce7-8fe8-4fdc-9675-32785206f5f9',\n",
    "       '590b73b9-2960-4c3f-8b5e-31b35206f5f9',\n",
    "       '59318b7f-12a8-4e32-917b-7b435206f5f9',\n",
    "       '5af9d47d-8c68-4bd0-bee8-58085206f5f9',\n",
    "       '5a317d2c-c22c-4c30-bfab-245c5206f5f9',\n",
    "       '59e90517-5ed0-4796-95fd-77225206f5f9',\n",
    "       '5a8717a6-4e94-4cb0-8a25-0a5c5206f5f9',\n",
    "       '59a99331-e614-4004-8634-16bc5206f5f9',\n",
    "       '59af0a5d-513c-4ed7-9daf-6d845206f5f9',\n",
    "       '5af9a8b2-06a4-40b4-acf6-07ea5206f5f9',\n",
    "       '59c2bd2d-fc20-4efb-86a1-33955206f5f9',\n",
    "       '5a3039c7-7a38-4d18-a7d7-5b765206f5f9',\n",
    "       '590b4d4c-1110-47b9-af8b-202e5206f5f9',\n",
    "       '5a09be9b-336c-4208-a96c-2d505206f5f9',\n",
    "       '5a4d1178-d4d0-4a04-95b5-54d85206f5f9',\n",
    "       '59230b2f-bdb4-45cc-b3ff-76e55206f5f9',\n",
    "       '5a81ddce-186c-4903-adc8-21565206f5f9',\n",
    "       '5a565410-6288-4eeb-8f45-78ea5206f5f9',\n",
    "       '5aa1a8ff-1294-4b04-9044-576b5206f5f9',\n",
    "       '5a980634-efb4-4849-aa0f-17b05206f5f9',\n",
    "       '5a8206d3-d2b4-49b3-843b-11bc5206f5f9',\n",
    "       '5a58fc3d-37d4-43a1-992b-45a55206f5f9',\n",
    "       '5a562b13-b310-42d6-badf-1ad65206f5f9',\n",
    "       '5a70fdf7-cb30-440e-af77-14f75206f5f9',\n",
    "       '5ad8ae00-e10c-4a35-a5c6-5cb35206f5f9',\n",
    "       '5abeadde-ace8-46e4-b456-0fea5206f5f9',\n",
    "       '5aba67c1-a8c8-4f55-a83a-3a0a5206f5f9',\n",
    "       '5aa9724c-b8a8-47e5-98cc-21e65206f5f9',\n",
    "       '5ade1d25-f28c-4137-a080-64105206f5f9',\n",
    "       '5ad385d7-fcd4-423e-ac99-33625206f5f9',\n",
    "       '5b687f64-1074-4f2d-88ca-3d365206f5f9',\n",
    "       '5b217282-ef14-4990-a436-20f55206f5f9',\n",
    "       '5b2bb89e-3204-461e-b6a1-099f5206f5f9',\n",
    "       '5b6b34d6-40b8-483c-826e-68525206f5f9',\n",
    "       '5a43b245-4738-4607-8ed3-1f3c5206f5f9',\n",
    "       '59a4a07f-fa60-4de0-911c-699a5206f5f9',\n",
    "       '5a302f88-f984-4076-aaa1-47c15206f5f9',\n",
    "       '5b153ba0-5f0c-41e7-959c-3fcf5206f5f9',\n",
    "       '5b7adab1-2654-4345-9cc2-0a785206f5f9',\n",
    "       '5b92ca90-34e0-4019-a17b-52bb5206f5f9',\n",
    "       '59a06537-01fc-4bc1-81b7-7ad25206f5f9',\n",
    "       '5b5a2703-9660-4860-b221-32ca5206f5f9',\n",
    "       '58405524-3c70-49fc-a996-6dbf5206f5f9',\n",
    "       '583f2c80-ea88-48bd-a4ba-3f035206f5f9',\n",
    "       '5a1c7352-b910-474e-86c1-40705206f5f9',\n",
    "       '5c6b6a37-8198-40cd-8442-67fc5206f5f9',\n",
    "       '5c6b6b95-7668-471c-934c-5ddb5206f5f9',\n",
    "       '590a3af0-8e04-4e06-ae1b-12405206f5f9',\n",
    "       '583352f9-d400-4da5-a7c8-48645206f5f9',\n",
    "       '59df7a08-d680-41a2-b33e-2eae5206f5f9',\n",
    "       '5a257762-6988-416b-8f13-1f735206f5f9',\n",
    "       '5a4693eb-0408-48d9-ad3c-306c5206f5f9',\n",
    "       '5a6740c3-72d8-4fc3-a844-735e5206f5f9',\n",
    "       '59fba6af-bbe4-442d-972e-3d715206f5f9',\n",
    "       '5a7345e7-3ee8-4b47-a700-30f15206f5f9',\n",
    "       '5a13452c-8df0-4900-8616-2e185206f5f9',\n",
    "       '5a60be6b-8038-4793-b9eb-23255206f5f9',\n",
    "       '5a14428f-9d48-4017-a644-6e8d5206f5f9',\n",
    "       '5a4f98e5-4e38-466e-8669-122a5206f5f9',\n",
    "       '59a2e4ef-2f84-4dd6-a7fe-3ed15206f5f9',\n",
    "       '5a2ec6eb-8c24-4e9c-87aa-41bd5206f5f9',\n",
    "       '59dd4424-fe1c-485c-b6cd-1b485206f5f9',\n",
    "       '5a4fd1c7-b21c-4023-b545-263f5206f5f9',\n",
    "       '5a53aa79-184c-47a6-a2a3-313a5206f5f9',\n",
    "       '5a2ace7a-7b24-4d2a-b676-6c9d5206f5f9',\n",
    "       '5a8ae3f2-7158-495b-ba25-3c085206f5f9',\n",
    "       '59ea2b38-4154-40c8-8aed-6b395206f5f9',\n",
    "       '5a57b9dd-93f0-4abd-81c8-28bc5206f5f9',\n",
    "       '5a66533b-d89c-4478-8f6c-37015206f5f9',\n",
    "       '5a9efd91-b278-458b-9eb4-608a5206f5f9',\n",
    "       '5c6b4275-d2d4-4c55-98a6-44785206f5f9',\n",
    "       '5c87e429-1794-419e-8c84-08485206f5f9',\n",
    "       '5c6b457c-e7dc-47cb-bba7-34db5206f5f9',\n",
    "       '5c7fe534-32c8-45dc-8f21-01bf5206f5f9',\n",
    "       '5c87e6c4-ae88-4da5-ab6d-0e975206f5f9',\n",
    "       '5c6b4b03-157c-4a28-8236-1c545206f5f9',\n",
    "       '5c7ff378-5284-49ef-90d3-31965206f5f9',\n",
    "       '5c6c391e-8e18-4106-8e5a-7aaf5206f5f9',\n",
    "       '5c6c733f-631c-42a9-9b02-11855206f5f9',\n",
    "       '5c6b4dbc-f87c-463c-962e-19915206f5f9',\n",
    "       '5c8941fc-5b00-4c1d-8063-5a7e5206f5f9',\n",
    "       '5c803365-3704-4b3f-8c79-5bfb5206f5f9',\n",
    "       '5c87ee2c-3534-46ba-a49e-08485206f5f9',\n",
    "       '5c6c3c5b-94cc-4f8d-8833-128e5206f5f9',\n",
    "       '5c6c7600-7848-414e-a503-2ca25206f5f9',\n",
    "       '5c802215-eb68-415c-8b78-76555206f5f9',\n",
    "       '5c6b5dbd-ad4c-4558-aecf-5dbe5206f5f9',\n",
    "       '5c802a0a-6190-483b-bd7c-19725206f5f9',\n",
    "       '5c6b30ac-036c-4073-b9e4-198e5206f5f9',\n",
    "       '5c818e6a-0cd4-443a-8d8f-46285206f5f9',\n",
    "       '5c6b3aa2-9b50-43ea-908e-0e4a5206f5f9',\n",
    "       '5c87f0b2-d280-40bd-a827-15405206f5f9',\n",
    "       '5c892c06-6cf0-468b-872d-68695206f5f9',\n",
    "       '5c8025b5-e930-4ab5-b87c-19715206f5f9',\n",
    "       '5c89333f-b684-4593-b87c-7aac5206f5f9',\n",
    "       '5c66f565-61d0-4834-9d32-6c675206f5f9',\n",
    "       '5c6b5e5a-00cc-4c97-a95b-5dd95206f5f9',\n",
    "       '5c6b3572-56a0-4d27-a23e-44785206f5f9',\n",
    "       '5c6c70fc-fd20-4769-9ee1-088e5206f5f9',\n",
    "       '5c802fca-1ee4-4f10-a2be-0e805206f5f9',\n",
    "       '5c89366f-5600-491a-9c27-1f965206f5f9',\n",
    "       '5c82ba4e-aca8-40d8-9ed8-0cbe5206f5f9',\n",
    "       '5c6b3f3c-2ba0-4dad-8764-19915206f5f9',\n",
    "       '5c6c7c8b-bde8-4bc9-91ef-533d5206f5f9',\n",
    "       '5c7fdb4d-3688-46a2-b808-45615206f5f9',\n",
    "       '5c82ca25-1eec-4427-871f-7b095206f5f9',\n",
    "       '5c87f30e-bf94-41ab-b234-15415206f5f9',\n",
    "       '5c6b5ef7-6c28-4774-afbc-67d45206f5f9',\n",
    "       '5c893fc1-44d8-48e7-8844-5a785206f5f9',\n",
    "       '5bcf4f57-8658-4484-84b4-165c5206f5f9',\n",
    "       '59b6bd5d-1008-4d2c-8194-263b5206f5f9',\n",
    "       '5a54f181-e37c-41da-9f62-42925206f5f9',\n",
    "       '5a393a3a-7628-4bce-b9ea-556b5206f5f9',\n",
    "       '584054cb-f3d8-4c38-b560-03135206f5f9',\n",
    "       '5840533c-27a0-4c85-8603-7a475206f5f9',\n",
    "       '590a3e6e-ac64-4341-af5b-18165206f5f9',\n",
    "       '5840528b-6010-4133-8fef-7d065206f5f9',\n",
    "       '5e862221-758c-48b1-a7cf-11bcc0a80a41',\n",
    "       '5e860049-7e9c-4f9d-9911-37c4c0a80a41',\n",
    "       '5e8622bc-0ef4-472a-a19b-6f4bc0a80a41',\n",
    "       '5e83a2da-3c78-430f-95aa-236fc0a80a41',\n",
    "       '5e86018d-79d4-4d30-998e-69e6c0a80a41',\n",
    "       '5e862439-c108-40be-b3ec-36b6c0a80a41',\n",
    "       '5e791e51-81d0-48f5-a6c1-31e3c0a80a41',\n",
    "       '59f0f5dc-31bc-41b6-860b-0a415206f5f9',\n",
    "       '5e83a579-e5c4-45a1-82bd-792ec0a80a41',\n",
    "       '5e86031d-5590-4c2b-97a6-44d6c0a80a41',\n",
    "       '5d24927d-161c-4287-9ef7-7494c0a80a41',\n",
    "       '58405401-f23c-46b2-8dfc-032d5206f5f9',\n",
    "       '5a5e3aba-95d4-4577-bbe8-67375206f5f9',\n",
    "       '5b7ae951-7e04-4262-a599-2f745206f5f9']], handle_unknown='ignore'), ['event_id']),\n",
    "            ('event.date.start','counts.participants.expected','age','sex','cols_to_keep', 'passthrough'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"regressor\", RandomForestRegressor())\n",
    "    ])\n",
    "\n",
    "# now let's visually inspect our pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "display(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd941a1-52b7-46e7-8f0a-c480c67d02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_pipe=pipe.fit(holdout, holdout['overall_ranking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3048d910-df28-4c6e-8c8f-7e772c7c52a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "\n",
    "# This code simulates the autograder. It is not the full autograder implementation\n",
    "# but shares an API with the autograder. It expects that your fitted pipeline is\n",
    "# submitted with the name pipeline.cloudpickle as demonstrated above. This object\n",
    "# must implement the predict() function. This is done automatically by the sklearn\n",
    "# Pipeline object if the last element of your pipeline is a classifier which has\n",
    "# a predict() function. If you are not submitting a Pipeline, and want to do something\n",
    "# different, you *must* have a predict() function of the same method signature, e.g.:\n",
    "#\n",
    "#   predict(self, X, **predict_params)->np.ndarray\n",
    "\n",
    "# Load holdout data, in this case I'll simulate it by loading the training data\n",
    "#df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "\n",
    "# And evaluate on all 5k races that we didn't consider for training\n",
    "#holdout_data=df.query(\"`event.id`!='583f013a-1e54-4906-87f7-2b625206f5f9' and `clean_categories.name`=='5k'\")\n",
    "\n",
    "\n",
    "# This is the scoring function to determine model fitness\n",
    "def score(left: pd.DataFrame, right: pd.DataFrame):\n",
    "    '''\n",
    "    Calculates the difference between the left and the right when considering rank of items. \n",
    "    This scoring function requires that the two DataFrames have identical indicies, and that\n",
    "    they each contain only one column of values and no missing values. Props to Blake Atkinson\n",
    "    for providing MWE indicating issues with autograder version #1.\n",
    "    '''\n",
    "    assert(type(left)==pd.DataFrame)\n",
    "    assert(type(right)==pd.DataFrame)\n",
    "    assert(len(left)==len(right))\n",
    "    assert(not np.any(np.isnan(left)))\n",
    "    assert(not np.any(np.isnan(right)))\n",
    "    assert(left.index.equals(right.index))\n",
    "    # convert to ndarrays\n",
    "    left=left.squeeze()\n",
    "    right=right.squeeze()\n",
    "    return np.sum(np.abs(left-right))/(len(left)*(len(left)-1))\n",
    "\n",
    "# This function runs the prediction model agains a given event/category pair. It\n",
    "# intentionally loads the student model each time to avoid accidental leakage of data\n",
    "# between events.\n",
    "def evaluate(data, pipeline_file='pipeline.cloudpickle'):\n",
    "    # Load student pipeline\n",
    "    fitted_pipe = cloudpickle.load(open(pipeline_file,'rb'))\n",
    "    \n",
    "    # Separate out the X and y\n",
    "    X=list(set(data.columns)-{'overall_ranking'})\n",
    "    y=['overall_ranking']\n",
    "    \n",
    "    # Drop any missing results (DNFs)\n",
    "    data=data.dropna(subset=['overall_ranking'])\n",
    "    \n",
    "    # Ensure there is data to actually predict on\n",
    "    if len(data)==0:\n",
    "        return np.nan\n",
    "\n",
    "    # Predict on unseen data\n",
    "    from IPython.utils import io\n",
    "    with io.capture_output() as captured:\n",
    "        predictions=pd.DataFrame(fitted_pipe.predict(data[X]),data.index)\n",
    "    observed=data[y]\n",
    "    \n",
    "    # Generate rankings within this bracket\n",
    "    observed=pd.DataFrame(data[y].rank(),data.index)\n",
    "    \n",
    "    # Return the ratio of the student score\n",
    "    return pd.Series({\"score\":score(observed,predictions)})\n",
    "\n",
    "# Student solution\n",
    "pipeline_file='pipeline.cloudpickle'\n",
    "\n",
    "holdout=holdout.rename(columns={'event.id':'event_id'})\n",
    "\n",
    "# Run prediction on each group\n",
    "results=holdout.groupby([\"event_id\",\"clean_categories.name\"]).apply(evaluate, pipeline_file)\n",
    "\n",
    "# Display the results, uncomment this for your own display\n",
    "results.reset_index()['score'].plot.bar();\n",
    "\n",
    "# This is the student final grade\n",
    "np.average(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3927b2bb-0786-482f-867e-dc730aa39f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Think about the predictive modelling workflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Now that we have out outcome to predict, we want to think about what variables might\n",
    "# be useful in predicting this. For running it's well known that sex and age have impacts\n",
    "# at a population level, so we can start with those. But while age is numeric, sex is not.\n",
    "# If you look at the data, you'll see that sex actually has a host of different values,\n",
    "# and you can think about how to clean those. But for linear regression we need to make\n",
    "# this numeric. While there are various ways to do this, one hot encoding is a pretty\n",
    "# common one. So the strategy for this first model is to one hot encode sex with a binary\n",
    "# split of Male/Female, and to just use age as is, and train a linear regression model\n",
    "# with default parameters and then convert that timing into a ranking down the road.\n",
    "\n",
    "# There are several ways to do this. The autograder is expecting that you will have\n",
    "# saved a python object and that it has a predict(X) function where X is a pandas\n",
    "# DataFrame object that has all of the columns in the holdout data but only for one\n",
    "# combination of event.id and clean_categories.name. There are two high level strategies\n",
    "# here:\n",
    "#  1. Roll your own object, where you create your own object that has the predict()\n",
    "#     function and just does all the work in there however you want it to.\n",
    "#  2. Use sklearn.pipeline.Pipeline objects, where you leverage some of the resuable\n",
    "#     sklearn pipeline objects which were build for this purpose.\n",
    "\n",
    "# Importantly, there are non-exclusive options, and you can blend however you see fit.\n",
    "# I'll show examples of both, first being the roll your own\n",
    "\n",
    "def roll_own()->object:\n",
    "    \"\"\"This function returns a fitted object with a predict(x) function\"\"\"\n",
    "    \n",
    "    # First I'm going to create a new class with a predict function, and that class\n",
    "    # is just going to call the regression object it is setup with and then rerank\n",
    "    # all of the values which come back\n",
    "    class RollingRegressor():\n",
    "        \n",
    "        # For this class I'm going to assume it has been given a fitted model, so\n",
    "        # I'm choosing not to implement the fit() function.\n",
    "        def __init__(self, fitted_model):\n",
    "            self.regressor=fitted_model\n",
    "        \n",
    "        # For the prediction we are just given our dataframe, so we have to do our\n",
    "        # data cleaning here.\n",
    "        def predict(self, X):\n",
    "            # We need to be careful and *not* drop rows. The autograder is expecting\n",
    "            # a rank back for every row in X! Lets just grab out the two columns of\n",
    "            # interest\n",
    "            df=X[[\"age\",\"sex\"]]\n",
    "            \n",
    "            # For brevity let's get rid of any sex that isn't Male/Female and replace with nan\n",
    "            # A better approach would be to inspect and map this data accordingly, but I'll leave\n",
    "            # that as an enhancement.\n",
    "            df.loc[df.query(\"`sex` not in ['Male','Female']\").index, 'sex']=np.nan\n",
    "            \n",
    "            # Now that this is binary we can convert this column into a numeric value\n",
    "            df.loc[df.query(\"`sex` == 'Male'\").index, 'sex']=1\n",
    "            df.loc[df.query(\"`sex` == 'Female'\").index, 'sex']=0\n",
    "            \n",
    "            # Now just do whatever you want with missing values, this below doesn't seem ideal\n",
    "            df=df.fillna(-1)\n",
    "            \n",
    "            # With the data cleaning done, we can now predict the times for our data\n",
    "            times=self.regressor.predict(df)\n",
    "            \n",
    "            # We can't return the times directly - the autograder wants ranks. We can\n",
    "            # use a similar method those to return ranks\n",
    "            return times.squeeze().argsort()+1\n",
    "    \n",
    "    # Our return class is done, now we just need to initalize it with a fitted\n",
    "    # model. To fit the model we just do all of the cleaning over, and add in some training.\n",
    "    # It would be a better ideal to put this all in the class itself, but I want to\n",
    "    # show you that this isn't needed -- the autograder is NOT going to try and fit()\n",
    "    # your model, it is only going to call predict(), so you can do whatever you want\n",
    "    # within that predict()\n",
    "    \n",
    "    df=train[[\"age\",\"sex\"]]\n",
    "    df.loc[df.query(\"`sex` not in ['Male','Female']\").index, 'sex']=np.nan\n",
    "    df.loc[df.query(\"`sex` == 'Male'\").index, 'sex']=1\n",
    "    df.loc[df.query(\"`sex` == 'Female'\").index, 'sex']=0\n",
    "    df=df.fillna(-1)\n",
    "    \n",
    "    # Since we have decided it's a regression problem, we can decide to use a simple linear\n",
    "    # model for our first attempt too, so I'll create that now\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    reg=LinearRegression()\n",
    "    reg.fit(df,y)\n",
    "    \n",
    "    # Now we just return the object that the autograder will want\n",
    "    return RollingRegressor(reg)\n",
    "    \n",
    "# We can test this out by instantiating it\n",
    "fitted_reg=roll_own()\n",
    "# Then saving it to a file\n",
    "cloudpickle.dump(fitted_reg, open('pipeline.cloudpickle','wb'))\n",
    "# Then telling the autograder function to fire\n",
    "autograde(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99dcc87-d1db-449f-9683-a82bb3be816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0,train_size=0.8,test_size=0.2) \n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c69b44c-9add-48a9-84a3-f99ab6938738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "preprocessor = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5939b4-883a-465f-9dbb-f15057881b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2960213c-c6cb-4249-ab80-aabe3bceab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_LinR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('LinearRegression', LinearRegression())\n",
    "    ])\n",
    "\n",
    "pipe_LogR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('LogisticRegression', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "pipe_BR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('BaggingRegressor', BaggingRegressor())\n",
    "    ])\n",
    "\n",
    "pipe_ETR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('ExtraTreesRegressor', ExtraTreesRegressor())\n",
    "    ])\n",
    "\n",
    "pipe_ABR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('AdaBoostRegressor', AdaBoostRegressor())\n",
    "    ])\n",
    "\n",
    "pipe_GBR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('GradientBoostingRegressor', GradientBoostingRegressor())\n",
    "    ])\n",
    "\n",
    "pipe_XGBR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('XGBRegressor', XGBRegressor())\n",
    "    ])\n",
    "\n",
    "pipe_VR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('VotingRegressor', VotingRegressor(estimators=10))\n",
    "    ])\n",
    "\n",
    "pipe_SR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('StackingRegressor', StackingRegressor(estimators=10))\n",
    "    ])\n",
    "\n",
    "pipe_HGBR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('HistGradientBoostingRegressor', HistGradientBoostingRegressor())\n",
    "    ])\n",
    "\n",
    "pipe_RFR = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor), ('RandomForestRegressor', RandomForestRegressor())\n",
    "    ])\n",
    "\n",
    "# Creating pipeline for categorical variables with missing value should be \"None\"\n",
    "cat_pipeline_none = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant',fill_value='None')),\n",
    "        ('encoder', OneHotEncoder(sparse=False,handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "# Creating pipeline for categorical variables where we plug missing value with most frequent value\n",
    "cat_pipeline_freq = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(sparse=False,handle_unknown='ignore'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2131ae-a83b-4239-b025-cb9886d2ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That assignment should pass the autograder. A more pythonic way to do this, and certainly\n",
    "# the goal of the sklearn team, is to use pipelines, and reuse transformer objects to do the\n",
    "# data cleaning. In sklearn pipelines are made up of a sequence of Transformers with the last\n",
    "# item in the pipeline being an Estimator. You can have Estimators throughout the pipeline\n",
    "# too, creating new features through modeling. For instance, you could use PCA to reduce the\n",
    "# dimensionality of features and then learn on principal components instead.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# We can write a similar model to the above using pipelines and transformers. A good example\n",
    "# would be to first create a transformer for the columns of sex and age, and get rid of\n",
    "# everything else while one hot encoding sex\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "cleaner = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"sex\", OneHotEncoder(categories=[['Male','Female','Unspecified']], handle_unknown='ignore'), ['sex']),\n",
    "        ('age', 'passthrough', ['age']),\n",
    "    ], remainder='drop')\n",
    "\n",
    "# Then we create a three stage pipeline, where the first step applies the column transformer,\n",
    "# the next step fills our missing values, and the third step is a regression model. But remember,\n",
    "# this isn't a simple regression, we need an ordinal classification. To do this we can wrap\n",
    "# the linear regressor in another class which will transform the regression output. This class\n",
    "# is called the TransformedTargetRegressor, and we can tell it what function we want to apply\n",
    "# to the final output before returning the predictions.\n",
    "\n",
    "def evaluation_function(x):\n",
    "    '''Must return a ndarray of the rankings in order, the autograder will then create\n",
    "    a dataframe out of this with x.index as the index. Props to Rachell Calhoun!'''\n",
    "    return pd.Series(x.squeeze()).rank().values\n",
    "\n",
    "# We can wrap a linear regressor by setting the inverse_func to evaluation_function\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#reg=TransformedTargetRegressor(regressor=LinearRegression(), inverse_func=evaluation_function)\n",
    "reg=TransformedTargetRegressor(regressor=RandomForestRegressor(n_estimators=100, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0), inverse_func=evaluation_function)\n",
    "\n",
    "# Now we can build our three part pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"cleaner\", cleaner),\n",
    "        (\"fix_nans\", SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)),\n",
    "        (\"regressor\", reg)\n",
    "    ])\n",
    "\n",
    "# We can display the pipeline to see what it looks like and get a sense of data flow\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "display(pipe)\n",
    "\n",
    "# We can then fit the data in the pipeline\n",
    "fitted_pipe=pipe.fit(X_train,y)\n",
    "\n",
    "# And we can save it to an output file\n",
    "cloudpickle.dump(fitted_pipe, open('pipeline.cloudpickle','wb'))\n",
    "# Then telling the autograder function to fire\n",
    "autograde(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de60f444-465a-4987-a02c-1025c7044a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "LinR = LinearRegression()\n",
    "print('Parameters currently in use:\\n')\n",
    "print(LinR.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deee43a6-a58c-4cfe-9efa-5e1c82287cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogR = LogisticRegression()\n",
    "print('Parameters currently in use:\\n')\n",
    "print(LogR.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3d9d3-6159-4fc6-b8e4-6c20e4bb7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "BR = BaggingRegressor()\n",
    "print('Parameters currently in use:\\n')\n",
    "print(BR.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25fc52-3de5-41fc-bb33-62685fa23ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETR = ExtraTreesRegressor()\n",
    "print('Parameters currently in use:\\n')\n",
    "print(ETR.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d1aad-9d53-4777-906f-cdbb421f3149",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABR = AdaBoostRegressor()\n",
    "print('Parameters currently in use:\\n')\n",
    "print(ABR.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab878ae3-c701-46be-8094-7afc42dc83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR = GradientBoostingRegressor()\n",
    "print('Parameters currently in use:\\n')\n",
    "print(GBR.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d95b2-4782-4526-be64-94dd833a1a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBR = XGBRegressor()\n",
    "print('Parameters currently in use:\\n')\n",
    "print(XGBR.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4c671-3d73-4a3f-be09-0aa3ca0eba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "VR = VotingRegressor(estimators=10)\n",
    "print('Parameters currently in use:\\n')\n",
    "print(VR.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a32dd-6ec0-468d-8450-1ef1f30e1ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = StackingRegressor(estimators=10)\n",
    "print('Parameters currently in use:\\n')\n",
    "print(SR.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda6dbf6-2286-4051-b200-5617df20ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGBR = HistGradientBoostingRegressor()\n",
    "print('Parameters currently in use:\\n')\n",
    "print(HGBR.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f680df-c730-405d-87d6-8f3ef877db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR = RandomForestRegressor()\n",
    "print('Parameters currently in use:\\n')\n",
    "print(RFR.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75ce48-f810-4a7e-8f1e-b2381fe0c68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, GridSearchCV, cross_validate, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcff785-2293-4668-91f3-b390589163b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['location.state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899fee7f-738d-4659-9804-e7752fbb4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, GridSearchCV, cross_validate, KFold\n",
    "X_train = train.filter(items=['event.date.start','counts.participants.expected','age','sex','event_id', 'location.state','location.city','categories.name'])\n",
    "y_train = train.filter(items=['overall_ranking'])\n",
    "\n",
    "X_holdout = holdout.filter(items=['event.date.start','counts.participants.expected','age','sex','event_id', 'location.state','location.city','categories.name'])\n",
    "y_holdout = holdout.filter(items=['overall_ranking'])\n",
    "\n",
    "X_test = test.filter(items=['event.date.start','counts.participants.expected','age','sex','event_id', 'location.state','location.city','categories.name'])\n",
    "y_test = test.filter(items=['overall_ranking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b4373-29ca-43e0-8d29-18888a1ea95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "pipe_train_RFR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"training_data\", X_train),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"regressor\", RandomForestRegressor())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96719720-7350-46cb-91f3-b66d7409a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_holdout_RFR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"holdout_data\", X_holdout),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"regressor\", RandomForestRegressor())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c78b5-9d66-4a4f-b062-63a54ee0c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_test_RFR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"test_data\", X_test),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"regressor\", RandomForestRegressor())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a6509-a2b9-40e2-99b6-a14b8fb74cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_train_LR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"training_data\", X_train),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"LR\", LogisticRegression())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4822b719-9fe4-4398-9742-9e83b237d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_holdout_LR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"holdout_data\", X_holdout),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"LR\", LogisticRegression())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592dfc4c-5463-41fc-8e31-d20614602ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_test_LR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"test_data\", X_test),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"LR\", LogisticRegression())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a6ebc-1ca4-4701-a348-040512f7d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_train_ETR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"training_data\", X_test),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"ETR\", ExtraTreesRegressor())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6bd544-1150-438a-9b69-c1ec425c38dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_holdout_ETR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"test_data\", X_test),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"ETR\", ExtraTreesRegressor())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95fbed-a9cd-47cf-ada2-b8525681eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_test_ETR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"test_data\", X_test),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"ETR\", ExtraTreesRegressor())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b19788-10e6-4f21-b13e-870788eb6f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_train_BR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"training_data\", X_train),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"BR\", BaggingRegressor())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120f4fdb-837c-4153-bba1-59b9fe889b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_holdout_BR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"holdout_data\", X_holdout),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"BR\", BaggingRegressor())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac75591-9c35-4dce-9b8a-6ed1b82ea2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_test_BR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"test_data\", X_test),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"BR\", BaggingRegressor())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467e295-5a6e-4b0d-b8a2-25b719eba8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_train_XGBR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"training_data\", X_train),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"XGBR\", XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=None, subsample=1, verbosity=1))\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6801d3-1402-4b80-8a8f-5500d739da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_holdout_XGBR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"holdout_data\", X_holdout),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"XGBR\", XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=None, subsample=1, verbosity=1))\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb47c3-c412-403b-952a-ca8eeb36b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_test_XGBR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"test_data\", X_test),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"XGBR\", XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=None, subsample=1, verbosity=1))\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34862dab-4823-4abf-8306-8d9ddcce3a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_train_SR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"training_data\", X_train),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"SR\", StackingRegressor(estimators=10))\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c8471d-58f7-44bf-ab36-091c95df44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_holdout_SR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"holdout_data\", X_holdout),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"SR\", StackingRegressor(estimators=10))\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4574ca1-5385-4c9e-b4a3-77e27678e25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_test_SR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"test_data\", X_test),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"SR\", StackingRegressor(estimators=10))\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea3d482-0b5a-458f-a120-6c0cdbbad90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_train_HGBR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"training_data\", X_train),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"HGBR\", HistGradientBoostingRegressor())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f839389-c793-44e9-a0f3-8230a2a9ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_holdout_HGBR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"holdout_data\", X_holdout),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"HGBR\", HistGradientBoostingRegressor())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a1f9cf-b11d-4678-b0c5-7e8abec99711",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_test_HGBR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"test_data\", X_test),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"HGBR\", HistGradientBoostingRegressor())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedbee5b-17a7-484a-b3b7-29fea9ebcb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_train_GBR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"training_data\", X_train),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"GBR\", GradientBoostingRegressor())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b081db2f-2902-4f44-bcc8-7418de495dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_holdout_GBR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"holdout_data\", X_holdout),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"GBR\", GradientBoostingRegressor())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb04e435-e36a-461d-ad80-99e237326b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_test_GBR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"test_data\", X_test),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"GBR\", GradientBoostingRegressor())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99205d29-4805-4234-b237-6af20527a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_train_VR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"training_data\", X_train),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"VR\", VotingRegressor(estimators=10))\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f590c9-4839-48cb-8bad-b43c5d94263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_holdout_VR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"holdout_data\", X_holdout),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"VR\", VotingRegressor(estimators=10))\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe672ab-0478-4a94-8dbf-0fc8714433f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_test_VR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"test_data\", X_test),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"VR\", VotingRegressor(estimators=10))\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad1f7b-5d95-4ede-a5cf-3d8121707552",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_train_ABR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"training_data\", X_train),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"ABR\", AdaBoostRegressor())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b2c6e-0612-4454-8581-325ece0ab8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_holdout_ABR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"holdout_data\", X_holdout),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"ABR\", AdaBoostRegressor())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa083ae4-f25d-4285-b50b-4df64678786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_test_ABR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"test_data\", X_test),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"ABR\", AdaBoostRegressor())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4a90f8-d177-4542-8058-f3c4334d6efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_train_LinR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"training_data\", X_train),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"LinR\", LinearRegression())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966af66c-8c04-425e-9e52-b68ea9785e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_holdout_LinR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"holdout_data\", X_holdout),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"LinR\", LinearRegression())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02820d13-e245-49f3-81a7-36b437cfa0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_test_LinR = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"test_data\", X_test),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "            ('cols_to_keep', 'passthrough', 'age','sex','event.date.start','counts.participate.expected'),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        # this is our final estimator\n",
    "        (\"LinR\", LinearRegression())\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc915a-cc55-4658-872a-35bfc1fc2556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "state_trans = ColumnTransformer(transformers=[\n",
    "            (\"location.state\", OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state'])])\n",
    "state_trans.fit(X_train,y_train)\n",
    "state_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bce7cd0-4cc5-43a1-8b85-dcc11f873992",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['location.state'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38edfd52-1669-4e69-ba0c-b4d44f4f05f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"location.city\", OneHotEncoder(categories=[['Scottsdale', 'San Francisco', 'San Diego', 'Arcata', 'Denver',\n",
    "       'Tampa', 'Atlanta', 'Chicago', 'Highland Park',\n",
    "       'Elk Grove Village', 'Oak Park', 'Indianapolis', 'Port Huron',\n",
    "       'Flint', 'Swartz Creek', 'Royal Oak', 'Pinconning', 'Roscommon',\n",
    "       'Plymouth', 'Algonac', 'Fenton', 'Detroit', 'Pigeon',\n",
    "       'Bloomfield Hills', 'Rogers City', 'Caseville', 'Montrose',\n",
    "       'Milford', 'Mackinac Island', 'Sault Ste. Marie', 'East Lansing',\n",
    "       'Williamston', 'Howell', 'Minneapolis', 'St. Louis', 'Santa Fe',\n",
    "       'Charlotte', 'Columbus', 'Canal Fulton', 'Brewster', 'Hartville',\n",
    "       'Strasburg', 'North Canton', 'Clinton', 'Cadiz', 'Dalton',\n",
    "       'Alliance', 'Barberton', 'Millersburg', 'Peninsula', 'Bolivar',\n",
    "       'Massillon', 'Canton', 'Akron', 'Oklahoma City', 'Tulsa', 'Norman',\n",
    "       'Edmond', 'Lawton', 'Stillwater', 'Moore', 'Perry', 'Seiling',\n",
    "       'Bethany', 'Elk City', 'Sulphur', 'Yukon', 'Beaverton', 'Salem',\n",
    "       'Albany', 'Philadelphia', 'Nashville', 'Houston', 'Dallas',\n",
    "       'Virginia Beach', 'Fairfax', 'West Point', 'Seattle',\n",
    "       'Parkersburg', 'Milwaukee']], handle_unknown='ignore'), ['location.city']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed399fa9-6acb-46ab-a70c-a807a05ffee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"categories.name\", OneHotEncoder(categories=[['15k', '5k', 'marathon', 'half marathon', '15K', '5K', '10k',\n",
    "       '5 mile', 'Half Marathon', '8k', '5k run', '3k walk', '10k run',\n",
    "       'youth mile', '10K', '5k run/walk', '5k walk', '5 mile run',\n",
    "       '10k Run', '5k Run', '1 Mile Run', '15k run', '5k Walk', '10K Run',\n",
    "       '10K Walk', '6k run', '6k walk', '1 mile run', '1 mile walk',\n",
    "       '5K Run', '5K Walk', '8k Run', '10 Mile Run', '10 Mile Walk',\n",
    "       '5 Mile Run', '5 Mile Walk', '30k run', '30k bike', '8 mile run',\n",
    "       '8 mile walk', 'bridge run', 'Marathon',\n",
    "       'International Half Marathon', 'U.S. Only Half Marathon', '1 Mile',\n",
    "       '5.7 mile run', '5.7 mile walk', '5k competitive walk',\n",
    "       'half marathon run', '5k fun walk', '5k wheelchair',\n",
    "       '1 mile fun run', '2 mile run', '2 mile walk', '10k walk',\n",
    "       '4 mile run/walk', 'life time commitment day 5k',\n",
    "       'midnight streak', 'commitment day 5k - master',\n",
    "       'quarter marathon', '5k walk/run', '1 mile fun run/walk',\n",
    "       '5 km run', 'olympic triathlon', 'sprint triathlon',\n",
    "       'olympic duathlon', 'sprint duathlon', '10k scenic challenge',\n",
    "       'run swim run', '1 mile', 'Half Marathon Run',\n",
    "       'Half Marathon Walk', '2 Mile Run', '2 Mile Walk', 'Mini-Marathon']], handle_unknown='ignore'), ['categories.name']),\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed0b0e-73ec-49d7-8fb5-a5b03bbec0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_pipe=pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026d2c1e-4bff-4248-8a6d-ef61cad19618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#create a cross-validation scheme\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "min_samples_split= np.arange(start = 10 , stop = 200 , step=10 , dtype=int)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'regressor__bootstrap':[True],\n",
    "              'regressor__criterion' : ['squared_error','absolute_error','poisson'],\n",
    "              'regressor__min_samples_split':min_samples_split,\n",
    "              'regressor__max_features':['auto','sqrt','log2'],\n",
    "              'regressor__random_state':[0,42,88]}  \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "RFR = RandomForestRegressor()\n",
    "grid_pipeline_train_RFR = GridSearchCV(estimator=pipe_train_RFR, param_grid=param_grid, cv=folds, n_jobs=-1, verbose=2)\n",
    "grid_pipeline_train_RFR.fit(X_train, y_train)\n",
    "grid_pipeline_train_RFR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f094f8-da45-4b8e-9740-a82428e6dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running GridSearchCV, the best_params_ parameter was called to identify the recommended parameter setup\n",
    "\n",
    "#best_grid = grid_searcher.best_params_\n",
    "#best_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581173d-df1e-4b2e-b382-485d779417c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a cross-validation scheme\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {#create a cross-validation scheme\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'regressor__bootstrap':[True],\n",
    "              'regressor__criterion' : ['squared_error','absolute_error','poisson'],\n",
    "              'regressor__max_depth' : [1,2,3,4],\n",
    "              'regressor__max_features':['auto','sqrt','log2',None],\n",
    "              'regressor__random_state':[0,42,88]}  \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "RFR = RandomForestRegressor()\n",
    "grid_pipeline_holdout_RFR = GridSearchCV(estimator=pipe_holdout_RFR, param_grid=param_grid, cv=folds, n_jobs=-1, verbose=2)\n",
    "grid_pipeline_holdout_RFR.fit(X_holdout, y_holdout)\n",
    "grid_pipeline_holdout_RFR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b2aec-3e9b-44c6-a897-c0830a800728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a cross-validation scheme\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'regressor__bootstrap':[True],\n",
    "              'regressor__criterion' : ['squared_error','absolute_error','poisson'],\n",
    "              'regressor__max_depth' : [1,2,3,4],\n",
    "              'regressor__max_features':['auto','sqrt','log2',None],\n",
    "              'regressor__random_state':[0,42,88]}  \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "RFR = RandomForestRegressor()\n",
    "grid_pipeline_test_RFR = GridSearchCV(estimator=pipe_test_RFR, param_grid=param_grid, cv=folds, n_jobs=-1, verbose=2)\n",
    "grid_pipeline_test_RFR.fit(X_test, y_test)\n",
    "grid_pipeline_test_RFR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd6a59-0dfe-47a8-9a08-3bfc4844a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a cross-validation scheme\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "## identify parameters\n",
    "param_grid = {'LinR__bootstrap' : [True], \n",
    "              'LinR__max_depth' : [1,2,3,4], \n",
    "              'LinR__max_features' : [1,2,3,4],\n",
    "              'LinR__min_samples_split' : [1,2,3,4],\n",
    "              'LinR__n_estimators': [25, 50, 75, 100, 125, 150, 175, 200]}  \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "LinR = LinearRegression()\n",
    "grid_pipeline_train_LinR = GridSearchCV(estimator=pipe_train_LinR, param_grid=param_grid, cv=folds, n_jobs=-1, verbose=2)\n",
    "grid_pipeline_train_LinR.fit(X_train, y_train)\n",
    "grid_pipeline_train_LinR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4959da-9f9c-47ba-93e4-87fcf0d96e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a cross-validation scheme\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "## identify parameters\n",
    "param_grid = {'LinR__bootstrap' : [True], \n",
    "              'LinR__max_depth' : [1,2,3,4], \n",
    "              'LinR__max_features' : [1,2,3,4],\n",
    "              'LinR__min_samples_split' : [1,2,3,4],\n",
    "              'LinR__n_estimators': [25, 50, 75, 100, 125, 150, 175, 200]}  \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "LinR = LinearRegression()\n",
    "grid_pipeline_holdout_LinR = GridSearchCV(estimator=pipe_holdout_LinR, param_grid=param_grid, cv=folds, n_jobs=-1, verbose=2)\n",
    "grid_pipeline_holdout_LinR.fit(X_holdout, y_holdout)\n",
    "grid_pipeline_holdout_LinR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d0a9c-f71e-487a-a5e3-3bdb645dd656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a cross-validation scheme\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "## identify parameters\n",
    "param_grid = {'LinR__bootstrap' : [True], \n",
    "              'LinR__max_depth' : [1,2,3,4], \n",
    "              'LinR__max_features' : [1,2,3,4],\n",
    "              'LinR__min_samples_split' : [1,2,3,4],\n",
    "              'LinR__n_estimators': [25, 50, 75, 100, 125, 150, 175, 200]}  \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "LinR = LinearRegression()\n",
    "grid_pipeline_test_LinR = GridSearchCV(estimator=pipe_test_LinR, param_grid=param_grid, cv=folds, n_jobs=-1, verbose=2)\n",
    "grid_pipeline_test_LinR.fit(X_test, y_test)\n",
    "grid_pipeline_test_LinR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea107db-50e7-4c45-bfe0-c77d8d27b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'LR__penalty': ['l2', 'none', 'elasticnet'], \n",
    "            'LR__l1_ratio' : [0,1], \n",
    "            'LR__multi_class' : ['auto', 'ovr', 'multinomial'],\n",
    "            'LR__solver': ['lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "             'LR__random_state':[0,42],\n",
    "             'LR__max_iter':[50,75,100,125,150,175,200,225,250,275,300]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "LR = LogisticRegression()\n",
    "grid_pipeline_train_LR = GridSearchCV(estimator=pipe_train_LR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_train_LR.fit(X_train, y_train)\n",
    "grid_pipeline_train_LR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6315d94b-8405-42ca-bab0-90df8c0cffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'LR__penalty': ['l2', 'none', 'elasticnet'], \n",
    "            'LR__l1_ratio' : [0,1], \n",
    "            'LR__multi_class' : ['auto', 'ovr', 'multinomial'],\n",
    "            'LR__solver': ['lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "             'LR__random_state':[0,42],\n",
    "             'LR__max_iter':[50,75,100,125,150,175,200,225,250,275,300]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "LR = LogisticRegression()\n",
    "grid_pipeline_holdout_LR = GridSearchCV(estimator=pipe_holdout_LR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_holdout_LR.fit(X_holdout, y_holdout)\n",
    "grid_pipeline_holdout_LR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081747d-3a09-40d2-bbf1-e78b80dea257",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'LR__penalty': ['l2', 'none', 'elasticnet'], \n",
    "            'LR__l1_ratio' : [0,1], \n",
    "            'LR__multi_class' : ['auto', 'ovr', 'multinomial'],\n",
    "            'LR__solver': ['lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "             'LR__random_state':[0,42],\n",
    "             'LR__max_iter':[50,75,100,125,150,175,200,225,250,275,300]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "LR = LogisticRegression()\n",
    "grid_pipeline_test_LR = GridSearchCV(estimator=pipe_test_LR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_test_LR.fit(X_test, y_test)\n",
    "grid_pipeline_test_LR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9687adc3-de30-45c0-912e-d29718ec88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'ETR__n_estimators': [50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300], \n",
    "            'ETR__criterion' : ['squared_error','absolute_error'], \n",
    "            'ETR__max_depth' : [1,2,3,4],\n",
    "            'ETR__bootstrap': [True, False],\n",
    "             'ETR__random_state':[0,42,88],\n",
    "             'ETR__n_jobs':[1,2,3,4,5,-1]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "ETR = ExtraTreesRegressor()\n",
    "grid_pipeline_train_ETR = GridSearchCV(estimator=pipe_train_ETR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_train_ETR.fit(X_train, y_train)\n",
    "grid_pipeline_train_ETR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c346e2-15f8-4541-8f3e-81cabef81500",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'ETR__n_estimators': [50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300], \n",
    "            'ETR__criterion' : ['squared_error','absolute_error'], \n",
    "            'ETR__max_depth' : [1,2,3,4],\n",
    "            'ETR__bootstrap': [True, False],\n",
    "             'ETR__random_state':[0,42,88],\n",
    "             'ETR__n_jobs':[1,2,3,4,5,-1]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "ETR = ExtraTreesRegressor()\n",
    "grid_pipeline_holdout_ETR = GridSearchCV(estimator=pipe_holdout_ETR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_holdout_ETR.fit(X_holdout, y_holdout)\n",
    "grid_pipeline_holdout_ETR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b1c928-0823-443c-ac9c-51a0477a0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'ETR__n_estimators': [50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300], \n",
    "            'ETR__criterion' : ['squared_error','absolute_error'], \n",
    "            'ETR__max_depth' : [1,2,3,4],\n",
    "            'ETR__bootstrap': [True, False],\n",
    "             'ETR__random_state':[0,42,88],\n",
    "             'ETR__n_jobs':[1,2,3,4,5,-1]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "ETR = ExtraTreesRegressor()\n",
    "grid_pipeline_test_ETR = GridSearchCV(estimator=pipe_test_ETR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_test_ETR.fit(X_test, y_test)\n",
    "grid_pipeline_test_ETR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad021b-d801-4b8c-9010-d97fe03a0fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'BR__bootstrap': [True,False], \n",
    "            'BR__bootstrap_features' : [True,False], \n",
    "            'BR__warm_start' : [True,False],\n",
    "            'BR__n_jobs': [1,2,3,4,5,-1],\n",
    "             'BR__random_state':[0,42,88]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "BR = BaggingRegressor()\n",
    "grid_pipeline_train_BR = GridSearchCV(estimator=pipe_train_BR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_train_BR.fit(X_train, y_train)\n",
    "grid_pipeline_train_BR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801627cc-da5f-4fb0-9d7a-b328e854e21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'BR__bootstrap': [True,False], \n",
    "            'BR__bootstrap_features' : [True,False], \n",
    "            'BR__warm_start' : [True,False],\n",
    "            'BR__n_jobs': [1,2,3,4,5,-1],\n",
    "             'BR__random_state':[0,42,88]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "BR = BaggingRegressor()\n",
    "grid_pipeline_holdout_BR = GridSearchCV(estimator=pipe_holdout_BR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_holdout_BR.fit(X_holdout, y_holdout)\n",
    "grid_pipeline_holdout_BR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacfd765-d4f1-44cb-97d6-9f5d8dceb98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'BR__bootstrap': [True,False], \n",
    "            'BR__bootstrap_features' : [True,False], \n",
    "            'BR__warm_start' : [True,False],\n",
    "            'BR__n_jobs': [1,2,3,4,5,-1],\n",
    "             'BR__random_state':[0,42,88]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "BR = BaggingRegressor()\n",
    "grid_pipeline_test_BR = GridSearchCV(estimator=pipe_test_BR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_test_BR.fit(X_test, y_test)\n",
    "grid_pipeline_test_BR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72dc2d5-a6c8-48ce-8cc1-8ec91c7e040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'SR__cv': ['int','cross-validation generator','iterable','prefit', None], \n",
    "            'SR__bootstrap_features' : [True,False], \n",
    "            'SR__passthrough' : [True,False],\n",
    "            'SR__n_jobs': [1,2,3,4,5,-1],\n",
    "             'SR__random_state':[0,42,88]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "SR = SRegressor()\n",
    "grid_pipeline_train_SR = GridSearchCV(estimator=pipe_train_SR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_train_SR.fit(X_train, y_train)\n",
    "grid_pipeline_train_SR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d331716-7045-4eb2-b93a-8ac16f24bfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'SR__cv': ['int','cross-validation generator','iterable','prefit', None], \n",
    "            'SR__bootstrap_features' : [True,False], \n",
    "            'SR__passthrough' : [True,False],\n",
    "            'SR__n_jobs': [1,2,3,4,5,-1],\n",
    "             'SR__random_state':[0,42,88]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "SR = SRegressor()\n",
    "grid_pipeline_holdout_SR = GridSearchCV(estimator=pipe_holdout_SR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_holdout_SR.fit(X_holdout, y_holdout)\n",
    "grid_pipeline_holdout_SR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40c9823-8434-4b8d-a95d-b1251c302724",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'SR__cv': ['int','cross-validation generator','iterable','prefit', None], \n",
    "            'SR__bootstrap_features' : [True,False], \n",
    "            'SR__passthrough' : [True,False],\n",
    "            'SR__n_jobs': [1,2,3,4,5,-1],\n",
    "             'SR__random_state':[0,42,88]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "SR = SRegressor()\n",
    "grid_pipeline_test_SR = GridSearchCV(estimator=pipe_test_SR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_test_SR.fit(X_test, y_test)\n",
    "grid_pipeline_test_SR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800d0d5b-b6ee-484e-ad28-91738cb0d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'HGBR__loss': ['squared_error','absolute_error','poisson','quantile'], \n",
    "            'HGBR__warm_start' : [True,False], \n",
    "             'HGBR__random_state':[0,42,88]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "HGBR = HistGradientBoostingRegressor()\n",
    "grid_pipeline_train_HGBR = GridSearchCV(estimator=pipe_train_HGBR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_train_HGBR.fit(X_train, y_train)\n",
    "grid_pipeline_train_HGBR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dbcb5d-afc0-4617-a7e0-3f416504d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'HGBR__loss': ['squared_error','absolute_error','poisson','quantile'], \n",
    "            'HGBR__warm_start' : [True,False], \n",
    "             'HGBR__random_state':[0,42,88]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "HGBR = HistGradientBoostingRegressor()\n",
    "grid_pipeline_holdout_HGBR = GridSearchCV(estimator=pipe_holdout_HGBR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_holdout_HGBR.fit(X_holdout, y_holdout)\n",
    "grid_pipeline_holdout_HGBR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e23078d-6fc0-41ae-99a3-ac4388541920",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'HGBR__loss': ['squared_error','absolute_error','poisson','quantile'], \n",
    "            'HGBR__warm_start' : [True,False], \n",
    "             'HGBR__random_state':[0,42,88]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "HGBR = HistGradientBoostingRegressor()\n",
    "grid_pipeline_test_HGBR = GridSearchCV(estimator=pipe_test_HGBR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_test_HGBR.fit(X_test, y_test)\n",
    "grid_pipeline_test_HGBR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e719db-f972-4e6e-a79a-b1386d3ac2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'GBR__loss': ['squared_error','absolute_error','huber','quantile'], \n",
    "            'GBR__criterion' : ['friedman_mse','squared_error','mse'], \n",
    "             'GBR__random_state':[0,42,88],\n",
    "             'GBR__max_depth': [1,2,3,4],\n",
    "             'GBR__max_features':['auto','sqrt','log2',None].\n",
    "             'GBR__warm_start':[True,False]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "GBR = GradientBoostingRegressor()\n",
    "grid_pipeline_train_GBR = GridSearchCV(estimator=pipe_train_GBR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_train_GBR.fit(X_train, y_train)\n",
    "grid_pipeline_train_GBR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9026ecfb-3bc6-4b13-9c4a-db27d1c6eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'GBR__loss': ['squared_error','absolute_error','huber','quantile'], \n",
    "            'GBR__criterion' : ['friedman_mse','squared_error','mse'], \n",
    "             'GBR__random_state':[0,42,88],\n",
    "             'GBR__max_depth': [1,2,3,4],\n",
    "             'GBR__max_features':['auto','sqrt','log2',None].\n",
    "             'GBR__warm_start':[True,False]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "GBR = GradientBoostingRegressor()\n",
    "grid_pipeline_holdout_GBR = GridSearchCV(estimator=pipe_holdout_GBR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_holdout_GBR.fit(X_holdout, y_holdout)\n",
    "grid_pipeline_holdout_GBR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a7bc05-4541-4f70-bdb2-18cb6fad721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'GBR__loss': ['squared_error','absolute_error','huber','quantile'], \n",
    "            'GBR__criterion' : ['friedman_mse','squared_error','mse'], \n",
    "             'GBR__random_state':[0,42,88],\n",
    "             'GBR__max_depth': [1,2,3,4],\n",
    "             'GBR__max_features':['auto','sqrt','log2',None].\n",
    "             'GBR__warm_start':[True,False]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "GBR = GradientBoostingRegressor()\n",
    "grid_pipeline_test_GBR = GridSearchCV(estimator=pipe_test_GBR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_test_GBR.fit(X_test, y_test)\n",
    "grid_pipeline_test_GBR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c762edbc-3260-4ec4-a171-f7139204f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'VR__verbose': [True,False], \n",
    "            'VR__n_jobs' : [1,2,3,4,5,-1]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "VR = VotingRegressor()\n",
    "grid_pipeline_train_VR = GridSearchCV(estimator=pipe_train_VR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_train_VR.fit(X_train, y_train)\n",
    "grid_pipeline_train_VR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961911d-6e2e-408b-a717-468847dc20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'VR__verbose': [True,False], \n",
    "            'VR__n_jobs' : [1,2,3,4,5,-1]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "VR = VotingRegressor()\n",
    "grid_pipeline_holdout_VR = GridSearchCV(estimator=pipe_holdout_VR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_holdout_VR.fit(X_holdout, y_holdout)\n",
    "grid_pipeline_holdout_VR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5153b0b-f665-429b-81eb-57122ebb25b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'VR__verbose': [True,False], \n",
    "            'VR__n_jobs' : [1,2,3,4,5,-1]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "VR = VotingRegressor()\n",
    "grid_pipeline_test_VR = GridSearchCV(estimator=pipe_test_VR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_test_VR.fit(X_test, y_test)\n",
    "grid_pipeline_test_VR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb77ddf-63c2-498b-b182-779ac1ec1f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'ABR__n_estimators': [25,50,75,100,125,150,175,200,225,250,275,300], \n",
    "            'ABR__loss' : ['linear','square','exponential'], \n",
    "             'ABR__random_state':[0,42,88]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "ABR = AdaBoostRegressor()\n",
    "grid_pipeline_train_ABR = GridSearchCV(estimator=pipe_train_ABR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_train_ABR.fit(X_train, y_train)\n",
    "grid_pipeline_train_ABR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d212fb-65e1-4724-98e6-eeeae99b6547",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'ABR__n_estimators': [25,50,75,100,125,150,175,200,225,250,275,300], \n",
    "            'ABR__loss' : ['linear','square','exponential'], \n",
    "             'ABR__random_state':[0,42,88]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "ABR = AdaBoostRegressor()\n",
    "grid_pipeline_holdout_ABR = GridSearchCV(estimator=pipe_holdout_ABR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_holdout_ABR.fit(X_holdout, y_holdout)\n",
    "grid_pipeline_holdout_ABR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e0a41a-7b7c-468f-aa30-89ef79914bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# identify parameters\n",
    "param_grid = {'ABR__n_estimators': [25,50,75,100,125,150,175,200,225,250,275,300], \n",
    "            'ABR__loss' : ['linear','square','exponential'], \n",
    "             'ABR__random_state':[0,42,88]} \n",
    "\n",
    "# perform grid search\n",
    "# specify model\n",
    "ABR = AdaBoostRegressor()\n",
    "grid_pipeline_test_ABR = GridSearchCV(estimator=pipe_test_ABR, param_grid=param_grid, cv=folds,n_jobs=-1, verbose=2)\n",
    "grid_pipeline_test_ABR.fit(X_test, y_test)\n",
    "grid_pipeline_test_ABR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d61db4-0e2c-4940-9137-521188117333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running GridSearchCV, the best_params_ parameter was called to identify the recommended parameter setup\n",
    "\n",
    "#best_grid2 = grid_searcher2.best_params_\n",
    "#best_grid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784f47b5-481a-4ced-a1f7-35782c1b0aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can build a little pipeline and use this column as a predictor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        # this will initialize our dataframe with training data\n",
    "        (\"SequenceSexRatio\", SequenceSexRatio(train)),\n",
    "        # this will cut out all parameters except a few\n",
    "        (\"reduce_columns\", \n",
    "         ColumnTransformer(transformers=[\n",
    "            (\"sex\", OneHotEncoder(categories=[['Male','Female']], handle_unknown='ignore'), ['sex']),\n",
    "            ('cols_to_keep', 'passthrough', ['age','SequenceSexRatio']),\n",
    "        ], remainder='drop')),\n",
    "        # we'll just use this questionable method for dealing with missing values across all columns\n",
    "        ('fill missing', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "        # this is our final estimator\n",
    "        (\"regressor\", RandomForestRegressor(n_estimators=100, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None))\n",
    "    ])\n",
    "\n",
    "# now let's visually inspect our pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "display(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9ccfd7-3799-4563-b9b0-aa08da733c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have a pipeline that will first add in our new column of data then\n",
    "# pass this on to the rest of the pipeline. Importantly, the new data is\n",
    "# added when we create the object, through the constructor, and is merged\n",
    "# with the data we are fitting to or predicting on when the transform()\n",
    "# function is called. Since the object is *not* created when we predict, and\n",
    "# instead is loaded through the pickle process, it means we can embed historical\n",
    "# data in the pipeline for use in the future.\n",
    "\n",
    "# We now have to fit out pipeline, this will just call the transform() and fit()\n",
    "# functions of the objects in the pipeline, but will not create new objects.\n",
    "fitted_pipe=pipe.fit(train, train['x_result.duration.chip'])\n",
    "\n",
    "# And we can take that final regression object and observe the coefficients\n",
    "# to verify that we have four, two for sex, one for sexsequenceratio, and\n",
    "# one age\n",
    "fitted_pipe.steps[-1][1].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a6b58-1e61-464d-9542-54e191b2f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we can now try this on unseen data\n",
    "fitted_pipe.score(test, test['x_result.duration.chip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91db40c-1428-4d8d-96d9-cab291f14e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cbeea8-2fb5-4385-8ae2-b746f6cfd281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5607a5e5-7110-482b-a055-79e940129f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c81026-fa07-4a0a-b81d-79d69fad2ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209872ff-c7d5-4084-90c6-01d7ad6ff46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b089a93-1eae-4519-8f0e-9c2be3805b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42dd9b3-44f8-4eda-bb30-3fc1a0606703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Think about the predictive modelling workflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Now that we have out outcome to predict, we want to think about what variables might\n",
    "# be useful in predicting this. For running it's well known that sex and age have impacts\n",
    "# at a population level, so we can start with those. But while age is numeric, sex is not.\n",
    "# If you look at the data, you'll see that sex actually has a host of different values,\n",
    "# and you can think about how to clean those. But for linear regression we need to make\n",
    "# this numeric. While there are various ways to do this, one hot encoding is a pretty\n",
    "# common one. So the strategy for this first model is to one hot encode sex with a binary\n",
    "# split of Male/Female, and to just use age as is, and train a linear regression model\n",
    "# with default parameters and then convert that timing into a ranking down the road.\n",
    "\n",
    "# There are several ways to do this. The autograder is expecting that you will have\n",
    "# saved a python object and that it has a predict(X) function where X is a pandas\n",
    "# DataFrame object that has all of the columns in the holdout data but only for one\n",
    "# combination of event.id and clean_categories.name. There are two high level strategies\n",
    "# here:\n",
    "#  1. Roll your own object, where you create your own object that has the predict()\n",
    "#     function and just does all the work in there however you want it to.\n",
    "#  2. Use sklearn.pipeline.Pipeline objects, where you leverage some of the resuable\n",
    "#     sklearn pipeline objects which were build for this purpose.\n",
    "\n",
    "# Importantly, there are non-exclusive options, and you can blend however you see fit.\n",
    "# I'll show examples of both, first being the roll your own\n",
    "\n",
    "def roll_own()->object:\n",
    "    \"\"\"This function returns a fitted object with a predict(x) function\"\"\"\n",
    "    \n",
    "    # First I'm going to create a new class with a predict function, and that class\n",
    "    # is just going to call the regression object it is setup with and then rerank\n",
    "    # all of the values which come back\n",
    "    class RollingRegressor():\n",
    "        \n",
    "        # For this class I'm going to assume it has been given a fitted model, so\n",
    "        # I'm choosing not to implement the fit() function.\n",
    "        def __init__(self, fitted_model):\n",
    "            self.regressor=fitted_model\n",
    "        \n",
    "        # For the prediction we are just given our dataframe, so we have to do our\n",
    "        # data cleaning here.\n",
    "        def predict(self, X):\n",
    "            # We need to be careful and *not* drop rows. The autograder is expecting\n",
    "            # a rank back for every row in X! Lets just grab out the two columns of\n",
    "            # interest\n",
    "            df=X[[\"age\",\"sex\"]]\n",
    "            \n",
    "            # For brevity let's get rid of any sex that isn't Male/Female and replace with nan\n",
    "            # A better approach would be to inspect and map this data accordingly, but I'll leave\n",
    "            # that as an enhancement.\n",
    "            df.loc[df.query(\"`sex` not in ['Male','Female']\").index, 'sex']=np.nan\n",
    "            \n",
    "            # Now that this is binary we can convert this column into a numeric value\n",
    "            df.loc[df.query(\"`sex` == 'Male'\").index, 'sex']=1\n",
    "            df.loc[df.query(\"`sex` == 'Female'\").index, 'sex']=0\n",
    "            \n",
    "            # Now just do whatever you want with missing values, this below doesn't seem ideal\n",
    "            df=df.fillna(-1)\n",
    "            \n",
    "            # With the data cleaning done, we can now predict the times for our data\n",
    "            times=self.regressor.predict(df)\n",
    "            \n",
    "            # We can't return the times directly - the autograder wants ranks. We can\n",
    "            # use a similar method those to return ranks\n",
    "            return times.squeeze().argsort()+1\n",
    "    \n",
    "    # Our return class is done, now we just need to initalize it with a fitted\n",
    "    # model. To fit the model we just do all of the cleaning over, and add in some training.\n",
    "    # It would be a better ideal to put this all in the class itself, but I want to\n",
    "    # show you that this isn't needed -- the autograder is NOT going to try and fit()\n",
    "    # your model, it is only going to call predict(), so you can do whatever you want\n",
    "    # within that predict()\n",
    "    \n",
    "    df=train[[\"age\",\"sex\"]]\n",
    "    df.loc[df.query(\"`sex` not in ['Male','Female']\").index, 'sex']=np.nan\n",
    "    df.loc[df.query(\"`sex` == 'Male'\").index, 'sex']=1\n",
    "    df.loc[df.query(\"`sex` == 'Female'\").index, 'sex']=0\n",
    "    df=df.fillna(-1)\n",
    "    \n",
    "    # Since we have decided it's a regression problem, we can decide to use a simple linear\n",
    "    # model for our first attempt too, so I'll create that now\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    reg1=RandomForestRegressor()\n",
    "    reg=LinearRegression()\n",
    "    reg1.fit(df,y)\n",
    "    \n",
    "    # Now we just return the object that the autograder will want\n",
    "    return RollingRegressor(reg1)\n",
    "    \n",
    "# We can test this out by instantiating it\n",
    "fitted_reg=roll_own()\n",
    "# Then saving it to a file\n",
    "cloudpickle.dump(fitted_reg, open('pipeline.cloudpickle','wb'))\n",
    "# Then telling the autograder function to fire\n",
    "autograde(holdout)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e8aa29-d291-41af-b953-6b98f24e7328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Use the autograder!\n",
    "\n",
    "# I gave you the autograder code, so a next great step is just to copy and paste\n",
    "# that in your notebook and get used to how it works.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "\n",
    "# This code simulates the autograder. It is not the full autograder implementation\n",
    "# but shares an API with the autograder. It expects that your fitted pipeline is\n",
    "# submitted with the name pipeline.cloudpickle as demonstrated above. This object\n",
    "# must implement the predict() function. This is done automatically by the sklearn\n",
    "# Pipeline object if the last element of your pipeline is a classifier which has\n",
    "# a predict() function. If you are not submitting a Pipeline, and want to do something\n",
    "# different, you *must* have a predict() function of the same method signature, e.g.:\n",
    "#\n",
    "#   predict(self, X, **predict_params)->np.ndarray\n",
    "\n",
    "# Load holdout data, in this case I'll simulate it by loading the training data\n",
    "#df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "\n",
    "# And evaluate on all 5k races that we didn't consider for training\n",
    "#holdout_data=df.query(\"`event.id`!='583f013a-1e54-4906-87f7-2b625206f5f9' and `clean_categories.name`=='5k'\")\n",
    "holdout_data=holdout\n",
    "\n",
    "# This is the scoring function to determine model fitness\n",
    "\n",
    "def score(left: pd.DataFrame, right: pd.DataFrame):\n",
    "    '''\n",
    "    Calculates the difference between the left and the right when considering rank of items. \n",
    "    This scoring function requires that the two DataFrames have identical indicies, and that\n",
    "    they each contain only one column of values and no missing values.\n",
    "    '''\n",
    "    assert(type(left)==pd.DataFrame)\n",
    "    assert(type(right)==pd.DataFrame)\n",
    "    assert(len(left)==len(right))\n",
    "    assert(not np.any(np.isnan(left)))\n",
    "    assert(not np.any(np.isnan(right)))\n",
    "    assert(left.index.equals(right.index))\n",
    "    # convert to ndarrays\n",
    "    left=left.squeeze()\n",
    "    right=right.squeeze()\n",
    "    return np.sum(np.abs(left-right))/(len(left)*(len(left)-1))\n",
    "\n",
    "# This function runs the prediction model agains a given event/category pair. It\n",
    "# intentionally loads the student model each time to avoid accidental leakage of data\n",
    "# between events.\n",
    "def evaluate(data, pipeline_file='pipeline.cloudpickle'):\n",
    "    # Load student pipeline\n",
    "    fitted_pipe = cloudpickle.load(open(pipeline_file,'rb'))\n",
    "    \n",
    "    # Separate out the X and y\n",
    "    X=list(set(data.columns)-{'overall_ranking'})\n",
    "    y=['overall_ranking']\n",
    "    \n",
    "    # Drop any missing results (DNFs)\n",
    "    data=data.dropna(subset=['overall_ranking'])\n",
    "    \n",
    "    # Ensure there is data to actually predict on\n",
    "    if len(data)==0:\n",
    "        return np.nan\n",
    "    # Predict on unseen data\n",
    "    from IPython.utils import io\n",
    "    with io.capture_output() as captured:\n",
    "        predictions=pd.DataFrame(fitted_pipe.predict(data[X]),data.index)\n",
    "    observed=data[y]\n",
    "    \n",
    "    # Generate rankings within this bracket\n",
    "    observed=pd.DataFrame(data[y].rank(),data.index)\n",
    "\n",
    "    # Return the ratio of the student score\n",
    "    return pd.Series({\"score\":score(observed,predictions)})\n",
    "\n",
    "# Student solution\n",
    "pipeline_file='pipeline.cloudpickle'\n",
    "    \n",
    "def autograde(data_held_out):\n",
    "    # Run prediction on each group\n",
    "    results=data_held_out.groupby([\"event.id\",\"clean_categories.name\"]).apply(evaluate, pipeline_file)\n",
    "\n",
    "    # Display the results, uncomment this for your own display\n",
    "    results.reset_index()['score'].plot.bar();\n",
    "\n",
    "    # This is the student final grade\n",
    "    print(np.average(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb14733-cb21-49f0-a0fe-8a066d1db90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "\n",
    "# We are going to regress on time\n",
    "df['x_result.duration.chip']=pd.to_timedelta(df['result.duration.chip']).astype(int)\n",
    "\n",
    "# For this demo we are going to use the sequence identifiers, let's look at a\n",
    "# couple I hand picked\n",
    "data=df.query('lineage.event_series.name in [\"5e862221-758c-48b1-a7cf-11bcc0a80a41\",\"57bdcd1f-a474-43e0-8e54-5f3a5206f5f9\"]')\n",
    "data.groupby(['lineage.event_series.name','event.id']).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5cf02c-6941-4f93-acf0-c4b0e98e442e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7817f8-a2dd-40e0-9f73-3786d0bded31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ff8e5-79ff-4181-b7a2-769959664d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df['sex'] == 'F', 'sex'] = 'Female'\n",
    "df.loc[ df['sex'] == 'M', 'sex'] = 'Male'\n",
    "df.loc[df.query(\"`sex` not in ['Male','Female']\").index, 'sex']=np.nan\n",
    "            \n",
    "df.loc[df.query(\"`sex` == 'Male'\").index, 'sex']=2\n",
    "df.loc[df.query(\"`sex` == 'Female'\").index, 'sex']=1\n",
    "            \n",
    "# Now just do whatever you want with missing values, this below doesn't seem ideal\n",
    "df=df.fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f3f9b-855a-4def-963e-a1670f9cbe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b1166-4b3b-4dfb-80e6-f3bd2dadc3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.filter(items=['lineage.event_series.id','result.duration','location.state','age','sex','coupon','coupon_type','result.duration.chip','result.duration.pace','overall_ranking','location.city'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6393afd-c669-45a8-bfab-079b6b9a348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9f20b3-a76d-4a02-afd6-a43acca5ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['location.state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed67277f-8e40-42fc-854e-9b7b6eddc5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['location.city'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b93c79-e203-4f90-b3dd-e01b9f417285",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['coupon'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d345ceee-bb1d-435b-b8fb-83f4b153e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['coupon_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aac431-7712-4469-b511-0a03725f6cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['hometown'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764bfbd6-7f28-43e1-8a7f-89f60bef84e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54b3e9-46e7-4447-876c-e60fa9ac2a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "X=df\n",
    "# This is a custom transformer to demonstrate how you might modify the data for feature\n",
    "# selection or engineering before applying a given model. In this example I am only\n",
    "# doing feature selection, and passing to the next element in the pipeline the age\n",
    "# and bib number for the runner. Thus only two features will be used in my predictive model.\n",
    "# There are other ways to do this\n",
    "class CustomTransformer(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        # Just select the features we want\n",
    "        Xprime=X[['age','sex','hometown','location.name']]\n",
    "        # Ensure that they have numbers in them of the regression will fail\n",
    "        Xprime=Xprime.fillna(value=-1)\n",
    "        return Xprime\n",
    "\n",
    "# I build a very basic pipeline which is made up of three stages. In the first, my\n",
    "# custom transform is called and reduces the DataFrame to just two columns. In the\n",
    "# second I use a built-in transformer from sklearn to bucket users based on their\n",
    "# bib number, perhaps as a proxy for \"how early did they sign up\". In the final step\n",
    "# I want to use a LinearRegression() regressor.\n",
    "\n",
    "# There are two main concerns I need to address. First, I need to be resilient to bad\n",
    "# data which might address. So I know the LinearRegression() object can't handle\n",
    "# missing data, so I need to deal with that. This was done in the CustomeTransformer()\n",
    "# already.\n",
    "\n",
    "# Second, I actually need to be ranking results, not regressing. Depending upon your\n",
    "# model you need to consider this carefully. Here is a fine catch all if you\n",
    "# are using regression, and object which just ranks the results in order. This is\n",
    "# called monkey patching and replaces the LinearRegression() object's predict()\n",
    "# function with a wrapper\n",
    "\n",
    "#reg=LinearRegression()\n",
    "reg=RandomForestRegressor()\n",
    "reg.original_predict=reg.predict\n",
    "\n",
    "def new_predict(X):\n",
    "    # run the old regression method\n",
    "    rankings=reg.original_predict(X)\n",
    "    # now calculate and return the ranks of each item instead\n",
    "    # we need to add a +1 because the lowest rank is a 1, not a 0\n",
    "    # it's unfortunate, the first athletic competition was probably run by R users...\n",
    "    return rankings.squeeze().argsort()+1\n",
    "\n",
    "# Now we overwrite (monkey patch) the predict() function with our own implementation\n",
    "reg.predict=new_predict\n",
    "\n",
    "# And build our pipeline object\n",
    "pipe = make_pipeline( CustomTransformer(), QuantileTransformer(), reg )\n",
    "\n",
    "# This is just one way to do this, you could also implement a new estimator with the\n",
    "# predict interface and build all of your logic in there. The benefit of the\n",
    "# pipeline is that you can rapidly change the logic and try different pipelines using\n",
    "# common methods from sklearn. When the pipeline gets complicated, you can also\n",
    "# visualize it...\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "display(pipe)\n",
    "\n",
    "# Once the pipeline is built, we need to train it. I'm going to just do a pretty poor\n",
    "# job here, getting the training set provided\n",
    "df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "\n",
    "# I'm just going to build a model off of one event/category combination (lame)\n",
    "training_data=df.query(\"`event.id`=='583f013a-1e54-4906-87f7-2b625206f5f9' and `clean_categories.name`=='5k'\")\n",
    "\n",
    "# And I'm going to pass in all of my potential columns for consideration. Note: The\n",
    "# example pipeline I built is going to reduce this to just the two columns I'm interested\n",
    "# in, so this is a safe thing to do. But be aware, the holdout set does not have all of\n",
    "# the data the training set might, because of leakage, so you need to think about this\n",
    "# and not make assumptions. You can see how I built the holdout set at the bottom of\n",
    "# this notebook\n",
    "X=set(training_data.columns)-{'overall_ranking'}\n",
    "\n",
    "# The ranking is what we aim to predict\n",
    "y={'overall_ranking'}\n",
    "\n",
    "# Now I fit() the pipeline. You'll note that the outcomes I need to squeeze() to ensure\n",
    "# it's a one dimensional structure and not a DataFrame\n",
    "fitted_pipe=pipe.fit(training_data[X],training_data[y].squeeze().to_numpy())\n",
    "\n",
    "# And now, assuming that I am happy with this model and think it is great, I write the\n",
    "# fitted pipeline to a file. This file will be read in by the autograder.\n",
    "cloudpickle.dump(fitted_pipe, open('pipeline.cloudpickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfba52a-1984-420a-86e0-d521cea8c0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bbfd25-b800-4d5a-a599-326baa0848fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f1f29-18db-4d32-99ce-09cacb4f2e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "\n",
    "# This code simulates the autograder. It is not the full autograder implementation\n",
    "# but shares an API with the autograder. It expects that your fitted pipeline is\n",
    "# submitted with the name pipeline.cloudpickle as demonstrated above. This object\n",
    "# must implement the predict() function. This is done automatically by the sklearn\n",
    "# Pipeline object if the last element of your pipeline is a classifier which has\n",
    "# a predict() function. If you are not submitting a Pipeline, and want to do something\n",
    "# different, you *must* have a predict() function of the same method signature, e.g.:\n",
    "#\n",
    "#   predict(self, X, **predict_params)->np.ndarray\n",
    "\n",
    "# Load holdout data, in this case I'll simulate it by loading the training data\n",
    "#df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "\n",
    "# And evaluate on all 5k races that we didn't consider for training\n",
    "#holdout_data=df.query(\"`event.id`!='583f013a-1e54-4906-87f7-2b625206f5f9' and `clean_categories.name`=='5k'\")\n",
    "\n",
    "\n",
    "# This is the scoring function to determine model fitness\n",
    "def score(left: pd.DataFrame, right: pd.DataFrame):\n",
    "    '''\n",
    "    Calculates the difference between the left and the right when considering rank of items. \n",
    "    This scoring function requires that the two DataFrames have identical indicies, and that\n",
    "    they each contain only one column of values and no missing values. Props to Blake Atkinson\n",
    "    for providing MWE indicating issues with autograder version #1.\n",
    "    '''\n",
    "    assert(type(left)==pd.DataFrame)\n",
    "    assert(type(right)==pd.DataFrame)\n",
    "    assert(len(left)==len(right))\n",
    "    assert(not np.any(np.isnan(left)))\n",
    "    assert(not np.any(np.isnan(right)))\n",
    "    assert(left.index.equals(right.index))\n",
    "    # convert to ndarrays\n",
    "    left=left.squeeze()\n",
    "    right=right.squeeze()\n",
    "    return np.sum(np.abs(left-right))/(len(left)*(len(left)-1))\n",
    "\n",
    "# This function runs the prediction model agains a given event/category pair. It\n",
    "# intentionally loads the student model each time to avoid accidental leakage of data\n",
    "# between events.\n",
    "def evaluate(data, pipeline_file='pipeline.cloudpickle'):\n",
    "    # Load student pipeline\n",
    "    fitted_pipe = cloudpickle.load(open(pipeline_file,'rb'))\n",
    "    \n",
    "    # Separate out the X and y\n",
    "    X=list(set(data.columns)-{'overall_ranking'})\n",
    "    y=['overall_ranking']\n",
    "    \n",
    "    # Drop any missing results (DNFs)\n",
    "    data=data.dropna(subset=['overall_ranking'])\n",
    "    \n",
    "    # Ensure there is data to actually predict on\n",
    "    if len(data)==0:\n",
    "        return np.nan\n",
    "\n",
    "    # Predict on unseen data\n",
    "    from IPython.utils import io\n",
    "    with io.capture_output() as captured:\n",
    "        predictions=pd.DataFrame(fitted_pipe.predict(data[X]),data.index)\n",
    "    observed=data[y]\n",
    "    \n",
    "    # Generate rankings within this bracket\n",
    "    observed=pd.DataFrame(data[y].rank(),data.index)\n",
    "    \n",
    "    # Return the ratio of the student score\n",
    "    return pd.Series({\"score\":score(observed,predictions)})\n",
    "\n",
    "# Student solution\n",
    "pipeline_file='pipeline.cloudpickle'\n",
    "\n",
    "# Run prediction on each group\n",
    "results=holdout.groupby([\"event.id\",\"clean_categories.name\"]).apply(evaluate, pipeline_file)\n",
    "\n",
    "# Display the results, uncomment this for your own display\n",
    "results.reset_index()['score'].plot.bar();\n",
    "\n",
    "# This is the student final grade\n",
    "np.average(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c45a14-e495-4d67-83d8-582eaf196ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7361a0b-7ae0-443f-8fb2-0e600c721384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e67e3-3b18-42ea-94c7-999ba1a5ba91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef055d6-2e84-485f-8e05-7b401ff60c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de2e62-dda1-47b9-a0af-383b00ef8ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
