{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543f0792-5e97-4327-9b7f-df20e117aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "preprocessor = StandardScaler()\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, cross_val_score, KFold\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "#df = df['overall_ranking'].dropna()\n",
    "events=df['event.id'].unique()\n",
    "\n",
    "df.loc[df.query(\"`sex` not in ['Male','Female']\").index, 'sex']=0\n",
    "\n",
    "df.loc[df.query(\"`sex` == 'Male'\").index, 'sex']=2\n",
    "df.loc[df.query(\"`sex` == 'Female'\").index, 'sex']=1\n",
    "\n",
    "   \n",
    "df['clean_categories_run_count']=df['clean_categories.name'].replace({'15k':15, '5k':5, 'marathon':42.195, 'half marathon':21.0975, '10k':10, '5 mile':8.04672,\n",
    "'8k':8,'5k run':5, '3k walk':0, '10k run':10, 'youth mile':1.60934, '5k run/walk':5,\n",
    "       '5k walk':0, '5 mile run':8.04672, '1 mile run':1.60934, '15k run':15, '10k walk':0,\n",
    "       '6k run':6, '6k walk':0, '1 mile walk':0, '8k run':8, '8k walk':0,\n",
    "       '10 mile run':16.0934, '10 mile walk':0, '5 mile walk':0, '30k run':30,\n",
    "       '30k bike':0, '8 mile run':12.8748, '8 mile walk':0, 'bridge run':10,\n",
    "       'international half marathon':21.0975, 'u.s. only half marathon':21.0975, '1 mile':1.60934,\n",
    "       '5.7 mile run':9.17326, '5.7 mile walk':0, '5k competitive walk':0,\n",
    "       'half marathon run':21.0975, '5k fun walk':0, '5k wheelchair':0,\n",
    "       '1 mile fun run':1.60934, '2 mile run':3.21869, '2 mile walk':0, '4 mile run/walk':6.43738,\n",
    "       'life time commitment day 5k':5, 'midnight streak':5,\n",
    "       'commitment day 5k - master':5, 'quarter marathon':10.54875, '5k walk/run':5,\n",
    "       '1 mile fun run/walk':1.60934, 'one mile fun run':1.60934, '5 km run':5,\n",
    "       'fire fighter':42.195, 'olympic triathlon':10, 'sprint triathlon':10,\n",
    "       'olympic duathlon':10, 'sprint duathlon':10, '10k scenic challenge':10,\n",
    "       'run swim run':50, 'half marathon walk':0, 'mini-marathon':21.0975})\n",
    "\n",
    "df['clean_categories_walk_count']=df['clean_categories.name'].replace({'15k':0, '5k':0, 'marathon':0, 'half marathon':0, '10k':0, '5 mile':0,\n",
    "'8k':0,'5k run':0, '3k walk':3, '10k run':0, 'youth mile':0, '5k run/walk':0,\n",
    "       '5k walk':5, '5 mile run':0, '1 mile run':0, '15k run':0, '10k walk':10,\n",
    "       '6k run':0, '6k walk':6, '1 mile walk':1.60934, '8k run':0, '8k walk':8,\n",
    "       '10 mile run':0, '10 mile walk':16.0934, '5 mile walk':8.04672, '30k run':0,\n",
    "       '30k bike':0, '8 mile run':0, '8 mile walk':12.9748, 'bridge run':0,\n",
    "       'international half marathon':0, 'u.s. only half marathon':0, '1 mile':0,\n",
    "       '5.7 mile run':0, '5.7 mile walk':9.17326, '5k competitive walk':5,\n",
    "       'half marathon run':0, '5k fun walk':5, '5k wheelchair':0,\n",
    "       '1 mile fun run':0, '2 mile run':0, '2 mile walk':3.21869, '4 mile run/walk':0,\n",
    "       'life time commitment day 5k':0, 'midnight streak':0,\n",
    "       'commitment day 5k - master':0, 'quarter marathon':0, '5k walk/run':0,\n",
    "       '1 mile fun run/walk':0, 'one mile fun run':0, '5 km run':0,\n",
    "       'fire fighter':0, 'olympic triathlon':0, 'sprint triathlon':0,\n",
    "       'olympic duathlon':0, 'sprint duathlon':0, '10k scenic challenge':0,\n",
    "       'run swim run':0, 'half marathon walk':21.0975, 'mini-marathon':0})\n",
    "\n",
    "#walk_count = df['clean_categories_walk_count'].unique()\n",
    "#run_count = df['clean_categories_run_count'].unique()\n",
    "\n",
    "df.loc[df.query(\"`age` >= 119\").index, 'age']=np.nan\n",
    "df.loc[df.query(\"`age` <= 18\").index, 'age']=np.nan\n",
    "df.loc[df['age'] == 'nan', 'age'] = 38\n",
    "df['age']=df['age'].replace(np.nan,38)\n",
    "\n",
    "df['date'] = pd.to_datetime(df['event.date.start'])\n",
    "df['year'], df['month'] = df['date'].dt.year, df['date'].dt.month\n",
    "\n",
    "df['result.primary_bracket']=df['result.primary_bracket'].replace(['WHEELCHAIR','nan','Male 25-29','Male 40-44','Female 25-29','Female 20-24','wheelchair'],['Wheelchair','Overall','Male','Male','Female','Female','Wheelchair']) \n",
    "#df['result.primary_bracket1']=df['result.primary_bracket'].replace(['Wheelchair', 'Overall', 'nan', 'Male', 'Female'],[1,2,3,4,5])\n",
    "#df = df.dropna(subset = ['result.duration.chip'])\n",
    "\n",
    "#groups=pd.DataFrame(df.groupby([\"event.id\",\"clean_categories.name\"]).groups.keys(), columns=[\"event.id\",\"clean_categories.name\"])\n",
    "\n",
    "#train_set=events[100:]\n",
    "#holdout_set=events[0:100]\n",
    "\n",
    "#train_set=events[100:]\n",
    "#holdout_set=events[0:100]\n",
    "\n",
    "train_set = df[(df['year']==2018) | (df['year']==2017)] \n",
    "holdout_set = df[(df[\"year\"]==2016) | (df[\"year\"]==2015) | (df[\"year\"]==2014) | (df[\"year\"]==2013) | (df[\"year\"]==2012)]\n",
    "\n",
    "#test_set=events[200:300]\n",
    "\n",
    "#train=df.query(\"`event.id` in @train_set\")\n",
    "#test=df.query(\"`event.id` in @test_set\")\n",
    "#holdout=df.query(\"`event.id` in @holdout_set\")\n",
    "\n",
    "holdout_set=holdout_set.drop(\n",
    "    columns=['time.end',\n",
    "             'body.results_certificate',\n",
    "             'event.results_posted',\n",
    "            'event.results_posted',\n",
    "             'event.results_certificate',\n",
    "             'event.photos_available',\n",
    "             'event.photos_faces',\n",
    "             'event.photos_social_sharing',\n",
    "             'event.results_searchable',\n",
    "             'corral.id',\n",
    "             'corral.name',\n",
    "             'corral.wave',\n",
    "             'corral.time.close',\n",
    "             'corral.time.start',\n",
    "             'result.duration.chip',\n",
    "             'result.duration.pace',\n",
    "             'result.rankings',\n",
    "             'result.splits',\n",
    "             'result.videos',\n",
    "             'result.finished',\n",
    "             'result.disqualified',\n",
    "             'result.duration'])\n",
    "\n",
    "holdout=df.groupby([\"event.id\",\"clean_categories.name\"]).filter(lambda z: len(z)>5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a816dd3-0b4a-43c6-adcc-03425caa03f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.to_timedelta(train_set['result.duration.chip']).astype(int)\n",
    "#y=train['overall_ranking']\n",
    "holdout_data=holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a3a9d-c40f-437e-a3ce-66964e449f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Use the autograder!\n",
    "\n",
    "# I gave you the autograder code, so a next great step is just to copy and paste\n",
    "# that in your notebook and get used to how it works.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "\n",
    "# This code simulates the autograder. It is not the full autograder implementation\n",
    "# but shares an API with the autograder. It expects that your fitted pipeline is\n",
    "# submitted with the name pipeline.cloudpickle as demonstrated above. This object\n",
    "# must implement the predict() function. This is done automatically by the sklearn\n",
    "# Pipeline object if the last element of your pipeline is a classifier which has\n",
    "# a predict() function. If you are not submitting a Pipeline, and want to do something\n",
    "# different, you *must* have a predict() function of the same method signature, e.g.:\n",
    "#\n",
    "#   predict(self, X, **predict_params)->np.ndarray\n",
    "\n",
    "# Load holdout data, in this case I'll simulate it by loading the training data\n",
    "#df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "\n",
    "# And evaluate on all 5k races that we didn't consider for training\n",
    "#holdout_data=df.query(\"`event.id`!='583f013a-1e54-4906-87f7-2b625206f5f9' and `clean_categories.name`=='5k'\")\n",
    "#holdout_data=holdout\n",
    "\n",
    "# This is the scoring function to determine model fitness\n",
    "def score(left: pd.DataFrame, right: pd.DataFrame):\n",
    "    '''\n",
    "    Calculates the difference between the left and the right when considering rank of items. \n",
    "    This scoring function requires that the two DataFrames have identical indicies, and that\n",
    "    they each contain only one column of values and no missing values.\n",
    "    '''\n",
    "    assert(type(left)==pd.DataFrame)\n",
    "    assert(type(right)==pd.DataFrame)\n",
    "    assert(len(left)==len(right))\n",
    "    assert(not np.any(np.isnan(left)))\n",
    "    assert(not np.any(np.isnan(right)))\n",
    "    assert(left.index.equals(right.index))\n",
    "    # convert to ndarrays\n",
    "    left=left.squeeze()\n",
    "    right=right.squeeze()\n",
    "    return np.sum(np.abs(left-right))/(len(left)*(len(left)-1))\n",
    "\n",
    "# This function runs the prediction model agains a given event/category pair. It\n",
    "# intentionally loads the student model each time to avoid accidental leakage of data\n",
    "# between events.\n",
    "def evaluate(data, pipeline_file='pipeline.cloudpickle'):\n",
    "    # Load student pipeline\n",
    "    fitted_pipe = cloudpickle.load(open(pipeline_file,'rb'))\n",
    "    \n",
    "    # Separate out the X and y\n",
    "    X=list(set(data.columns)-{'overall_ranking'})\n",
    "    y=['overall_ranking']\n",
    "    \n",
    "    # Drop any missing results (DNFs)\n",
    "    data=data.dropna(subset=['overall_ranking'])\n",
    "    \n",
    "    # Ensure there is data to actually predict on\n",
    "    if len(data)==0:\n",
    "        return np.nan\n",
    "    \n",
    "    # Predict on unseen data\n",
    "    from IPython.utils import io\n",
    "    with io.capture_output() as captured:\n",
    "        predictions=pd.DataFrame(fitted_pipe.predict(data[X]),data.index)\n",
    "    observed=data[y]\n",
    "    \n",
    "    # Generate rankings within this bracket\n",
    "    observed=pd.DataFrame(data[y].rank(),data.index)\n",
    "\n",
    "    # Return the ratio of the student score\n",
    "    return pd.Series({\"score\":score(observed,predictions)})\n",
    "\n",
    "# Student solution\n",
    "pipeline_file='pipeline.cloudpickle'\n",
    "\n",
    "def autograde(holdout_data):\n",
    "    # Run prediction on each group\n",
    "    results=holdout_data.groupby([\"event.id\",\"clean_categories.name\"]).apply(evaluate, pipeline_file)\n",
    "\n",
    "    # Display the results, uncomment this for your own display\n",
    "    results.reset_index()['score'].plot.bar();\n",
    "\n",
    "    # This is the student final grade\n",
    "    print(np.average(results))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2b6c31-f2d6-4c33-95bd-a6341257f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That assignment should pass the autograder. A more pythonic way to do this, and certainly\n",
    "# the goal of the sklearn team, is to use pipelines, and reuse transformer objects to do the\n",
    "# data cleaning. In sklearn pipelines are made up of a sequence of Transformers with the last\n",
    "# item in the pipeline being an Estimator. You can have Estimators throughout the pipeline\n",
    "# too, creating new features through modeling. For instance, you could use PCA to reduce the\n",
    "# dimensionality of features and then learn on principal components instead.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# We can write a similar model to the above using pipelines and transformers. A good example\n",
    "# would be to first create a transformer for the columns of sex and age, and get rid of\n",
    "# everything else while one hot encoding sex\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "cleaner = ColumnTransformer(\n",
    "    transformers=[\n",
    "        #(\"sex\", OneHotEncoder(sparse=False,categories=[['Male','Female']], handle_unknown='ignore'), ['sex']),\n",
    "        ('sex', 'passthrough', ['sex']),\n",
    "        ('age', 'passthrough', ['age']),\n",
    "        ('clean_categories_run_count', 'passthrough', ['clean_categories_run_count']),\n",
    "        ('clean_categories_walk_count', 'passthrough', ['clean_categories_walk_count']),\n",
    "        ('event.date.start', OneHotEncoder(sparse=False,categories=[['2017-12-03', '2018-12-02', '2018-01-07', '2018-03-18',\n",
    "       '2018-05-06', '2017-10-01', '2018-10-07', '2017-12-17',\n",
    "       '2018-12-16', '2018-02-04', '2017-06-04', '2017-09-09',\n",
    "       '2017-10-29', '2018-04-29', '2018-05-05', '2018-06-03',\n",
    "       '2018-06-07', '2018-06-21', '2018-06-23', '2018-09-08',\n",
    "       '2018-09-30', '2018-10-14', '2018-10-20', '2018-10-21',\n",
    "       '2018-11-04', '2018-11-22', '2018-12-31', '2018-03-24',\n",
    "       '2018-05-12', '2018-05-31', '2018-06-02', '2018-06-16',\n",
    "       '2018-06-17', '2018-06-30', '2018-07-14', '2018-07-15',\n",
    "       '2018-07-19', '2018-07-21', '2018-07-28', '2018-08-04',\n",
    "       '2018-08-11', '2018-08-16', '2018-08-19', '2018-08-25',\n",
    "       '2018-09-01', '2018-09-29', '2018-10-13', '2018-10-27',\n",
    "       '2018-11-23', '2018-04-14', '2017-12-10', '2018-12-09',\n",
    "       '2017-09-17', '2018-09-16', '2018-02-10', '2017-11-05',\n",
    "       '2018-06-01', '2018-07-27', '2018-09-03', '2018-10-06',\n",
    "       '2018-11-18', '2018-12-22', '2012-08-11', '2013-01-01',\n",
    "       '2013-08-10', '2014-09-27', '2015-01-01', '2015-08-15',\n",
    "       '2015-09-26', '2015-12-12', '2016-03-12', '2016-08-20',\n",
    "       '2016-08-27', '2016-10-02', '2016-10-22', '2016-12-10',\n",
    "       '2017-03-11', '2017-08-26', '2017-09-16', '2017-09-23',\n",
    "       '2017-09-30', '2017-10-28', '2018-03-31', '2018-09-15',\n",
    "       '2018-11-03', '2018-11-17', '2018-12-01', '2018-09-23',\n",
    "       '2018-04-07', '2018-02-17', '2018-01-28', '2018-02-03',\n",
    "       '2016-03-26', '2016-07-16', '2017-03-25', '2017-06-10',\n",
    "       '2017-07-15', '2018-06-09', '2018-06-10', '2018-03-04',\n",
    "       '2018-08-18', '2018-09-22']], handle_unknown='ignore'), ['event.date.start']),\n",
    "        #('clean_categories.name', OneHotEncoder(categories=[['15k', '5k', 'marathon', 'half marathon', '10k', '5 mile', '8k',\n",
    "       #'5k run', '3k walk', '10k run', 'youth mile', '5k run/walk',\n",
    "       #'5k walk', '5 mile run', '1 mile run', '15k run', '10k walk',\n",
    "       #'6k run', '6k walk', '1 mile walk', '8k run', '8k walk',\n",
    "       #'10 mile run', '10 mile walk', '5 mile walk', '30k run',\n",
    "       #'30k bike', '8 mile run', '8 mile walk', 'bridge run',\n",
    "       #'international half marathon', 'u.s. only half marathon', '1 mile',\n",
    "       #'5.7 mile run', '5.7 mile walk', '5k competitive walk',\n",
    "       #'half marathon run', '5k fun walk', '5k wheelchair',\n",
    "       #'1 mile fun run', '2 mile run', '2 mile walk', '4 mile run/walk',\n",
    "       #'life time commitment day 5k', 'midnight streak',\n",
    "       #'commitment day 5k - master', 'quarter marathon', '5k walk/run',\n",
    "       #'1 mile fun run/walk', 'one mile fun run', '5 km run',\n",
    "       #'fire fighter', 'olympic triathlon', 'sprint triathlon',\n",
    "       #'olympic duathlon', 'sprint duathlon', '10k scenic challenge',\n",
    "       #'run swim run', 'half marathon walk', 'mini-marathon']], handle_unknown='ignore'), ['clean_categories.name']),\n",
    "        #('body.type', OneHotEncoder(categories=[['Run','nan']], handle_unknown='ignore'), ['body.type']),\n",
    "        #('body.timezone', OneHotEncoder(categories=[['America/Boise', 'America/Los_Angeles', 'America/Denver',\n",
    "       #'America/New_York', 'America/Chicago', 'America/Detroit']], handle_unknown='ignore'), ['body.timezone']),\n",
    "        ('location.state', OneHotEncoder(categories=[['AZ', 'CA', 'CO', 'FL', 'GA', 'IL', 'IN', 'MI', 'MN', 'MO', 'NM',\n",
    "       'NC', 'OH', 'OK', 'OR', 'PA', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI']], handle_unknown='ignore'), ['location.state']),\n",
    "        ('location.city', OneHotEncoder(sparse=False,categories=[['Scottsdale', 'San Francisco', 'San Diego', 'Arcata', 'Denver',\n",
    "       'Tampa', 'Atlanta', 'Chicago', 'Highland Park',\n",
    "       'Elk Grove Village', 'Oak Park', 'Indianapolis', 'Port Huron',\n",
    "       'Flint', 'Swartz Creek', 'Royal Oak', 'Pinconning', 'Roscommon',\n",
    "       'Plymouth', 'Algonac', 'Fenton', 'Detroit', 'Pigeon',\n",
    "       'Bloomfield Hills', 'Rogers City', 'Caseville', 'Montrose',\n",
    "       'Milford', 'Mackinac Island', 'Sault Ste. Marie', 'East Lansing',\n",
    "       'Williamston', 'Howell', 'Minneapolis', 'St. Louis', 'Santa Fe',\n",
    "       'Charlotte', 'Columbus', 'Canal Fulton', 'Brewster', 'Hartville',\n",
    "       'Strasburg', 'North Canton', 'Clinton', 'Cadiz', 'Dalton',\n",
    "       'Alliance', 'Barberton', 'Millersburg', 'Peninsula', 'Bolivar',\n",
    "       'Massillon', 'Canton', 'Akron', 'Oklahoma City', 'Tulsa',\n",
    "       'Oklahoma City, OK', 'Norman', 'Edmond', 'Lawton', 'Stillwater',\n",
    "       'Moore', 'Perry', 'Seiling', 'Bethany', 'Elk City', 'Sulphur',\n",
    "       'Yukon', 'Beaverton', 'Salem', 'Albany', 'Philadelphia',\n",
    "       'Nashville', 'Houston', 'Dallas', 'Virginia Beach', 'Fairfax',\n",
    "       'West Point', 'Seattle', 'Parkersburg', 'Milwaukee']], handle_unknown='ignore'), ['location.city']),\n",
    "       \n",
    "         #('event.tenant.name', OneHotEncoder(sparse=False,categories=[['Ventures Endurance', 'Avenue of the Giants Marathon',\n",
    "       #'Lincoln Park Zoo', 'Strides for Peace Run/Walk',\n",
    "       #'Leukemia Research Foundation', 'Chicago Bears',\n",
    "       #'Greater Illinois Pediatric Palliative Care Coalition',\n",
    "       #'Frank Lloyd Wright Races', 'Worldwide Sport and Social Club',\n",
    "       #'St. Clair County Mental Healthy Authority',\n",
    "       #'Genesee County Free Medical Clinic', 'Riverbend Striders',\n",
    "       #'Everal Race Management', 'CheeseTown Races',\n",
    "       #'Higgins Lake 5K/10K/Half Marathon', 'Plymouth YMCA',\n",
    "       #'Pickerel Run', 'Habitat for Humanity - Genesee County',\n",
    "       #'Scheurer Hospital', 'Atwood 10K Committee', 'Crim Foundation',\n",
    "       #'Milford Labor Day 30K', 'RunMackinac Events', 'Dino Dash',\n",
    "       #'EnMotive Michigan', 'Detroit Marathon',\n",
    "       #'Howell Area Chamber of Commerce', 'EnMotive OKC',\n",
    "       #'Ohio Challenge Series', 'HCCC ColorRun ', 'Bowerman 5k ',\n",
    "       #'Rotary River Fest Salem', 'Corvallis Lions Club',\n",
    "       #'LifeNet Health', 'Allen Stone Memorial Races',\n",
    "       #'Chesapeake Beach Civic League', 'Commonwealth Race Management',\n",
    "       #'Town Of West Point', 'Cape Henry Collegiate',\n",
    "       #'News And Sentinel Half Marathon',\n",
    "       #'Milwaukee Brewers Baseball Club']], handle_unknown='ignore'), ['event.tenant.name']),\n",
    "        \n",
    "\n",
    "         ('result.primary_bracket', OneHotEncoder(sparse=False,categories=[['Overall', 'Wheelchair', 'nan', 'Male', 'Female']], handle_unknown='ignore'), ['result.primary_bracket']),\n",
    "        \n",
    "    ], remainder='drop')\n",
    "\n",
    "# Then we create a three stage pipeline, where the first step applies the column transformer,\n",
    "# the next step fills our missing values, and the third step is a regression model. But remember,\n",
    "# this isn't a simple regression, we need an ordinal classification. To do this we can wrap\n",
    "# the linear regressor in another class which will transform the regression output. This class\n",
    "# is called the TransformedTargetRegressor, and we can tell it what function we want to apply\n",
    "# to the final output before returning the predictions.\n",
    "\n",
    "\n",
    "def evaluation_function(x):\n",
    "    '''Must return a ndarray of the rankings in order, the autograder will then create\n",
    "    a dataframe out of this with x.index as the index. Props to Rachell Calhoun!'''\n",
    "    return pd.Series(x.squeeze()).rank().values\n",
    "\n",
    "# We can wrap a linear regressor by setting the inverse_func to evaluation_function\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#estimators = [('ETR', ExtraTreesRegressor())]\n",
    "reg=TransformedTargetRegressor(regressor=ExtraTreesRegressor(n_estimators=900, criterion='squared_error', max_depth=4, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=False, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None), inverse_func=evaluation_function)\n",
    "#reg = TransformedTargetRegressor(regressor=LinearRegression(fit_intercept=True, copy_X=True, n_jobs=None, positive=False), inverse_func=evaluation_function)\n",
    "\n",
    "# Now we can build our three part pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        \n",
    "        (\"cleaner\", cleaner),\n",
    "        (\"fix_nans\", SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "        (\"regressor\", reg)\n",
    "        \n",
    "    ])\n",
    "\n",
    "# We can display the pipeline to see what it looks like and get a sense of data flow\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "display(pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec2ec7-b7e2-4058-9fee-30530bc06656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, GridSearchCV, cross_validate, KFold, RepeatedKFold\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce22443-34b7-49b2-a3b4-3d8a77a5adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_pipe = pipe.fit(train_set, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec6a90-ee39-4a3f-a1c2-0b2525f305cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_set[['sex','age','clean_categories_run_count','clean_categories_walk_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacb08ed-da68-48a3-81e3-e231de210785",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_30000 = features.loc[0:29999]\n",
    "features_30000.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1973de8a-101a-4f1c-baa0-d12f0bd8a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_30000 = y.loc[0:29999]\n",
    "y_30000.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ff40d9-fa62-492a-81dd-6fc8e24b18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(features_30000,y_30000,random_state=0,test_size=0.2, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d4118-af32-4cfe-8460-3b911ad34a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "        features, features_30000, y_30000, scoring=\"neg_mean_squared_error\", cv=10\n",
    "    )\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e3ddd11-d56a-4a82-a611-24926af45882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model evaluation method\n",
    "#cv = RepeatedKFold(n_splits=10, n_repeats=3)\n",
    "# evaluate model\n",
    "#scores = cross_val_score(train_set, features, y, scoring='neg_mean_absolute_error', cv=cv)\n",
    "\n",
    "clf = svm.SVC().fit(X_train, y_train)\n",
    "\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "# force scores to be positive\n",
    "#scores = absolute(scores)\n",
    "#print('Mean MAE: %.3f (%.3f)' % (scores.mean(), scores.std()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc7cd3b-947f-4104-ae6a-5086dcd36989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9d2d1-20ce-4aef-8272-b10a660406da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291dd301-500a-4ce0-b254-74e3b0bba13f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
