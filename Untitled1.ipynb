{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc89d570-a758-4fe3-8e2f-3a77d663a724",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "In this course assignment you must build a predictive model to determine what place a runner will come in in a foot race. More specifically, you must predict the place order for all participants running races in the year 2019 which are part of a series (e.g. they have been run annually, or at least once previously) using historical data. **For each race you must predict the integer place ordering for all participants**. You are not predicting the top n finishers, or performance bands where people will finish. Instead, your method is expected to be integrated into a premium feature of an application such as Strava, where historical data and data about the racer (and who is signed up for the race!) could be used to help build a personalized prediction for them.\n",
    "\n",
    "## Framing\n",
    "Through this assignment you will demonstrate your ability to build sophisticated supervised machine learning models, from data manipulation through feature engineering and modelling. This is an authentic dataset, and a real-world problem. You can use whatever modelling method you would like to, and can characterise the problem as a regression, classification, or ordinal prediction problem. There is no particular guidelines you must follow, nor guidance offered in the course _per se_ however, there is plenty of opportunity to ask course staff questions. **It is expected that this assignment will take significant effort**.\n",
    "\n",
    "## About the Data\n",
    "All of the races you are asked to predict outcomes for have a temporal relationship with some race in the past (e.g. they are part of an annual series), and I have included an identifier `sequence_id` to help identify this. The `sequence_id` will be included in all races you need to predict, so you can build race-specific features should you wish to. Races which are in your training set and do not have a `sequence_id` could be used however you might like. There may be some races which have a `sequence_id` in the training set but do not have a `sequence_id` in the holdout set -- this all depends what is offered in a given year!\n",
    "\n",
    "A couple of core concepts are important beyond sequences. First, races have categories, which generally (though doesn't need to) denote the length of the race (e.g. 5k, marathon, etc). I've cleaned this column into a new one, prepending the word `clean` so that a columns such as `category.completed.name` becomes `clean_category.completed.name`. I have left the original data in there for you as well, and the transformations I've done have been largely to reduce dimensionality along lines I think is reasonable.\n",
    "\n",
    "In addition to a category, there are `brackets`. Brackets typical denote demographic aspects of the runners and group them, such as Men aged 40-45. I have removed bracket information from the data and instead want you to focus on overall prediction which merges all runners in a given category together. This (should) line up with the rank order based on the individual's time, though I have not verified it (and predicting time is **not** the task).\n",
    "\n",
    "## Evaluation Criteria\n",
    "In this assignment you will be penalized equally for incorrect predictions weighted by the distance by which you are incorrect within a given race. It does not matter whether you over or under predicted a given rank, you are penalized one point per position you are off for a given individual. All DNF's are removed from the dataset, so each person in the dataset has a rank. You *must* provide a predicted rank for each person however, you may rank multiple people at the same spot if you would like (e.g. ties). The evaluation is for each combination of event and category, so a given event may have a 5 kilometer category, a 1 mile category, and so forth. Only individuals registered for a given event and category combination are included in the `DataFrame` you will be asked to predict for. Each event/category pair is equally weighted, and is scaled by the size of the event. Your overall prediction score will be the sum of all scores across the prediction tasks (e.g. across unique combinations of event and category). The exact scoring function is provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b011e2b-9c39-4c56-8ee3-dc89be4e4021",
   "metadata": {},
   "source": [
    "## Example Solution\n",
    "The following cell contains an example solution to demonstrate the API which is used for this assignment. In short, you are to create an `sklearn.pipeline.Pipeline` object which you `fit()` on your training data using whatever method you like and serialize it to disk in a file called `pipeline.cloudpickle`. This object will then be reinstantiated in the autograder and evaluated based on the scoring function described above. Please note that the solution below would be a poor one, it is intended **only** to demonstrate the API for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f32258bf-f64b-4e6b-8455-c4fd0a33e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "events=df['event.id'].unique()\n",
    "\n",
    "train_set=events[0:100]\n",
    "test_set=events[100:200]\n",
    "holdout_set=events[200:300]\n",
    "\n",
    "train=df.query(\"`event.id` in @train_set\")\n",
    "test=df.query(\"`event.id` in @test_set\")\n",
    "holdout=df.query(\"`event.id` in @holdout_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f972063-d0f2-480e-a3a8-b01db81ce2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "\n",
    "# This code simulates the autograder. It is not the full autograder implementation\n",
    "# but shares an API with the autograder. It expects that your fitted pipeline is\n",
    "# submitted with the name pipeline.cloudpickle as demonstrated above. This object\n",
    "# must implement the predict() function. This is done automatically by the sklearn\n",
    "# Pipeline object if the last element of your pipeline is a classifier which has\n",
    "# a predict() function. If you are not submitting a Pipeline, and want to do something\n",
    "# different, you *must* have a predict() function of the same method signature, e.g.:\n",
    "#\n",
    "#   predict(self, X, **predict_params)->np.ndarray\n",
    "\n",
    "# Load holdout data, in this case I'll simulate it by loading the training data\n",
    "df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "\n",
    "# And evaluate on all 5k races that we didn't consider for training\n",
    "holdout_data=df.query(\"`event.id`!='583f013a-1e54-4906-87f7-2b625206f5f9' and `clean_categories.name`=='5k'\")\n",
    "\n",
    "\n",
    "# This is the scoring function to determine model fitness\n",
    "def score(left: pd.DataFrame, right: pd.DataFrame):\n",
    "    '''\n",
    "    Calculates the difference between the left and the right when considering rank of items. \n",
    "    This scoring function requires that the two DataFrames have identical indicies, and that\n",
    "    they each contain only one column of values and no missing values. Props to Blake Atkinson\n",
    "    for providing MWE indicating issues with autograder version #1.\n",
    "    '''\n",
    "    assert(type(left)==pd.DataFrame)\n",
    "    assert(type(right)==pd.DataFrame)\n",
    "    assert(len(left)==len(right))\n",
    "    assert(not np.any(np.isnan(left)))\n",
    "    assert(not np.any(np.isnan(right)))\n",
    "    assert(left.index.equals(right.index))\n",
    "    # convert to ndarrays\n",
    "    left=left.squeeze()\n",
    "    right=right.squeeze()\n",
    "    return np.sum(np.abs(left-right))/(len(left)*(len(left)-1))\n",
    "\n",
    "# This function runs the prediction model agains a given event/category pair. It\n",
    "# intentionally loads the student model each time to avoid accidental leakage of data\n",
    "# between events.\n",
    "def evaluate(data, pipeline_file='pipeline.cloudpickle'):\n",
    "    # Load student pipeline\n",
    "    fitted_pipe = cloudpickle.load(open(pipeline_file,'rb'))\n",
    "    \n",
    "    # Separate out the X and y\n",
    "    X=list(set(data.columns)-{'overall_ranking'})\n",
    "    y=['overall_ranking']\n",
    "    \n",
    "    # Drop any missing results (DNFs)\n",
    "    data=data.dropna(subset=['overall_ranking'])\n",
    "    \n",
    "    # Ensure there is data to actually predict on\n",
    "    if len(data)==0:\n",
    "        return np.nan\n",
    "\n",
    "    # Predict on unseen data\n",
    "    predictions=pd.DataFrame(fitted_pipe.predict(data[X]),data.index)\n",
    "    observed=data[y]\n",
    "    \n",
    "    # Generate rankings within this bracket\n",
    "    observed=pd.DataFrame(data[y].rank(),data.index)\n",
    "    \n",
    "    # Return the ratio of the student score\n",
    "    return pd.Series({\"score\":score(observed,predictions)})\n",
    "\n",
    "# Student solution\n",
    "pipeline_file='pipeline.cloudpickle'\n",
    "\n",
    "def autograde(data_held_out):\n",
    "    # Run prediction on each group\n",
    "    results=data_held_out.groupby([\"event.id\",\"clean_categories.name\"]).apply(evaluate, pipeline_file)\n",
    "\n",
    "    # Display the results, uncomment this for your own display\n",
    "    results.reset_index()['score'].plot.bar();\n",
    "\n",
    "    # This is the student final grade\n",
    "    print(np.average(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c26bc46b-d3c3-4709-973b-65240f612f12",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert clean_categories.name, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 77>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m cloudpickle\u001b[38;5;241m.\u001b[39mdump(fitted_reg, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpipeline.cloudpickle\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Then telling the autograder function to fire\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[43mautograde\u001b[49m\u001b[43m(\u001b[49m\u001b[43mholdout\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mautograde\u001b[0;34m(data_held_out)\u001b[0m\n\u001b[1;32m     75\u001b[0m results\u001b[38;5;241m=\u001b[39mdata_held_out\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent.id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean_categories.name\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mapply(evaluate, pipeline_file)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Display the results, uncomment this for your own display\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar();\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# This is the student final grade\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39maverage(results))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:5839\u001b[0m, in \u001b[0;36mDataFrame.reset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[1;32m   5833\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m lab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5834\u001b[0m             \u001b[38;5;66;03m# if we have the codes, extract the values with a mask\u001b[39;00m\n\u001b[1;32m   5835\u001b[0m             level_values \u001b[38;5;241m=\u001b[39m algorithms\u001b[38;5;241m.\u001b[39mtake(\n\u001b[1;32m   5836\u001b[0m                 level_values, lab, allow_fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fill_value\u001b[38;5;241m=\u001b[39mlev\u001b[38;5;241m.\u001b[39m_na_value\n\u001b[1;32m   5837\u001b[0m             )\n\u001b[0;32m-> 5839\u001b[0m         \u001b[43mnew_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5841\u001b[0m new_obj\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m new_index\n\u001b[1;32m   5842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:4440\u001b[0m, in \u001b[0;36mDataFrame.insert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   4434\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot specify \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_duplicates=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4436\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself.flags.allows_duplicate_labels\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4437\u001b[0m     )\n\u001b[1;32m   4438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_duplicates \u001b[38;5;129;01mand\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m   4439\u001b[0m     \u001b[38;5;66;03m# Should this be a different kind of error??\u001b[39;00m\n\u001b[0;32m-> 4440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot insert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m   4442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc must be int\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert clean_categories.name, already exists"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "def roll_own()->object:\n",
    "    \"\"\"This function returns a fitted object with a predict(x) function\"\"\"\n",
    "    \n",
    "    # First I'm going to create a new class with a predict function, and that class\n",
    "    # is just going to call the regression object it is setup with and then rerank\n",
    "    # all of the values which come back\n",
    "    class RollingRegressor():\n",
    "        \n",
    "        # For this class I'm going to assume it has been given a fitted model, so\n",
    "        # I'm choosing not to implement the fit() function.\n",
    "        def __init__(self, fitted_model):\n",
    "            self.regressor=fitted_model\n",
    "        \n",
    "        # For the prediction we are just given our dataframe, so we have to do our\n",
    "        # data cleaning here.\n",
    "        def predict(self, X):\n",
    "            # We need to be careful and *not* drop rows. The autograder is expecting\n",
    "            # a rank back for every row in X! Lets just grab out the two columns of\n",
    "            # interest\n",
    "            df=X[[\"age\",\"sex\"]]\n",
    "            \n",
    "                        # For brevity let's get rid of any sex that isn't Male/Female and replace with nan\n",
    "            # A better approach would be to inspect and map this data accordingly, but I'll leave\n",
    "            # that as an enhancement.\n",
    "            #df.loc[df.query(\"`sex` not in ['Male','Female']\").index, 'sex']=np.nan\n",
    "            \n",
    "            # Now that this is binary we can convert this column into a numeric value\n",
    "            df.loc[ df['sex'] == 'F', 'sex'] = 'Female'\n",
    "            df.loc[ df['sex'] == 'M', 'sex'] = 'Male'\n",
    "            df.loc[df.query(\"`sex` not in ['Male','Female']\").index, 'sex']=np.nan\n",
    "            \n",
    "            df.loc[df.query(\"`sex` == 'Male'\").index, 'sex']=2\n",
    "            df.loc[df.query(\"`sex` == 'Female'\").index, 'sex']=1\n",
    "            \n",
    "            # Now just do whatever you want with missing values, this below doesn't seem ideal\n",
    "            df=df.fillna(0)\n",
    "            \n",
    "            # With the data cleaning done, we can now predict the times for our data\n",
    "            times=self.regressor.predict(df)\n",
    "            \n",
    "            # We can't return the times directly - the autograder wants ranks. We can\n",
    "            # use a similar method those to return ranks\n",
    "            return times.squeeze().argsort()+1\n",
    "        \n",
    "    # Our return class is done, now we just need to initalize it with a fitted\n",
    "    # model. To fit the model we just do all of the cleaning over, and add in some training.\n",
    "    # It would be a better ideal to put this all in the class itself, but I want to\n",
    "    # show you that this isn't needed -- the autograder is NOT going to try and fit()\n",
    "    # your model, it is only going to call predict(), so you can do whatever you want\n",
    "    # within that predict()\n",
    "    \n",
    "    df=train[[\"age\",\"sex\"]]\n",
    "    #df.loc[df.query(\"`sex` not in ['Male','Female','Unspecified']\").index, 'sex']=np.nan\n",
    "    #df.loc[df.query(\"`sex` == 'Male'\").index, 'sex']=2\n",
    "    #df.loc[df.query(\"`sex` == 'Female'\").index, 'sex']=1\n",
    "    #df.loc[df.query(\"`sex` == 'Unspecified'\").index, 'sex']=0\n",
    "    #df=df.fillna(0)\n",
    "\n",
    "    \n",
    "    # Since we have decided it's a regression problem, we can decide to use a simple linear\n",
    "    # model for our first attempt too, so I'll create that now\n",
    "    #from sklearn.linear_model import LinearRegression\n",
    "    #reg=LinearRegression()\n",
    "    #reg.fit(df,y)\n",
    "    \n",
    "    # Now we just return the object that the autograder will want\n",
    "    #return RollingRegressor(reg)\n",
    "    return df\n",
    "# We can test this out by instantiating it\n",
    "fitted_reg=roll_own()\n",
    "# Then saving it to a file\n",
    "cloudpickle.dump(fitted_reg, open('pipeline.cloudpickle','wb'))\n",
    "# Then telling the autograder function to fire\n",
    "autograde(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6277ac-8754-45cc-a446-6a6df3fab905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4104ab77-eaa8-46a9-88ac-63192f5abfa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f4c7b-3b7a-466b-a03a-8d9bf81eef3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
